[{"id":0,"href":"/posts/2025-06-24_reading_blogs/","title":"Programmers and Their Blogs","section":"Technical Blog","content":"Many developers seem to have a fanatic obsession with monospace fonts and using them to make their blogs look \u0026ldquo;cool\u0026rdquo;. I won\u0026rsquo;t call out anyone\u0026rsquo;s blog specifically, but you don\u0026rsquo;t have to look to hard to find some. As an example theme using a monospace font by default, look at hugo-theme-terminal, which has over 2,400 stars on GitHub. If you have a blog or are thinking about starting one, and you are writing mostly prose (you probably are), I have one suggestion for you about fonts:\nDo not use monospace fonts for prose.\nPlease use a nice proportionally-spaced font instead. It will be nicer for your readers.\nWhy monospace is bad for reading # I assume you care about your readers. Maybe there\u0026rsquo;s a slim fraction of a percent of developer/writers out there who are writing just so that they have a big portfolio of \u0026ldquo;content\u0026rdquo; with some metrics they can use to show off or brag about on LinkedIn. Whatever—those blokes probably don\u0026rsquo;t read much anyway, so I think I\u0026rsquo;m safe to ignore them.\nEven worse are the people who use an LLM to generate content for LinkedIn. Like, how banal can you get? Also, note that I\u0026rsquo;m using the word content in a slightly pejorative sense: LinkedIn addicts will talk about content as just some stuff that you need to generate to fill a space. It\u0026rsquo;s substance that matters. I want to read something that is trying to say something—not something that\u0026rsquo;s just taking up space on a (web)page.\nIf you care about your readers, you should make the reading experience pleasant for them. If I open a website that makes it hard or is uncomfortable for me to read/scan/whatever, my patience for reading whatever is on that site drops and I close the page.\nWhat things make a website uncomfortable to read? Here are a few:\nPoor contrast Bad margins/too-long lines Crappy fonts Setting light-gray text on a slightly-less-gray background is a great way to make people squint at your site in frustration. Not centering your text and/or having lines that are way too long also infuriates me. I want to read your article centered in my field if vision where I don\u0026rsquo;t have to turn my head. I\u0026rsquo;ve got a big monitor. Just slap margin: auto and max-width: 45rem on the body element in your CSS and you\u0026rsquo;re good to go. It\u0026rsquo;s not hard.\nMonospace fonts are a bad choice for prose because—news flash—we\u0026rsquo;re not used to reading monospace fonts! Every book on my shelf—from deeply technical texts like Types and Programming Languages by Pierce to high fantasy like The Way of Kings by Sanderson—is set in a proportional font.\nMonospace fonts are a holdover from the typewriter age. Thankfully, our technology is well past the limitations of that machine, and good typography can rule again.\nMonospace is good for code (duh) # "},{"id":1,"href":"/posts/2025-05-13_real_programmers/","title":"Real Programmers","section":"Technical Blog","content":"There\u0026rsquo;s been an explosion of tools for software development. At the same time there\u0026rsquo;s a growing sense that software quality isn\u0026rsquo;t what it used to be—or that developers these days don\u0026rsquo;t understand what it takes to be a \u0026ldquo;real\u0026rdquo; programmer, whatever that means. I\u0026rsquo;m not that old, but I have some old-school tool preferences. Some tools I really like; in other cases I feel that by not adopting particular habits, I\u0026rsquo;ve gained or retained an edge over others in the software development space.\nNotice: This is a rough-and-raw dump of some ideas that were ratting around in my head. Read at your own risk.\nGraybeard # I learned programming from a command line with nothing but a few books and some man pages to guide me. I am extremely comfortable navigating and controlling my computer via the terminal.\nMost college kids these days will start their programming journey with an IDE and Python Or C++ if they\u0026rsquo;re unlucky. and they learn nothing about how the operating system works under the hood. This is why things like MIT\u0026rsquo;s course \u0026ldquo;The Missing Semester of Your CS Education\u0026rdquo; exist: to get programmers up to speed on the tooling developed over the past several decades.\nThe thing is, there are a lot of new-fangled tools that programers have been picking up: instead of Emacs or Vim they use VS Code or Cursor. Instead of the git CLI they use the VS Code Git client. Instead of grep and perl they… I don\u0026rsquo;t know what they do to replace those tools honestly. Maybe they look for an NPM package that purports to do what they want.\nA lot of the new tools have less friction than old tools. But that typically comes at the cost of being further away from the underlying infrastructure. Tools like VS Code, etc. are less inspectable and understandable than Emacs and the like. GUIs—sometimes labeled \u0026ldquo;point-and-grunt interfaces\u0026rdquo;—almost always expose a smaller set of operations than comparable text-based interfaces to the user. Command line tools win by being composable; GUIs are very hard to plug together quickly in an ad-hoc way.\nThe value of friction # I believe it is important that every serious user of a computer—CS students especially—get familiar and comfortable with the command line. Our computers are rickety contraptions that frequently break or have novel requests made of them. Knowing the constituent components that make up an operating system, as well as some of the fundamental tools around software development (e.g. Make, Git, etc.) can help you get used to gluing generic utilities together to create perfectly-tailored workflows or one-off tools.\nI have been able to perform acts of astonishing wizardry—relative to the \u0026ldquo;average\u0026rdquo; computer-user—because I knew how to glue together a few command line utilities to process a huge amount of data in a short amount of time. Likewise, I am a capable programmer and have been able to effect some extraordinary refactors because I know how to make Emacs do my bidding in ways that would make your average VS Coder weep. Big respect out there for all the hard-core Vim users too. Vim is the gold standard for text editing efficiency. Being able to \u0026ldquo;pop the hood\u0026rdquo; on your computer and figure out what is going wrong lets you build more, better. When something goes wrong, you have a better mental model of how to fix it. When some new task comes up that no developer has ever encountered—it happens more than you think—you have the tools you need to create a novel solution.\nThe value of abstraction # And yet, I do not know how my car works. I drive an automatic. Computers are becoming increasingly a commodity like a car—is it so bad that more people don\u0026rsquo;t know how the innards work?\nTwo points: first, I believe that it is good that most people do not have to know how a file system functions to get work done on the computer. Second, I believe that any craftsperson understand their tools to the fullest extent—for race car drivers, this would be understanding how an engine works, and for programmers, the operating system.\nTo the first point: most people have high-level tasks that they want to accomplish. They want a friend to see a picture that they took, so they load it up in an email or messaging service and send it off. They don\u0026rsquo;t need to know about image encoding, network routing, etc. to get this done. This is good.\nProgrammers, too, often have high-level things that they want to accomplish. Consider editing a code base: when reading some code, I often want to jump from where a function is called to where it is defined. This task is more semantically meaningful to me than carefully crafting a regex for grep to show me where I might want to go. The less friction in this process, the better: it lets me stay more in flow and helps me get my work done.\nThe purpose of abstraction is not to be vague, but to create a new semantic level in which one can be absolutely precise.\nEdsger Dijkstra\nI learned how to use Git via the CLI. Now I use Magit. This is because Magit walks a delicate line: it makes common operations much easier than the CLI, yet at the same time it doesn\u0026rsquo;t baby me—it actually helps with discoverability—and it can compose Git commands at times to accomplish higher-level functions. Example: there are commands to \u0026ldquo;spin off\u0026rdquo; a series of unpushed commits into a new branch. It does this by creating a new branch, then reverting the old branch to point to whatever its upstream remote was. Super helpful when you start development work and realize after the fact that you should probably be working on a new branch. Moreover, I can see how it works under the hood: Magit can show you all the git commands it\u0026rsquo;s running to do what you want.\nI think we need more tools like Magit: things like lazygit, lazydocker, tldr, LSP, etc. all extend users\u0026rsquo; understanding of systems whilst not keeping them too far from the source.\nThe gift of choice # I think it\u0026rsquo;s valuable to be able to choose the level of abstraction to work on. I\u0026rsquo;m never far away from a command prompt while I\u0026rsquo;m working on my computer. Yet, most of the time I do my Git work via Magit. Magit is powerful enough that I typically don\u0026rsquo;t need to resort to the command line, yet sometimes I do for things like setting configuration variables.\nI think that it is good that we have tools that operate at higher levels of abstraction—GUIs even—because these can help us stay more rooted in the semantics of our problem domains. At the same time, I think it is crucial that software engineers get comfortable with understanding the fundamentals of operating systems, version control, text editing, scripting, etc. so that they can build new abstractions when the need arises.\nComputers are still in their infancy. They\u0026rsquo;re just barely taking their first steps. I see no reason to use exclusively decades-old command line tools when we have some fantastic new utilities that aid our ability to build more and better software. Yet we must not forget the basics, lest we loose the ability to take steps on our own.\n"},{"id":2,"href":"/posts/personal/2025-04-20_kids_shows/","title":"TV Shows for Kids","section":"Personal Blog","content":"When I was in my early 20s, I vowed that I would keep my kids from watching any amount of television.\nTurns out, sometimes you really need a break as a parent. A good show can keep your kid entertained while you perform necessary tasks like preparing a meal, doing the dishes, or getting just enough extra sleep to not blow your top or doze off in the car while you drive your kid to preschool.\nSo, I have had a change of heart: TV can be a tool, but not all TV programs are created equal.\nWithout further ado, here is my tier list of the shows I\u0026rsquo;ve seen or heard about:\nS-tier # These are the shows that I am fine with my kid watching any time. They are well-written, low-stimulus, and never get annoying.\nWhy do I care so much about low-stimulus shows? I don\u0026rsquo;t want my kids getting hooked on dopamine rushes. I\u0026rsquo;d rather that they play imaginatively as much as possible. Low-stimulus shows help by not desensitizing kids to the gentler kind of happiness that comes through creative play.\nBluey # How could it not be Bluey?! It\u0026rsquo;s a low-stimulus show about parenting that kids happen to enjoy as well. The dad, Bandit, is an enthusiastic, clever, engaged parent who sometimes messes up but always makes up for it. The mum, Chili, is loving, firm, hard-working, and creative. The relationships are positive and realistic.\nMy favorite episodes are:\nCamping This one makes me tear up. I initially saw Jean-Luc\u0026rsquo;s departure as a metaphor for death and Chili\u0026rsquo;s words as a hope to see our friends again in the hereafter. But then my wife pointed out that the episode is essentially the Star Trek episode Darmok where the captain of the Enterprise (Jean-Luc Picard—the name should have been a clue) must learn how to communicate with someone who speaks a strange language. The Sign The hour-long 3rd-season finale is an absolute onslaught of emotional sucker-punches if you\u0026rsquo;ve watched the entire show. Granny Mobile Nothing particularly deep in this episode, but it is so funny. There are more. Bluey deserves all the hype it gets. It\u0026rsquo;s that good. If you have a toddler, watch Bluey.\nPuffin Rock # This feels like an Irish-flavored Bluey-type show, but with Irish-accented puffins. Sweet show with a pretty animation style. Most episodes are just about the main character, Oona, exploring the island. Less anthropomorphic than Bluey.\nA-tier # Good shows that don\u0026rsquo;t quite rise to the level of Bluey and aren\u0026rsquo;t as visually beautiful as Puffin Rock but are still fun and occasionally educational.\nLittle Einsteins # Four kids fly around in a \u0026ldquo;Rocket\u0026rdquo;. Each episode features a work of classical music and some art by a famous artist. The kids never fight—the whole show is about them solving problems. The best part is that my kid can now recognize lots of different important classical pieces and enjoys listening to them. Occasionally the episodes get a little annoying because of how formulaic they are, but maybe that\u0026rsquo;s good for the kids.\nBlue\u0026rsquo;s Clues # I grew up watching Blue\u0026rsquo;s Clues and it\u0026rsquo;s still such a nice, sweet show.\nB-tier # These are shows that we will turn on if we have to. I wouldn\u0026rsquo;t consider them bad, but they are moderately annoying.\nIf You Give A Mouse A Cookie # This is a TV show based off of the series of children\u0026rsquo;s books by Laura Numeroff and Felicia Bond. The show is… fine. Most of the characters seem to have a sense of helplessness when something gets lost/broken and they feel that the circumstances \u0026ldquo;…will be ruined—forever!\u0026quot; This is a phrase that I am pretty sure crops up in every episode. Ugh. At least half the episodes involve some MacGuffin rolling down a hill to a pond.\nAgain, it\u0026rsquo;s not a bad show, but sometimes my daughter will start talking like Mouse with one-word requests for things like \u0026ldquo;thirsty\u0026rdquo; or \u0026ldquo;hungry\u0026rdquo; instead of speaking in full sentences.\nC-tier # These are shows that I don\u0026rsquo;t consider actively harmful, but I strongly dislike because of how annoying they are or because my kid picks up bad behaviors from them.\nDaniel Tiger # On the surface, this is the perfect show: it\u0026rsquo;s a spin-off of Mr. Roger\u0026rsquo;s Neighborhood, the animation gentle and low-stimulus, and it\u0026rsquo;s moderately cute.\nBut oh—oh how deceptive it is.\nDaniel Tiger displays an impressive degree of learned helplessness and timidity. All of the \u0026ldquo;problems\u0026rdquo; that he encounters in the show are invented and stupid. E.g., it is raining outside so we can\u0026rsquo;t play on the beach—grrr I\u0026rsquo;m mad and now I need help calming down from a total meltdown.\nThe worst thing from this rainy-beach episode is when the kids drag in several wheelbarrows\u0026rsquo; worth of sand onto the living room carpet and, when the mom comes in and gets angry, Daniel tells the mom to take a deep breath and calm down from her slightly agitated state.\nIf my kid ever dragged several cubic meters of sand into any part of my house, I reserve the right to be upset.\nAnyway, cute on the surface, aggravating underneath.\nF-tier # I have not watched these shows. I\u0026rsquo;m too scared to go near them with a stick.\nCoComelon # CoComelon is the epitome of high-stimulus children\u0026rsquo;s programming. In every shot the camera is panning, no shot lasts more than 3 seconds, and the show\u0026rsquo;s developers utilize a tool they call \u0026ldquo;The Distraction\u0026rdquo; to determine when scenes are insufficiently attention-grabbing: when a test subject (a small child) looks away from the show to look at a screen showing adults doing banal household chores, the animators will amp up the show at that point to keep kids dialed in.\nI would rather not have my child\u0026rsquo;s dopamine receptors burned out by stimulus-overload.\nLook, if you like CoComelon, I won\u0026rsquo;t judge you. If you\u0026rsquo;re wondering if you should pull it up for your kids, I would stay far away.\nThe fewer shows the better # Kids need to be bored. The more bored they are, the more time they have to be creative and develop an internal world. I do think it\u0026rsquo;s fine to have some TV—I grew up loving Arthur, Cyber Chase, and Reading Rainbow. It is really nice to have half an hour to shower, eat, and get some chores done so I can better take care of my child. I\u0026rsquo;m trying to find good shows though. I hope this helps any parents out there looking for ideas. :) Hang in there—raising kids is the very best experience this world has to offer.\n"},{"id":3,"href":"/posts/2025-02-06_latex_bootstrap/","title":"A Quick Guide to LaTeX","section":"Technical Blog","content":"LaTeX is a powerful typesetting system hamstrung by a few decades-old decisions and some… ahem… questionable design decisions. Nevertheless, its ability to typeset technical documents remains unmatched, and it enjoys wide support across STEM fields. Learning LaTeX is a worthy use of your time, if you intend to pursue a career in science.\nThis is meant as a short and simple how-to guide for learning LaTeX. It is not meant to be comprehensive, but rather serve as a guide of where to look to get the information you need to know. It is organized as a problem → solution mapping.\nKey resources # These are the places where I learned LaTeX. They will serve you well.\nLaTeX Wiki Overleaf Looks like Overleaf has a nice getting started guide here. Getting LaTeX # There are several LaTeX distributions. The only one I have ever used is the TeX Live distribution, and I\u0026rsquo;ve never needed anything else.\nmacOS brew install --cask mactex-no-gui to get just the CLI tools; I never use the GUI programs. Debian apt-get install texlive; see https://packages.debian.org/stable/texlive for details. You may need to install other packages like texlive-latex-recommended to get some more packages. Other The TeX Live website should have instructions for you. The TeX Live distribution comes bundled with most, if not all, of the packages you will ever need. So, when I suggest using the e.g. geometry or enumitem package, you should be able to just put \\usepackage{geometry} in your preamble without worrying about downloading anything.\nMaking a document # Further reading: LaTeX Wiki: Document Structure\nLaTeX documents have a preamble and then a document body. Roughly, the preamble specifies the look of the document through setting variables and importing libraries, and the document body holds all of the text.\nLaTeX documents have this format:\n\\documentclass[...class options...]{class name} %% This is the \u0026#34;preamble\u0026#34; ... packages and variables here ... \\begin{document} ... body of document ... \\end{document} A document class header is the first line in the file, and it describes what kind of a document you are making. Most common form is article. Technical journals typically define their own document class, which is kind of like enforcing a standard style sheet out-of-the-box. Document classes typically have options to configure fine points of the document setup.\nA standard article class might look like this:\n\\documentclass[letterpaper,draft]{article} This says that the document is an article (other types are book, beamer for slides, and more), and the options letterpaper mean the PDF should size to a US letter sheet, and draft will highlight hyphenation errors for you. There are lots of options for each document class; consult the documentation as needed.\nUTF-8 in source # Put this in your preamble:\n\\usepackage[utf8]{inputenc} This will let you put UTF-8 characters inside your document file.\nPage layout # Changing the size of the margins # You want to use the geometry package. For example, to set the left and right margins to 1.8 inches, and the top and bottom margins to 1 inch, do this:\n\\usepackage[margin=1.8in,top=1in,bottom=1in]{geometry} Changing paragraph styles # The default paragraph style is to not indent the first paragraph in a section This is correct typographic practice, so don\u0026rsquo;t mess with that. and to indent every subsequent paragraph.\nIf you want to change this so that paragraphs have no indentation but have a bigger separation between them (my personal favorite paragraph style) then you can put something like this in your preamble:\n\\setlength{\\parindent}{0pt} \\setlength{\\parskip}{0.5\\baselineskip} The \\parindent length controls how much to indent a paragraph. By setting it to 0pt we turn off paragraph indentation. The \\parskip controls how much space to put in between paragraphs. I think its default value is 0. By setting it to half of \\baselineskip we add about a line and a half of blank space between paragraphs. (See LaTeX Wiki: Lengths for more details.)\nFonts # Changing the default font # You need the fontspec package. Here is what I do to set the main font to Valkyrie, the sans-serif font to Concourse, and the monospace font to Iosevka:\n\\usepackage{fontspec} \\setmainfont[BoldFont = * Bold, RawFeature={+onum}]{Valkyrie B} \\setsansfont[RawFeature={+ss03,+ss05,+ss12,+ss13,+ss15,+ss18}]{Concourse 3} \\setmonofont{iosevka-output-extended}[Scale = 0.85, Extension = .ttf, Path = /Users/ashton/Library/Fonts/, UprightFont = *, ItalicFont = *italic, Ligatures={NoRequired,NoCommon,NoContextual}] As you can see, there are quite a few options enabled for each of those. The BoldFont = * Bold option for Valkyrie means that the otf file I want LaTeX to use for bolded Valkyrie is at Valkyrie B Bold.otf. If the file were named Valkyrie B-Bold.otf I would have to say BoldFont = *-Bold.\nYou need to use LuaLaTeX to use the fontspec package! This should come with your TeX Live distribution. I will typically say latexmk -lualatex file.tex to build.\nTables # Take a look at the LaTeX wiki and this Overleaf tutorial. LaTeX gives you a lot of control over the presentation of tables.\nSource Code # Further reading: LaTeX Wiki: Source Code Listings\nPutting source code in LaTeX is a pain. Lower your expectations now and life will be easier.\nFirst, put this in your preamble:\n\\usepackage{listings} \\usepackage{xcolor} \\definecolor{codegreen}{rgb}{0,0.6,0} \\definecolor{codegray}{rgb}{0.5,0.5,0.5} \\definecolor{codepurple}{rgb}{0.58,0,0.82} \\definecolor{backcolour}{rgb}{0.95,0.95,0.95} \\lstdefinestyle{mystyle}{ backgroundcolor=\\color{backcolour}, commentstyle=\\color{codegray}, keywordstyle=\\color{magenta}, numberstyle=\\tiny\\color{codegray}, stringstyle=\\color{codegreen}, basicstyle=\\ttfamily\\footnotesize, breakatwhitespace=false, breaklines=true, captionpos=b, keepspaces=true, numbers=left, numbersep=5pt, showspaces=false, showstringspaces=false, showtabs=false, tabsize=2 } \\lstset{style=mystyle} The first two lines bring in the listings and the xcolor packages. The first lets you define code blocks, and the second lets you define custom colors, though some named colors (like \u0026ldquo;magenta\u0026rdquo; in this example) come built-in.\nThe \\lstdefinestyle{mystyle}{...} lets you create something kind of like a stylesheet for your code. The most important big is setting the basicstyle=\\ttfamily option. This sets your code in a monospace font. (Specifically, it sets it in the \\ttfamily font. In the example it also sets it to be a little smaller at \\footnotesize.)\nInside your document you can put your source code in a lstlisting environment like this:\n\\begin{lstlisting}[language=C] int main() { printf(\u0026#34;Hello, world!\\n\u0026#34;); return 0; } \\end{lstlisting} There are a lot of other ways to customize this package, but I will not cover those here.\nOther recommended packages # LaTeX has a lot of packages. Here are some that I like using:\nmicrotype Little details to enhance the typography of your document. stmaryrd \u0026ldquo;St. Mary Road\u0026rdquo;: oodles of mathematical symbols. Full example # Here\u0026rsquo;s an example LaTeX document that uses a lot of the config above. Hope it helps you get started with LaTeX!\n\\documentclass[11pt,letterpaper]{article} \\usepackage[utf8]{inputenc} \\usepackage[margin=1in]{geometry} \\usepackage{microtype} \\usepackage{listings} \\usepackage{xcolor} \\definecolor{codegreen}{rgb}{0,0.6,0} \\definecolor{codegray}{rgb}{0.5,0.5,0.5} \\definecolor{codepurple}{rgb}{0.58,0,0.82} \\definecolor{backcolour}{rgb}{0.95,0.95,0.95} \\lstdefinestyle{mystyle}{ backgroundcolor=\\color{backcolour}, commentstyle=\\color{codegray}, keywordstyle=\\color{magenta}, numberstyle=\\tiny\\color{codegray}, stringstyle=\\color{codegreen}, basicstyle=\\ttfamily\\footnotesize, breakatwhitespace=false, breaklines=true, captionpos=b, keepspaces=true, numbers=left, numbersep=5pt, showspaces=false, showstringspaces=false, showtabs=false, tabsize=2 } \\lstset{style=mystyle} \\setlength{\\parindent}{0pt} \\setlength{\\parskip}{0.5\\baselineskip} \\begin{document} \\noindent % Don\u0026#39;t indent the first line; happens automatically after a \\section{} When writing a paper, I \\emph{always} load the \\texttt{microtype} package. I like how it lets you get hanging indentation. Here is an example of some code: \\begin{lstlisting}[language=C] int main() { printf(\u0026#34;Hello, world!\\n\u0026#34;); return 0; } \\end{lstlisting} Hustle and bustle were once very popular. This cannot be denied. Also, I think Strong Bad should decrease The Cheat\u0026#39;s allowance. \\end{document} "},{"id":4,"href":"/posts/2024-12-14_emacs_catchup/","title":"What's New in Emacs: Last Decade Edition","section":"Technical Blog","content":"Emacs has come a long way in the past decade. This is meant as a guide to anyone who\u0026rsquo;s been using stock or near-stock Emacs for some years and wants a quick update on the new shiny stuff that comes bundled with Emacs.\nThis guide assumes you are running Emacs 29, which was released in 2023.\nCompletion # Completion is pervasive in Emacs: hit TAB whenever you\u0026rsquo;re selecting a file (C-x C-f) or running a command by name (M-x) and the like, and completion kicks in. Emacs\u0026rsquo; built-in completion framework and interface have gotten a huge upgrade in recent years.\nIf you hit TAB a bunch of times when writing e.g. a file name, you\u0026rsquo;ll open up the *Completions* buffer. Emacs 29 has lots of ways to configure this buffer to be much more useful than the default:\n(setopt enable-recursive-minibuffers t) (setopt completion-auto-help \u0026#39;always) (setopt completions-max-height 20) (setopt completions-format \u0026#39;one-column) (setopt completion-auto-select \u0026#39;second-tab) Here\u0026rsquo;s what each one does:\nenable-recursive-minibuffers You can interrupt doing something in the minibuffer with another minibuffer-using operation. completion-auto-help The value 'always means always show the *Completions* buffer when trying to complete; other options include nil and 'lazy. completions-max-height Controls how many lines high the *Completions* buffer should be. completions-format Put all completions in one column. I like this formatting better. completion-auto-select Controls when to jump to the *Completions* buffer automatically. The 'second-tab option is nice: the first TAB opens the *Completions* buffer, and if you want to select something from the list, you just hit TAB again. That\u0026rsquo;s for minibuffer completion. Emacs also supports completion for whatever the cursor is on; Emacs calls this \u0026ldquo;completion-at-point\u0026rdquo;. Here\u0026rsquo;s how to get nice tab-complete behavior in Emacs:\n(setopt tab-always-indent \u0026#39;complete) (setopt completion-styles \u0026#39;(basic initials substring)) Setting tab-always-indent to 'complete means that when you hit TAB, Emacs will first try to indent the current line. If the line is already indented, then Emacs will call the completion-at-point facilities of Emacs. Assuming you have the minibuffer completions set up as explained above, you can use the same interface to complete in the minibuffer as well as tab-completion that you see in other editors.\nThese are just the built-in completion mechanisms. Emacs\u0026rsquo; framework has gotten a great upgrade that has allowed packages like Vertico (minibuffer completion) and Corfu (completion-at-point in a popup window) to flourish. Vertico and Corfu are two of my favorite packages.\nThe completion-styles is neat: it takes a list of different \u0026ldquo;styles\u0026rdquo; that can be used when filtering candidates. The initials is particularly fun: type M-x dtw TAB and you should see the function delete-trailing-whitespace in the *Completions* buffer.\nEditing code # Smart completion, jump-to-definition, etc. # Emacs 29 added the Eglot (\u0026ldquo;Emacs polyGLOT\u0026rdquo;) package to the core distribution: Eglot is a lightweight Language Server Protocol (LSP) client. This lets Emacs talk to language servers like clangd or rust-analyzer (etc.) to get things like good code completion, jump-to-definition, documentation, etc.\nEglot is conservative: it doesn\u0026rsquo;t get in your way, and all the completion smarts come up only when you ask for them. Of course, it\u0026rsquo;s possible to make it more eager and behave a little more like VS Code, but that\u0026rsquo;s your choice. I personally use jump-to-definition more than any other feature.\nIf you\u0026rsquo;re working on—say—a Rust project, install rust-analyzer on your system, then open a file in a Rust project and run M-x eglot. Now all of the completion-at-point mechanisms should be smart about the language you\u0026rsquo;re working with. You should also be able to jump to e.g. a function definition by putting your cursor on a function and invoking xref-find-definitions (bound to M-. by default.)\nProjects # Emacs now has project.el package that adds some nice stuff for navigating projects. For example, the project-find-file command is like find-file but is restricted to files in the current project. This pairs nicely with fancier completing-read interfaces to let you find and jump to files without having to navigate the entire file hierarchy.\nTree-sitter # Tree-sitter is a parser generator tool that is fast and—most importantly—works on incomplete inputs (e.g. a file you\u0026rsquo;re in the middle of editing). Emacs 29 added support for tree-sitter enabled modes. To be honest, it\u0026rsquo;s a little clunky still, but support is improving. (The Emacs 30 pre-release is already better than what 29 does.) Tree-sitter is too big for me to cover here; see Mickey Petersen\u0026rsquo;s excellent article on the subject.\nEditing prose # There\u0026rsquo;s a built-in dictionary feature in Emacs 28. Use this to look up words from https://dict.org:\n(setopt dictionary-server \u0026#34;dict.org\u0026#34;) Use M-x dictionary-lookup-definition to look up the word at point. You can of course bind this to a key for more convenience. (Looks like there\u0026rsquo;s also dictionary-tooltip-mode which shows the definition of a word when you hover over it with your mouse. Fancy, and a bit too much for me. But very cool!)\nGoing really far back is flyspell-mode: spellchecking while-you-type. Nothing special about that; what is special is how easy it is to correct words: hit C-; to cycle through corrections of the closest misspelled word. For code, there\u0026rsquo;s flyspell-prog-mode, which does spellchecking in just comments and strings. Even though this has existed for a while, I don\u0026rsquo;t see it turned on very often.\nI now use Jinx for my spellchecking needs. It\u0026rsquo;s faster and more flexible, but it draws a lot of inspiration from flyspell-mode.\nThis mode is also a bit older, but I love visual-line-mode: turning this on will soft-wrap lines at word boundaries and make all your motion commands behave according to visual rather than logical lines: e.g. if I have a really long line that is wider than my window, it will be wrapped—just like in any word processor—and pressing the arrow keys will move me to the character that is visually above the current one, even though it might be on the same line.\nGeneral improvements # New themes # Emacs comes with two new themes: modus-operandi (light) and modus-vivendi (dark). These themes have excellent contrast and are ment to conform to the highest levels of visual accessibility. Try them with M-x load-theme RET modus-vivendi.\nPackage manager and configuration # Emacs has a built-in package manager called package.el. This makes it easy to install 3rd-party packages. Run M-x list-packages to activate.\nI have a list of my favorite Emacs packages, which include (but are not limited to) Magit, Vertico, and Avy.\nThere are several places you can get packages from; when package.el came out it only supported packages from GNU ELPA. Recently Non-GNU ELPA got added to the stock list which opens up a huge set of packages such as the venerable Magit package. And of course, there\u0026rsquo;s MELPA, which you have to add to your config yourself if you want packages from there:\n(add-to-list \u0026#39;package-archives \u0026#39;(\u0026#34;melpa\u0026#34; . \u0026#34;https://melpa.org/packages/\u0026#34;) t) Emacs 28 added the awesome use-package macro, which makes configuring packages really nice. Previously you might have written something like this to configure a package:\n(require \u0026#39;citar) (define-key global-map (kbd \u0026#34;C-c C-i\u0026#34;) \u0026#39;citar-insert-citation) (define-key global-map (kbd \u0026#34;C-c C-d\u0026#34;) \u0026#39;citar-dwim) (add-hook \u0026#39;org-mode-hook \u0026#39;citar-capf-setup) (add-hook \u0026#39;LaTeX-mode \u0026#39;citar-capf-setup) (setq citar-bibliography \u0026#39;(\u0026#34;~/Research/refs.bib\u0026#34;)) Now you can do this with a macro:\n(use-package citar :bind ((\u0026#34;C-c C-i\u0026#34; . citar-insert-citation) (\u0026#34;C-c C-d\u0026#34; . citar-dwim)) :hook ((org-mode LaTeX-mode) . citar-capf-setup) :custom (citar-bibliography \u0026#39;(\u0026#34;~/Research/refs.bib\u0026#34;))) What you don\u0026rsquo;t see is all the extra work that use-package does behind the scenes to speed up startup times by lazily loading your package. There are lots of options for setting up hooks, different kinds of configuration, keymaps, etc.\nPerformance and utilities # Emacs 27 added a native JSON parsing library. This meant that things like Eglot (and other LSP clients) got much snappier. Emacs 28 can compile Emacs Lisp code to native byte code. This means that all Emacs packages just run faster.\nThere\u0026rsquo;s a lot more, but those are some of the biggest ones. Nice to see Emacs getting a lot of love.\nEcosystem # Many of the improvements to the core have also lead to a flourishing of excellent third-party packages. Here are some of my favorite:\nMagit The only Git porcelain worth using. I was once a Git command-line purist. Then I found Magit and became a convert: unlike other Git porcelains, Magit hides none of what Git can do. Moreover, it makes complicated operations (e.g. staging or reverting individual lines of a file) easy and exposes you to more of what Git can do. Vertico \u0026ldquo;Vertical completion\u0026rdquo;: wraps the standard completing-read interface with a nice interactive version. Thanks to the improvements to the completing-read API, all Emacs features that use completing-read just work. Consult Enhancements for a bunch of Emacs\u0026rsquo; UI: for example, consult-buffer replaces the standard switch-to-buffer with a version that shows you a live preview. Pairs nicely with Vertico. Corfu Enhanced completion-at-point interface: get a fancy popup window to show completion candidates when completing a word in-buffer. Corfu uses a child frame by default; for non-GUI users there\u0026rsquo;s corfu-terminal to make it work in TUI mode as well. Citar Citations made easy: Citar reads .bib databases and provides a slick completing-read interface to insert citation keys. There are so many more packages that have come out in the past few years that I use all day every day. I wrote about some of them here.\nA starter kit for this # I made Emacs Bedrock as a starter kit to help explore all these nice new built-in features of Emacs. It\u0026rsquo;s a true starter kit: you download it once, then tweak it to your liking. By default it installs only one package (which-key; Emacs 30 will have this package built-in) and the rest is tweaking some settings to be what I think the defaults should be. It\u0026rsquo;s meant to encourage exploration. If you liked something from this post, take a look at Bedrock and maybe you\u0026rsquo;ll find something else there that you like!\n"},{"id":5,"href":"/posts/2024-11-21_powerful_or_safe_languages/","title":"Should Programming Languages be Safe or Powerful?","section":"Technical Blog","content":"Should a programming language be powerful and let a programmer do a lot, or should it be safe and protect the programmer from bad mistakes? Contrary to what the title insinuates, these are not diametrically opposed attributes. Nevertheless, this is the mindset that underlies notions such as, \u0026ldquo;macros, manual memory management, etc. are power tools—they\u0026rsquo;re not supposed to be safe.\u0026rdquo; If safety and power are not necessarily opposed, why does this notion persist?\nThe problem—I think—is that historically you did have to trade safety for certain kinds of power: if you wanted to write a high-performance device driver, C—with all its unsafe behavior—was your only option. This founded the idea that the \u0026ldquo;power tools\u0026rdquo; of the industry were fundamentally dangerous.\nThere\u0026rsquo;s a few things wrong with this though:\nPower is relative to the domain of interest. Both Haskell and C are powerful, but in completely different ways. So, when judging whether an aspect of a language is powerful or not, consider its application.\nExpressive languages get you power without sacrificing safety. New advances in programming language research have found ways to express problem domains more precisely. This means that we have less and less reason to breach safety and reach into the unsafe implementation details to get our work done.\nIt\u0026rsquo;s good to add safety to power tools. A safe power tool is more trustworthy than an unsafe one. This holds for real-world tools: I will never use a table saw without a functioning saw stop.\nSpecifically in the case of macros, there\u0026rsquo;s been an evolution from powerful-but-unsafe procedural macros in Lisp to safe-but-less-powerful pattern macros in Scheme, and finally to powerful-and-safe macros in Racket.\nMore safety means higher reliability—something that everyone wants. And with advances in making languages more expressive, you can have a language perfectly suited to a particular domain without sacrificing safety.\nWhat makes a language powerful? # A language that lets you do more of what you want to do is more powerful than a language where you can\u0026rsquo;t do what you want. But what does \u0026ldquo;what you want to do\u0026rdquo; encompass? If you want to write device drivers, then C is great for you. However, C is not as expressive in some of the ways that, say, Haskell is. For example, in Haskell, I can write lazy, recursive definitions. Here\u0026rsquo;s a list of all Yes, all the Fibonacci numbers. Haskell is lazy; this will compute as many as you ask for. the Fibonacci numbers:\nfibs = 0 : 1 : zipWith (+) fibs (tail fibs) Before you tell me that that\u0026rsquo;s just a useless cute trick, I actually had to use this when I was building the balancing algorithm in my rope data structure for my text editor written in Haskell. Haskell is incredibly powerful in an expressive sense: a single line of code can elegantly capture a complicated computation.\nThe purpose of abstraction is not to be vague, but to create a new semantic level in which one can be absolutely precise.\nEdsgar Dijkstra\nPower is closely related to the domain of interest: a language is powerful in a particular realm of problems. C is powerful for working with memory directly. Conversely, Haskell or Racket is more powerful than C in pretty much every other domain because these languages give the user tremendous ability to match the program to the domain. This is a meta-power that sets high-level languages apart from lower-level ones.\nSafe languages can be just as powerful as their unsafe counterparts—in many cases, they are more powerful because the abstractions they create better fit the domain. Whenever a tradeoff between power and safety must be made, that is a sign that the language is not the right fit for the domain.\nConsider how immutability gives you local reasoning power. At one of my industry jobs, our codebase was a mixture of Ruby and Elixir. Both are safe languages, but Elixir is immutable. When I was working on some Elixir code, I could read:\nuser = get_user(session) name = get_user_name(user) do_something_else(user) and I didn\u0026rsquo;t have to worry about user getting modified in the call to get_user_name. To understand the output of this function, I didn\u0026rsquo;t have to worry too much about the implementation of get_user_name.\nIn contrast, if you did the same sort of thing in Ruby:\nuser = get_user(session) name = user.get_name() user.do_something_else() the get_name method could do something sneaky like set name to \u0026quot;blank\u0026quot; if it didn\u0026rsquo;t exist. You might think, \u0026ldquo;well, just document that behavior.\u0026rdquo; Now I need to read the documentation of every function I encounter—I might as well go read the code to be sure the documentation isn\u0026rsquo;t out of date. Local reasoning means to understand what do_something_else is passed, I don\u0026rsquo;t have to worry in the first place if get_name will do somethig to the result of get_user. In this case, I did have to understand what every method call did to understand the function. This made it harder to track down errors because I had to account for all the side effects that could happen at every method call.\nCertain things like immutability might seem constraining, but constraints can liberate you by allowing you to rely on particular behaviors. Elixir doesn\u0026rsquo;t let you modify things in-place, but you can rely on this, which makes understanding and composing code easier. Haskell forces you to express side-effects in the type system, but this lets you know that calling a function with a signature like String → Int won\u0026rsquo;t do any IO or throw an exception. Rust doesn\u0026rsquo;t have null like in Java, but you know when you get a pointer, you can safely dereference it and you don\u0026rsquo;t have to do all the null checking that you have to do in Java.\nCase study: macros in Lisp, Scheme, and Racket # The evolution of syntax macros in Lisp, Scheme, and Racket provide an interesting real-world instance of how safety and power can start off as a trade-off, but with better language design, become complimentary.\nLisp macros: unsafe but powerful # I don\u0026rsquo;t have the space here to do a deep dive into Lisp macros, but here\u0026rsquo;s the short of it: Lisp macros are just functions that receive code as data. This code is represented as nested lists of symbols. All a macro needs to do is return a new list of symbols that will be spliced right into the call site.\n(defmacro my-or (thing1 thing2) `(let ((tmp ,thing1)) (if tmp tmp ,thing2))) ;; calling the macro (my-or 1 2) ;; expands to (let ((tmp 1)) (if tmp tmp 2)) ;=\u0026gt; 1 The problem with this is that these macros are unhygienic: if I introduce a new variable, as I did with tmp in my-or, that is just a bare symbol that can be inadvertently captured producing unexpected output:\n(let ((tmp 99)) (my-or nil tmp)) ;; expands to (let ((tmp 99)) (let ((tmp nil)) (if tmp tmp tmp))) ;=\u0026gt; nil This is very bad! To use a macro safely, you need to be sure that it\u0026rsquo;s not introducing variables that you might accidentally capture. Lisp provides a mechanism Lisp has a function called gensym which makes a fresh symbol for you to use. Some other languages such as Julia have a gensym function; gensym is a poor substitute for proper hygiene. to avoid some of the pitfalls with variable capture, but that\u0026rsquo;s not the end of the danger. If I have a macro that expands to a call to a function, e.g. printf, I would expect this to be the printf in scope at the time I defined the macro. However, this might not be the case—a user might inadvertently redefine a function, and then the macro would not behave in the expected way.\nScheme macros: safe but less powerful # Scheme has a faculty called syntax-rules, which lets you define transformations between a pattern and a template:\n(define-syntax my-or (syntax-rules () ((_ thing1 thing2) (let ((tmp thing1)) (if tmp tmp thing2))))) Rust\u0026rsquo;s macro_rules! form is essentially syntax-rules from Scheme, but a little fancier with some syntax classes like :expr and such.\nThis is safe; the examples from the Lisp run as expected:\n(my-or 1 2) ;=\u0026gt; 1 (my-or #f 42) ;=\u0026gt; 42 (let ((tmp 99)) (my-or #f tmp)) ;=\u0026gt; 99 However, we\u0026rsquo;ve lost some of the power because we can only define transformations between templates. We can\u0026rsquo;t, for example, write a macro that does some deep inspection of the code and makes decisions on how to expand. Furthermore, there\u0026rsquo;s no way for us to intentionally break hygiene when we really want to.\nRacket macros: the best of both worlds # Racket resolves the dilemma between having to choose between powerful Lisp-like procedural macros, and safe Scheme-like hygienic macros by giving us fully hygienic procedural macros! I have another blog post discussing macros in Lisp, Scheme, and Racket and I go into some detail about the evolution of those macro systems.\nAnd if you want to dive deep into macro hygiene, see Matthew Butterick\u0026rsquo;s excellent explainer on Hygiene from his book Beautiful Racket.\nThe upshot of it is that Racket uses a combination of features (scope sets, syntax objects, etc.) to give the user a richer way of specifying syntax than simple dumb lists of symbols. This avoids inadvertent variable capture as well as keeps function references lined up nicely. However, macros can still do arbitrary computation, which means that we\u0026rsquo;re not constrained in the way that the pattern-transformation macros in Scheme are.\nAnd just to prove that Racket is just as powerful as Common Lisp, here\u0026rsquo;s the classic aif macro:\n#lang racket (require racket/stxparam syntax/parse/define) (define-syntax-parameter it (lambda (stx) (raise-syntax-error (syntax-e stx) \u0026#34;can only be used inside aif\u0026#34;))) (define-syntax (aif stx) (syntax-parse stx [(_ test tcase fcase) #\u0026#39;(let ([tmp test]) (if tmp (syntax-parameterize ([it (make-rename-transformer #\u0026#39;tmp)]) tcase) fcase))])) (aif 41 (+ it 1) \u0026#39;whatever) ;=\u0026gt; 42 it ;error: it: can only be used inside aif This example is inspired by Greg Hendershott\u0026rsquo;s fabulous tutorial Fear of Macros. The define-syntax-parameter bit lets us introduce new bindings intentionally, whilst still keeping us from accidental breaches of macro hygiene.\nConsequentially, Racket\u0026rsquo;s macro system is far more useful than Lisp or Scheme\u0026rsquo;s systems, and this because of Racket\u0026rsquo;s safety and expressiveness. You can actually build trustworthy systems on top of Racket\u0026rsquo;s macro system because you\u0026rsquo;re not constantly foot-gunning yourself with hygiene malfunctions, and the macros are expressive enough to do some rather complicated things.\nTowards greater safety and reliability # Safe systems let us build software that is more capable and more reliable. Unsafe power is something to improve, not grudgingly accept—and much less defend as somehow desirable. Languages like Rust and Zig have made systems programming immune to whole hosts of errors by being more expressive than C, and languages like Racket are leading the way in making metaprogramming more useful reliable and less like dark magic.\nFurther reading # If you want to learn more about writing macros in Racket, check out Beautiful Racket by Matthew Butterick and Fear of Macros by Greg Hendershott.\nI highly recommend listening Runar Bjarnason\u0026rsquo;s talk at Scala World, Constraints Liberate, Liberties Constrain, wherein he discusses how constraining one part of a system can open up freedoms of later components that build on that constrained part.\n"},{"id":6,"href":"/posts/2024-10-22_bf_writeup/","title":"Towards the Fastest Brainf*** Implementation Ever","section":"Technical Blog","content":"In my last post I described how I made a very fast BF interpreter. Well, there\u0026rsquo;s a lot more speed to be had with an optimizing compiler. This post is a write-up of my assignment for a compilers class, so the post a little rougher than normal.\nYou can find the code at the following places:\nGitHub repo Codeberg repo Code organization # Files for the compiler:\ninterp_threaded_opt.rkt BF parser and all optimizations live here. native.rkt Takes the optimized AST from interp_threaded_opt.rkt and emits native ARM instructions for my M1 Pro chip. interp_threaded_opt.rkt # The first role of this module is to define an AST for BF. My AST is represented as Racket structs; these are the nodes that I have:\nNode Fields Comment loop body Loops hold their entire body within them. There is a parsing pass to the code that matches all [ ] characters. add amount Sequences of + or - get smooshed together into single add instructions. shift amount Like add, but for \u0026gt; and \u0026lt; set-cell value Set the current cell to a specific value. Used to optimize [-] and the like. bf-write bf-read add-cell-0 dest Zero current cell; add old value to another cell. This is a common loop that I recognized and optimized. mult-block-0 body Result of optimizing simple loops. Body is a map from tape offset → value. search-0 stride Representation of scan loops like [\u0026lt;\u0026lt;\u0026lt;\u0026lt;]. The rest of the module is devoted to optimizations performed on the AST. Initially, only loop, add, shift, bf-write, and bf-read cells are present, but through the optimization passes more get added. See § Optimizations for details on all the optimization passes.\nThere is a compile function, but this just compiles the optimized AST down to Racket closures with a threaded interpreter.\nnative.rkt # The main entry point is the compile-to-asm function, which emits some fixed prelude code, the body of the program, and then some fixed postlude code.\nThere are a bunch of functions prefixed with i/; these are to help me generate assembly instructions with a particular format. Mostly just wrappers around calls to format.\nThe emit-asm function does the hard work of walking the AST and generating instructions for each node. There\u0026rsquo;s a loose set of conventions around various registers; the most important is that x20 always holds the address of the start of the tape, and x21 holds the current pointer. I never use these registers for anything else; you can always access the current value under the program head with [x20, x21].\nThere are two special functions for emitting the assembly for search-0 nodes: one for forward scans ([\u0026gt;]) and one for backward scans ([\u0026lt;]). This is just done for organizational convenience.\nOptimizations # The entry point to optimizing the BF AST is in the optimize function in interp_threaded_opt.rkt. This chains optimizations together; each optimization function must take a whole program AST and return a whole program AST functionally. The optimizations are in order they are performed:\ncombine-instrs\nThis pass takes sequences of instructions like +++, initially represented with (list (add 1) (add 1) (add 1)) and turns it into (add 3). Same thing for pointer shift instructions.\nopt/useless\nThis cleans up instructions like (shift 0) or (add 0) that have no effect.\nopt/add\nThis recognizes patterns like [\u0026gt;+\u0026lt;-], which adds the value of one cell to another. It handles arbitrary shift and add amounts, as long as they\u0026rsquo;re balanced. Kind of like a baby opt/basic-loop pass.\nopt/zero-out\nHandles cases of [-] or [+] to set the cell to 0.\nopt/basic-loop\nDoes the basic loop optimization we discussed in class. Easily the most complicated optimization. It abstractly evaluates the body of a loop; it sets the initial pointer to 0 and tracks what additions go to which offsets. Bails out if anything gets too complicated.\nopt/zero-add-\u0026gt;set\nOptimizes cases of [-]+++ to just set the current cell value to 3.\nopt/0-scan\nScan loops, as discussed in class.\nEvaluation # Extensive tests (bfcheck.pl) # I precompiled and ran all the files in the check/ folder provided. I noticed that the first run of the resulting binaries took a long time, and that they all ran almost instantly afterwards. I noticed that there was a bunch of network activity; seems like macOS was being zealous in sending signatures for each of the binaries the first time they were run. The benchmarks run quickly, so this added up. The numbers reported here are after running the tests one time to avoid the network penalty.\nOptimization set Total time (seconds) No optimizations 0.763064 Basic loops 0.767731 Scan loops 0.790222 Scan \u0026amp; basic loops 0.763272 There\u0026rsquo;s not a whole lot of variance.\nBenchmarks (mandel.b, etc.) # I ran my compiler on some of the benchmarks from the BF benchmarks suite we\u0026rsquo;ve been using. I also tried out a few with the cgbfi.b BF-interpreter-in-BF.\nTable 1: Execution times for two benchmarks, natively compiled. All times in seconds. Benchmark No opts Basic loops Scan loops Scan \u0026amp; basic loops hanoi.b 0.11 0.05 0.11 0.05 mandel.b 0.73 0.49 0.73 0.49 Seems that basic loop optimization is most important for the Hanoi and Mandelbrot benchmarks. I also tried the Sierpinski triangle benchmark but it never ran long enough for me to notice any difference.\nContrast with benchmarks running under the cgbfi.b interpreter: scan loops are far and away the most important optimization:\nTable 2: Execution times for benchmarks running under the cgbfi.b interpreter. All times in seconds. *Gave up after 2 hours; estimated duration recorded. †No attempt. Benchmark No opts Basic loops Scan loops Scan \u0026amp; basic loops serptri.b 0.07 0.06 0.03 0.02 mandel.b *44,052.00 † † 7,818.96 Example optimizations # Basic loops # This code:\n+++[-\u0026gt;+\u0026gt;-\u0026lt;\u0026lt;] Gets optimized to this:\nldrsb w11, [x20, x21] ; add 3 add w11, w11, #3 strb w11, [x20, x21] add x22, x20, x21 ; mult-block-0 ldrsb x23, [x22] add x24, x22, #1 ldrsb x25, [x24] mov x11, x23 add w11, w25, w11 strb w11, [x24] add x24, x22, #2 ldrsb x25, [x24] mov x11, x23 subs w11, w25, w11 strb w11, [x24] strb wzr, [x20, x21] Any loop with I/O or nested loops—even something like setting something to 0 are not covered by this.\nScan loops # This code:\n[\u0026gt;\u0026gt;\u0026gt;\u0026gt;] Gets optimized to this:\nadrp x22, lIDX@PAGE ; search-0 ldr q0, [x22, lIDX@PAGEOFF] ; v0 = idx vector adrp x22, lSTRIDE4@PAGE ldr q3, [x22, lSTRIDE4@PAGEOFF] ; v3 = stride mask movi.2d v1, #0 ; v1 = zero vect subs x21, x21, #16 LBB0_0: add x21, x21, #16 add x22, x20, x21 ld1 {v2.16b}, [x22] ; v2 = tape cmeq.16b v4, v2, v1 ; v4 = tape == zeros and.16b v4, v4, v3 ; mask with stride orn.16b v4, v0, v4 ; idx or !(tape == zeros) uminv.16b b5, v4 ; find smallest idx umov w22, v5.b[0] subs w11, w22, #255 beq LBB0_0 add x21, x21, x22 The first few lines load up the 0 and stride mask vectors.\nThe only strides I optimize are 1, -1, 2, -2, 4, -4, 8, and -8. At stride 16, you\u0026rsquo;re only getting one check per loop; might as well just do the basic iteration instead of firing up the vector unit.\n"},{"id":7,"href":"/posts/2024-09-27_threaded_interpreter/","title":"How to Make Racket Go (Almost) As Fast As C","section":"Technical Blog","content":"I recently wrote about using first-class functions to help make a BF interpreter. This is a follow-up post to describe a nifty solution to a tricky problem that made my program go 2–5× faster and put it about on-par with an interpreter written in pure C.\nA basic interpreter works by walking down the AST and evaluating nodes recursively: when the interpreter encounters an expression, it dispatches on the type of expression to decide how to perform the evaluation. Here\u0026rsquo;s the key insight to get a massive speed bump with very little effort: that dispatch is expensive and can be performed ahead-of-time. We can walk through the code once and precompute all the dispatching work.\nThis is not a new idea. The first description that I\u0026rsquo;m aware of comes from Feeley and Lapalme [1]. A name for this technique is making a threaded interpreter. It\u0026rsquo;s nowhere near as fast as a native code compiler, but interpreters are easy to write, and this is a very simple way to get a very big boost in performance.\nA basic interpreter # Please see the appendix for the full code for this interpreter. Tested to run with Racket v8.14 [cs].\nHere\u0026rsquo;s a simple language and a (simplified) interpreter:\n;; Syntax description (struct func (params body) #:transparent) (struct app (fn-expr args) #:transparent) (struct op (op-name arg1 arg2) #:transparent) (struct if-expr (test-expr t-case f-case) #:transparent) ;; Closure values (struct closure (params body env) #:transparent) ;; Core interpreter routine (define (interpret expr env) (match expr ;; Literal values: booleans and numbers evaluate to themselves [(or (? number?) (? boolean?)) expr] ;; Look up variables in the environment [(? symbol? var-name) (lookup-env env var-name)] ;; Evaluating a function expression yields a closure value [(func params body) (closure params body env)] ;; Application: evaluate the function expression to get a closure. ;; Next, evaluate the arguments, and then extend the environment ;; and evaluate the body of the closure. [(app fn-expr args) (let ([fn (interpret fn-expr env)] [eval-args (map (λ (e) (interpret e env)) args)]) (interpret (closure-body fn) (extend-env env (closure-params fn) eval-args)))] ;; Built-in operators [(op op-name a1 a2) (let ([arg1 (interpret a1 env)] [arg2 (interpret a2 env)]) (case op-name [(+) (+ arg1 arg2)] [else (error \u0026#34;Undefined operator!\u0026#34;)]))] ;; Conditionals [(if-expr test tcase fcase) (if (interpret test env) (interpret tcase env) (interpret fcase env))])) We can now build and run simple programs:\n(interpret (app (func \u0026#39;(x) (op \u0026#39;+ \u0026#39;x 1)) (list 41)) \u0026#39;()) ;; =\u0026gt; 42 There is nothing particularly special about this interpreter: there\u0026rsquo;s a basic representation for programs, and the interpret function walks the AST recursively to evaluate the program.\nThreading the environment # To make this interpreter go faster, we need bypass the match statement by pre-computing the code to run. We can do this by building up a closure that calls the next thing to run in tail-position. Racket has a proper tail-call optimization, so function calls in tail position will be optimized to jump instructions and they won\u0026rsquo;t grow the stack. Having known jump targets is also really good for modern CPUs which do speculative execution; known jump targets means no branch mis-predictions.\nWe do this by breaking up the interpret function: instead of taking an expression and an environment, we want a function that just takes an expression. This should return a function that we can give an environment, which will the compute the value of the program. We will call this new function compile.\n(define (compile expr) (match expr [(or (? number?) (? boolean?)) (λ (env) expr)] [(? symbol? var-name) (λ (env) (lookup-env env var-name))] [(func params body) (let ([comp-body (compile body)]) (λ (env) (closure params comp-body env)))] [(app fn-expr args) (let ([fn (compile fn-expr)] [comp-args (map compile args)]) (λ (env) (let ([c (fn env)]) ((closure-body c) (extend-env env (closure-params c) (map (λ (a) (a env)) comp-args))))))] [(op op-name a1 a2) (let ([arg1 (compile a1)] [arg2 (compile a2)]) (case op-name [(+) (λ (env) (+ (arg1 env) (arg2 env)))] [(-) (λ (env) (- (arg1 env) (arg2 env)))] [(*) (λ (env) (* (arg1 env) (arg2 env)))] [(/) (λ (env) (/ (arg1 env) (arg2 env)))] [(\u0026lt;) (λ (env) (\u0026lt; (arg1 env) (arg2 env)))] [(\u0026gt;) (λ (env) (\u0026gt; (arg1 env) (arg2 env)))] [(=) (λ (env) (= (arg1 env) (arg2 env)))] [else (error \u0026#34;Undefined operator!\u0026#34;)]))] [(if-expr test tcase fcase) (let ([comp-test (compile test)] [comp-tcase (compile tcase)] [comp-fcase (compile fcase)]) (λ (env) (if (comp-test env) (comp-tcase env) (comp-fcase env))))])) Note how the code follows the same structure as the basic interpreter, but the return type has changed: instead of a value, you get a function in the form of (λ (env) …). Also, instead of calling interpret on subexpressions, you call compile, and pass the environment to those subexpressions to get the value out.\nThere\u0026rsquo;s a lot more that we could here to improve things. The easiest thing would be to track where variables will be in the environment and optimize variable lookups with direct jumps into the environment structure. This saves us from having to walk the environment linearly on every variable lookup. I won\u0026rsquo;t implement that here, but that\u0026rsquo;s some pretty low-hanging fruit.\nThe tricky part of BF: mutual recursion # So, we get a lot of oomph by turning everything into tail calls. But loops (which, in BF, are the only branching mechanism) present a tricky problem: you either need to call the function that encodes the loop body repeatedly or call the function that encodes whatever comes after the loop. Moreover, once the loop body is done, it needs to jump back to the first function that encodes the choice of whether to keep going in the loop or exit.\nHere\u0026rsquo;s my compile function for my basic threaded interpreter for BF:\n(define (compile program c-ip jmp-targets inst-cache) (if (\u0026lt; c-ip (vector-length program)) (match (vector-ref program c-ip) [#\\+ (let ([rest-progn (compile program (+ 1 c-ip) jmp-targets inst-cache)]) (λ (state sp) (vector-set! state sp (+ (vector-ref state sp) 1)) (rest-progn state sp)))] [#\\- (let ([rest-progn (compile program (+ 1 c-ip) jmp-targets inst-cache)]) (λ (state sp) (vector-set! state sp (- (vector-ref state sp) 1)) (rest-progn state sp)))] [#\\\u0026gt; (let ([rest-progn (compile program (+ 1 c-ip) jmp-targets inst-cache)]) (λ (state sp) (rest-progn state (+ sp 1))))] [#\\\u0026lt; (let ([rest-progn (compile program (+ 1 c-ip) jmp-targets inst-cache)]) (λ (state sp) (rest-progn state (- sp 1))))] [#\\. (let ([rest-progn (compile program (+ 1 c-ip) jmp-targets inst-cache)]) (λ (state sp) (display (integer-\u0026gt;char (vector-ref state sp))) (rest-progn state sp)))] [#\\, (let ([rest-progn (compile program (+ 1 c-ip) jmp-targets inst-cache)]) (λ (state sp) (vector-set! state sp (char-\u0026gt;integer (read-char))) (rest-progn state sp)))] [(jmp-forward target) (letrec ([loop-start (λ (state sp) (if (zero? (vector-ref state sp)) (loop-end state sp) (loop-body state sp)))] [loop-past-end (compile program (+ c-ip target 1) jmp-targets inst-cache)] [loop-end (compile program (+ c-ip target) (cons loop-start loop-past-end) inst-cache)] [loop-body (compile program (+ 1 c-ip) null inst-cache)]) loop-start)] [(jmp-backward _) (λ (state sp) (if (zero? (vector-ref state sp)) ((cdr jmp-targets) state sp) ((car jmp-targets) state sp)))]) (λ (_state _sp) ; finished compiling program void))) I match on each of the characters of the program. In my interpreter I do a little bit of preprocessing to turn [ and ] into jmp-forward and jmp-backward structs respectively. That way, I don\u0026rsquo;t have to spend a ton of time scanning the program for matching brackets.\nThe interesting bit is the clause for the jmp-forward construct: to build the closure I need at a loop-start, I need to be able to refer to the loop body (computed and stored in loop-body) as well as the end of the loop (computed and stored in loop-end).\nWhen I build the loop-end closure, pass loop-start and loop-past-end (which is the rest of the program after the loop) into the compile function as the jmp-targets parameter. When the compiler encounters the matching jmp-backward instruction, it uses the jmp-targets parameter to get the loop-start and loop-past-end to decide whether or not to redo the loop or not.\nI\u0026rsquo;ve since improved this code, and now the zero? check only happens once. I also parse the program so that every instruction gets turned into a struct—rather than left as a bare character. See interp_threaded_opt.rkt in my Brainfreeze repo for the current version.\nThe loop-start and loop-end functions need to reference each other to be able to continue or abort the loop. letrec lets me build functions that can reference each other in a clean, functional way.\nLet\u0026rsquo;s see some numbers! # So how much faster does threading make the code go? Here is a BF program that renders a Mandelbrot set. I can run this with my basic and my threaded interpreter on my M1 Pro MacBook Pro to get an idea:\nracket interp_basic.rkt bench/benches/mandel.b 43.25s user 0.77s system 93% cpu 47.138 total racket interp_threaded.rkt bench/benches/mandel.b 17.62s user 0.38s system 92% cpu 19.461 total 43.25 seconds vs 17.62 seconds is a big difference! That\u0026rsquo;s a solid 2× speedup! This actually put my threaded Racket interpreter on par with a C-based threaded interpreter that one of my classmates built and ran with the same benchmarks. If I recall, his was only about a second or two faster.\nThe compile step opens up a big opportunity for optimizations. I\u0026rsquo;ve been working on some domain-specific optimizations for BF and my interpreter can run the same benchmark in a blazing 9.94 seconds.\nracket runner.rkt bench/benches/mandel.b 9.94s user 0.18s system 94% cpu 10.707 total (And, of course, none of this really holds a candle to a proper compiler; I\u0026rsquo;ve to a compiler that takes the optimized code from the threaded interpreter and emits machine code. It can run mandel.b in a mere 0.5 seconds!)\nI hope you take away a few things from this post:\nProper tail-calls make stuff go fast. If your language supports proper tail-call optimization, take advantage of it.\nRacket is really good for writing interpreters and compilers! You can get very fast performance in the comfort of a high-level garbage-collected functional programming language.\nRacket will never be able to match the best-written C code in terms of speed. But Racket is far easier to debug and a lot more fun to write—and for a lot of applications, Racket is still more than fast enough.\nA bad day writing code in Scheme is better than a good day writing code in C.\nDavid Stigant\nAppendix: Full code for basic interpreter # #lang racket ;; Syntax description (struct func (params body) #:transparent) (struct app (fn-expr args) #:transparent) (struct op (op-name arg1 arg2) #:transparent) (struct if-expr (test-expr t-case f-case) #:transparent) ;; Closure values (struct closure (params body env) #:transparent) ;; Environment helpers (define (extend-env base-env vars vals) (foldl (λ (var val env-acc) (cons (cons var val) env-acc)) base-env vars vals)) (define (lookup-env env var) (match (assoc var env) [(cons _ val) val] [#f (error \u0026#34;Undefined variable!\u0026#34;)])) ;; Core interpreter routine (define (interpret expr env) (match expr [(or (? number?) (? boolean?)) expr] [(? symbol? var-name) (lookup-env env var-name)] [(func params body) (closure params body env)] [(app fn-expr args) (let ([fn (interpret fn-expr env)] [eval-args (map (λ (e) (interpret e env)) args)]) (interpret (closure-body fn) (extend-env env (closure-params fn) eval-args)))] [(op op-name a1 a2) (let ([arg1 (interpret a1 env)] [arg2 (interpret a2 env)]) (case op-name [(+) (+ arg1 arg2)] [(-) (- arg1 arg2)] [(*) (* arg1 arg2)] [(/) (/ arg1 arg2)] [(\u0026lt;) (\u0026lt; arg1 arg2)] [(\u0026gt;) (\u0026gt; arg1 arg2)] [(=) (= arg1 arg2)] [else (error \u0026#34;Undefined operator!\u0026#34;)]))] [(if-expr test tcase fcase) (if (interpret test env) (interpret tcase env) (interpret fcase env))])) Appendix: Full code for threading interpreter # #lang racket ;; Syntax description (struct func (params body) #:transparent) (struct app (fn-expr args) #:transparent) (struct op (op-name arg1 arg2) #:transparent) (struct if-expr (test-expr t-case f-case) #:transparent) ;; Closure values (struct closure (params body env) #:transparent) ;; Environment helpers (define (extend-env base-env vars vals) (foldl (λ (var val env-acc) (cons (cons var val) env-acc)) base-env vars vals)) (define (lookup-env env var) (match (assoc var env) [(cons _ val) val] [#f (error \u0026#34;Undefined variable!\u0026#34;)])) ;; Threading interpreter (define (compile expr) (match expr [(or (? number?) (? boolean?)) (λ (env) expr)] [(? symbol? var-name) (λ (env) (lookup-env env var-name))] [(func params body) (let ([comp-body (compile body)]) (λ (env) (closure params comp-body env)))] [(app fn-expr args) (let ([fn (compile fn-expr)] [comp-args (map compile args)]) (λ (env) (let ([c (fn env)]) ((closure-body c) (extend-env env (closure-params c) (map (λ (a) (a env)) comp-args))))))] [(op op-name a1 a2) (let ([arg1 (compile a1)] [arg2 (compile a2)]) (case op-name [(+) (λ (env) (+ (arg1 env) (arg2 env)))] [(-) (λ (env) (- (arg1 env) (arg2 env)))] [(*) (λ (env) (* (arg1 env) (arg2 env)))] [(/) (λ (env) (/ (arg1 env) (arg2 env)))] [(\u0026lt;) (λ (env) (\u0026lt; (arg1 env) (arg2 env)))] [(\u0026gt;) (λ (env) (\u0026gt; (arg1 env) (arg2 env)))] [(=) (λ (env) (= (arg1 env) (arg2 env)))] [else (error \u0026#34;Undefined operator!\u0026#34;)]))] [(if-expr test tcase fcase) (let ([comp-test (compile test)] [comp-tcase (compile tcase)] [comp-fcase (compile fcase)]) (λ (env) (if (comp-test env) (comp-tcase env) (comp-fcase env))))])) ;; compute 42 (define p1 (app (func \u0026#39;(a) (op \u0026#39;+ \u0026#39;a 1)) \u0026#39;(41))) References # [1]Feeley, M. and Lapalme, G. 1987. Using closures for code generation. Computer languages. 12, 1 (Jan. 1987), 47–66. DOI:https://doi.org/10.1016/0096-0551(87)90012-9. "},{"id":8,"href":"/posts/2024-09-26_resist_surveillance/","title":"Why You Should Resist Surveillance","section":"Technical Blog","content":"I got to visit the Stasi museum in Berlin this week, and it gave me a newfound appreciation for why it\u0026rsquo;s important to resist surveillance. Interestingly, surveillance is not exclusively limited to one kind of government: it can appeal to both left- and right-wing governments, and corporations in the digital age use surveillance to make money. In every form, surveillance is evil and must be resisted.\nStasi = Abbreviation of Stadt Sicherheit (\u0026ldquo;state security\u0026rdquo; in German).\nFor those of you who don\u0026rsquo;t know, the Stasi were the secret police of the communist regime in East Germany. They employed massive resources to spy upon and surveil East German citizens, and they kept careful track of anyone who showed signs of dissatisfaction with the state. They employed massive numbers of informal collaborators—mere citizens—who would spy on their neighbors and report back to the Stasi.\nI got to go there with my dad, and he remarked on how much of a drag on the economy the Stasi must have been. Think of it: the country funneled incredibly vast resources into spying on its own citizens and for what? It was claimed to be a protection against domestic terrorists and the like, but in reality, the Stasi was oppressing and discouraging anyone who might be disgruntled with those in power and the way they were running things.\nThe Stasi were nominally there to ensure the security of the state. In reality they were ensuring the security of the regime.\nThis is such an important distinction! A state has a legitimate interest in protecting its own citizens from terrorism and preventing criminal activity. But a democratic government must never instill fear in its citizens because of their opinions with how things should change. For a democracy to work the only legitimate way to obtain the consent of the governed is if they can think express their ideas, frustrations, and concerns freely. (In a proper non-violent manner, of course.)\nSurveillance suppresses free thought.\nThink about it: if you know that you will be quizzed on something, you will pay better attention to what is being taught. If you know that your actions are being watched by someone who has the ability to influence your life, you start to change your behavior. Remember, there are people who, if they don\u0026rsquo;t like you, can make your life miserable. Imagine what detailed, personal knowledge enables for people who don\u0026rsquo;t like the categories you fit into:\nThe owner of an HOA who doesn\u0026rsquo;t like your political leanings goes to excessive lengths to fine you for minor infractions.\nAn insurance agency illegally profiles you and considers you higher risk for their portfolio because of some underlying health conditions and life circumstances you are in. They then find ways to decline service or coverage when you need it most.\nSomeone is elected to office. He knows you didn\u0026rsquo;t vote for him, so he puts pressure through back channels to slow down or prevent you from getting the services you need. Now, for example, you can\u0026rsquo;t travel internationally to visit your family because your file is marked for some reason and you\u0026rsquo;re fighting a Kafkaesque process to clear it up.\nA company uses your internet browsing history to profile your interests, fears, and hopes. They use sophisticated artificial intelligence to craft social media feeds crafted to be highly addicting to you. They erode your self-discipline so that they can make some more money.\nSurveillance is the means why which massive control is enabled. If you care about protecting your freedom and your agency, resist surveillance—whether it be by a government or a corporation. They may say that it\u0026rsquo;s in your own best interest: to make you safer or to serve up content that is catered to your tastes, but they are lying. It is all done in self-interest: to protect their regime or to turn their profits—all at your expense.\nTake your privacy back. Visiting the EFF is a great way to get started.\n"},{"id":9,"href":"/posts/2024-09-11_parameterized_decisions/","title":"First-Class Helper Functions","section":"Technical Blog","content":"We\u0026rsquo;re going to be writing a BF compiler for a class I\u0026rsquo;m in. Last night I threw together a little interpreter for the program in about an hour; it doesn\u0026rsquo;t do input—that should be easy to add—but it\u0026rsquo;s enough to handle some benchmarks for the language, albeit slowly. You can see my repository on Codeberg for the source code.\nI needed one function to do two closely related jobs—the logic was identical, but some parameters needed to change. Fortunately, first-class functions in your language make it trivial to parameterize your programs in elegant ways.\nFor those unfamiliar, a BF program looks like this:\n++++++++++[\u0026gt;+++++++\u0026gt;++++++++++\u0026gt;+++\u0026gt;+\u0026lt;\u0026lt;\u0026lt;\u0026lt;-]\u0026gt;++.\u0026gt;+.+++++++..+++.\u0026gt;++.\u0026lt;\u0026lt;+++++++++++++++.\u0026gt;.+++.------.--------.\u0026gt;+.\u0026gt;. That program prints Hello, World!. Here\u0026rsquo;s the spec for the language, taken from this repo:\n\u0026gt; move the pointer right \u0026lt; move the pointer left + increment the current cell - decrement the current cell . output the value of the current cell , replace the value of the current cell with input [ jump to the matching ] instruction if the current value is zero ] jump to the matching [ instruction if the current value is not zero Basically, BF is a little Turing machine: you have a big array of memory and a pointer into that array. The commands move the pointer around and can set or check the value pointed at.\nThe [ and ] characters form loops and need to be balanced. In my interpreter I wanted to run a preprocessing step so that when I encountered a [ or a ] I would know how far to jump instead of having to search the program for the matching bracket. Here\u0026rsquo;s the top-level function to modify the program vector to replace [ and ] with a struct containing how far to jump:\n(struct jmp (amount) #:transparent) (struct jmp-forward jmp () #:transparent) ; replaces a [ command (struct jmp-backward jmp () #:transparent) ; replaces a ] command (define (preprocess-loops! prog) (for ([i (in-range (vector-length prog))]) (match (vector-ref prog i) [#\\[ (vector-set! prog i (find-matching prog i 1 \u0026#39;close))] [#\\] (vector-set! prog i (find-matching prog i -1 \u0026#39;open))] [_ 42]))) That find-matching function was a little tricky: in the case of searching for a ] it would have to walk forward looking for a ] character or a (jmp-backward …) struct, and it would have to walk backward looking for a [ character or (jmp-forward …) struct. The naïve way to do this would be to have a bunch of if expressions dispatching on the 'close or 'open passed to find-matching:\n(define (find-matching prog start offset kind [stack 0]) (let* ([addr (+ start offset)] [current-instr (vector-ref prog addr)]) (if (eq? kind \u0026#39;close) (if (or (eqv? current-instr #\\]) (jmp-backward? current-instr)) (if (zero? stack) (jmp-forward offset) (find-matching prog start (+ 1 start) kind (- stack 1))) ; this isn\u0026#39;t our close ] (if (or (eqv? current-instr #\\[) (jmp-forward? current-instr)) (find-matching prog start (+ 1 start) kind (+ stack 1)) ; deepen stack because we found another [ (find-matching prog start (+ 1 start) kind stack))) (if (or (eqv? current-instr #\\[) (jmp-forward? current-instr)) (if (zero? stack) ...) (if (or (eqv? current-instr #\\]) (jmp-backward? current-instr)) ... ...))))) The need for a stack to find matching delimiters should be pretty obvious: if I have an open bracket [ and am looking for the matching close bracket ], then I need to make sure I don\u0026rsquo;t get confused by other open-close pairs in between.\nThe function above is pretty clunky: all the logic for checking if the stack is empty gets duplicated, and the logic for adding/decrementing the stack is a mirror image between the two branches of if (eq? kind 'close). There might be a few ways to rearrange this example so that it\u0026rsquo;s a little better, but there\u0026rsquo;s one big change we can make.\nThe key insight is this: we have first-class functions, so why not parameterize the condition we use to check the current command to know if we should push the stack, pop the stack, or return a new struct? Here\u0026rsquo;s how we do it:\n(define (find-matching prog start offset kind [stack 0]) (define (close? x) (or (jmp-backward? x) (eqv? x #\\]))) (define (open? x) (or (jmp-forward? x) (eqv? x #\\[))) (define addr (+ start offset)) (let-values ([(needle-pred other-pred bump jmp-maker) (if (eq? kind \u0026#39;close) (values close? open? 1 jmp-forward) (values open? close? -1 jmp-backward))]) (if (needle-pred (vector-ref prog addr)) (if (zero? stack) (jmp-maker offset) (find-matching prog start (+ bump offset) kind (- stack 1))) (if (other-pred (vector-ref prog addr)) (find-matching prog start (+ bump offset) kind (+ stack 1)) (find-matching prog start (+ bump offset) kind stack))))) Now we have needle-pred, which returns true if the current command is the current thing we\u0026rsquo;re looking for; other-pred, which tells us if we need to increase the stack; bump, which just tells us which way to move the offset; and jmp-maker which we use to build the right kind of struct to return when we\u0026rsquo;ve found the matching delimiter and the stack is empty.\nI really like that let-values lets me bind a bunch of variables on a single condition; other languages can do something similar if they have e.g. tuples and rich pattern matching.\nFirst-class functions are a powerful way to parameterize your code, and it doesn\u0026rsquo;t just have to be with higher-order functions. Clearly, generic functions like map and filter would be basically useless without the ability to take functions as parameters. But you can also tailor the behavior of your program by pushing the differences between two or more possible scenarios into functions, and then select the proper set of functions in one conditional.\n"},{"id":10,"href":"/posts/2024-08-19_fancy_eshell_prompt/","title":"Fancy lightweight prompts for Eshell and Zsh","section":"Technical Blog","content":"I started using the Zsh a few years ago and I\u0026rsquo;ve liked its completion features. I tried out Oh-my-zsh for a while and I liked the stock Robby Russel prompt. It gave me all the information I cared about: the status of the last command, current directory, and the state of the current Git repository.\nHowever, I didn\u0026rsquo;t like how slow Oh-my-zsh was making my shell startup. This mattered especially, I think, because my Emacs config would fire up a shell on startup to read the ENV so it could configure some language servers properly. Irked at how long stuff was taking, I set out to build my own.\nFancy Zsh prompt, no extra packages needed # Here\u0026rsquo;s the code for my Zsh prompt:\n# This is important to make some things play nicely with Emacs. # They\u0026#39;re not critical to the shell prompt per se, but I think they\u0026#39;re # pretty useful. # Bail out of rest of setup if we\u0026#39;re coming in from TRAMP [[ $TERM == \u0026#34;dumb\u0026#34; ]] \u0026amp;\u0026amp; unsetopt zle \u0026amp;\u0026amp; PS1=\u0026#39;$ \u0026#39; \u0026amp;\u0026amp; return [ -n \u0026#34;$EAT_SHELL_INTEGRATION_DIR\u0026#34; ] \u0026amp;\u0026amp; source \u0026#34;$EAT_SHELL_INTEGRATION_DIR/zsh\u0026#34; # This tells the shell to expand the call to $(git_prompt_info) setopt PROMPT_SUBST # This is a function that gathers information about the current HEAD. # It will show the name of the branch if there is one, otherwise the # short hash of the currently checked-out commit. git_prompt_info () { local ref ref=$(git symbolic-ref HEAD 2\u0026gt; /dev/null) || ref=$(git rev-parse --short HEAD 2\u0026gt; /dev/null) || return 0 local STATUS local -a FLAGS FLAGS=(\u0026#39;--porcelain\u0026#39;) if [[ \u0026#34;${DISABLE_UNTRACKED_FILES_DIRTY:-}\u0026#34; == \u0026#34;true\u0026#34; ]] then FLAGS+=\u0026#39;--untracked-files=no\u0026#39; fi case \u0026#34;${GIT_STATUS_IGNORE_SUBMODULES:-}\u0026#34; in (git) ;; (*) FLAGS+=\u0026#34;--ignore-submodules=${GIT_STATUS_IGNORE_SUBMODULES:-dirty}\u0026#34; ;; esac STATUS=$(git status ${FLAGS} 2\u0026gt; /dev/null | tail -n1) if [[ -n $STATUS ]] then echo \u0026#34; %F{red}[%F{yellow}${ref#refs/heads/}%F{red}]%f\u0026#34; else echo \u0026#34; %F{green}(%F{yellow}${ref#refs/heads/}%F{green})%f\u0026#34; fi } # If I\u0026#39;m on my home machine, don\u0026#39;t show the hostname in the prompt. if [[ `hostname` =~ ^my-home-machine.* ]] then PROMPT=\u0026#34;%(?:%F{green}➤:%F{red}!%?)%f %F{cyan}%~%f\\$(git_prompt_info) %(!:# :)\u0026#34; else # Add \u0026#34;%m\u0026#34; to print the short hostname on other servers PROMPT=\u0026#34;%(?:%F{green}➤:%F{red}!%?)%f %F{blue}%m%f:%F{cyan}%~%f\\$(git_prompt_info) %(!:# :)\u0026#34; fi Here\u0026rsquo;s what the shell looks like in a clean repository:\nAnd here\u0026rsquo;s what it looks like in a repository with some uncommitted changes:\nThe green prompt will change to a red ! and show the exit status of the last command if it was anything other than 0.\nThis should run pretty quick. The Git functions take almost no time to run, and the rest is straight-line Zsh script. Using this I was able to stop using Oh-my-zsh and dramatically reduce my shell startup time.\nEshell prompt # I recently started using Eshell in Emacs, and I wanted the same prompt there as I had in my terminal. Here\u0026rsquo;s how I got the same prompt, using some functions for the incomparable Magit Git porcelain.\nFirst, you need to define a function that generates the prompt for the current directory:\n(defun fancy-shell () \u0026#34;A pretty shell with git status\u0026#34; (let* ((cwd (abbreviate-file-name (eshell/pwd))) (ref (magit-get-shortname \u0026#34;HEAD\u0026#34;)) (stat (magit-file-status)) (x-stat eshell-last-command-status) (git-chunk (if ref (format \u0026#34;%s%s%s \u0026#34; (propertize (if stat \u0026#34;[\u0026#34; \u0026#34;(\u0026#34;) \u0026#39;font-lock-face (list :foreground (if stat \u0026#34;red\u0026#34; \u0026#34;green\u0026#34;))) (propertize ref \u0026#39;font-lock-face \u0026#39;(:foreground \u0026#34;yellow\u0026#34;)) (propertize (if stat \u0026#34;]\u0026#34; \u0026#34;)\u0026#34;) \u0026#39;font-lock-face (list :foreground (if stat \u0026#34;red\u0026#34; \u0026#34;green\u0026#34;)))) \u0026#34;\u0026#34;))) (propertize (format \u0026#34;%s %s %s$ \u0026#34; (if (\u0026lt; 0 x-stat) (format (propertize \u0026#34;!%s\u0026#34; \u0026#39;font-lock-face \u0026#39;(:foreground \u0026#34;red\u0026#34;)) x-stat) (propertize \u0026#34;➤\u0026#34; \u0026#39;font-lock-face (list :foreground (if (\u0026lt; 0 x-stat) \u0026#34;red\u0026#34; \u0026#34;green\u0026#34;)))) (propertize cwd \u0026#39;font-lock-face \u0026#39;(:foreground \u0026#34;#45babf\u0026#34;)) git-chunk) \u0026#39;read-only t \u0026#39;front-sticky \u0026#39;(font-lock-face read-only) \u0026#39;rear-nonsticky \u0026#39;(font-lock-face read-only)))) Now that that function is defined, you can tell Eshell to use that to make the shell prompt. (It\u0026rsquo;s also good to set eshell-prompt-regexp so it knows where the prompt begins and ends.)\n(setopt eshell-prompt-function \u0026#39;fancy-shell) (setopt eshell-prompt-regexp \u0026#34;^[^#$\\n]* [$#] \u0026#34;) (setopt eshell-highlight-prompt nil) It looks basically the same as the Zsh prompt, except there\u0026rsquo;s always a $ character at the end of the prompt. This is just to make Emacs\u0026rsquo; prompt-parsing easier.\nIf you are curious about using Eshell, you should use Eshell in concert with Eat, which runs commands in a little terminal emulator. This makes interactive programs like code REPLs or programs that use character escape codes work correctly. (You can even run emacs -nw and have it work! Madness!) I can use Eshell for more than 90% of what I need to do in a shell now, and that\u0026rsquo;s pretty nice.\n"},{"id":11,"href":"/posts/2024-08-06_zkp/","title":"Notes on Zero-Knowledge Proofs and Secure Remote Password (SRP) Protocol","section":"Technical Blog","content":"Today I learned about using zero-knowledge proofs in the context of passwords. These are my rough-and-ready notes from reading. Apparently OpenSSL has an implementation of the SRP algorithm.\nMath-based ZKP example # Source for this example comes from Wikipedia. It might be good to read that in tandem with these notes.\nIn this example Peggy is the person who wishes to prove knowledge about something to Victor, the verifier. Peggy is proving that she knows some value \\(x\\) , but she doesn\u0026rsquo;t want to reveal the value of \\(x\\) .\nPeggy and Victor need to share a large prime \\(p\\) and a generator \\(g\\) . (This means that \\(g\\) and \\(p\\) must be relatively prime.)\nPeggy computes \\(g^x \\mod{p} = y\\) and sends \\(y\\) to Victor.\nPeggy generates a random number \\(r\\) and computes \\(C = g^r \\mod{p}\\) and sends \\(C\\) to Victor.\nVictor randomly issues one of two challenges:\nVictor asks for \\(r\\) . Peggy sends him \\(r\\) and Victor verifies that \\(C\\) matches \\(g^r \\mod{p}\\) . Victor asks for \\(s = (x \u0026#43; r) \\mod{(p-1)}\\) . Peggy computes this and sends the result to Victor. Victor checks that \\(g^s \\equiv (C \\cdot y) \\mod{p}\\) . Repeat process \\(n\\) times to drive the probability that Peggy was just guessing to \\(\\frac{1}{2^n}\\) .\nThe Wikipedia article has a good explanation for how an attacker could not mimic knowing \\(x\\) with this interactive proof.\nDigression: properties of exponents modulo a prime # The last step works because\n\\(\\begin{aligned} C \\cdot y \u0026amp;\\equiv g^r \\cdot g^x \u0026amp;\\mod{p} \\\\ \u0026amp;\\equiv g^{r \u0026#43; x \\mod{p-1}} \u0026amp;\\mod{p} \\end{aligned}\\) When working \\(\\mod{p}\\) , operations on combining exponents are \\(\\mod{p-1}\\) . This is a consequence of Fermat\u0026rsquo;s Little Theorem. Proof:\n\\(a^e = a^{p-1} \\cdot a^{p-1} \\cdot a^{p-1} \\cdots a^n\\) Where \\(a^{p-1}\\cdot a^{p-1} \\cdots a^{p-1} \\equiv 1 \\mod{p}\\) by Fermat\u0026rsquo;s theorem, and \\(n \u0026lt; p\\) and \\(e = m(p-1) \u0026#43; n\\) by the division algorithm. Therefore, \\(n \\equiv e \\pmod{p-1}\\) .\nZKPs used for password-based authentication # The above framework is not useful as-is for password authentication.\nThere is a method for verifying that a user knows a password without revealing the password to the server. The standard is called \u0026ldquo;SRP\u0026rdquo; (Secure Remote Password) and there\u0026rsquo;s at least a version 6. As far as I can tell, version 6 is the most up-to-date version as of writing.\nResources:\nSRP Protocol Wikipedia article has a good explaination.\nTo convert between PostScript format (.ps) and PDF, run ps2pdf srp6.ps. On macOS I got the ps2pdf program by installing the ghostscript package via Homebrew.\nSRP protocol design document; includes links to a paper that I followed. I can\u0026rsquo;t find this paper in any official publication registry. URL is: http://srp.stanford.edu/srp6.ps and the title is: \u0026ldquo;SRP-6: Improvements and Refinements to the Secure Remote Password Protocol\u0026rdquo;. Note: it comes in PostScript format, so you\u0026rsquo;ll likely want to convert it to PDF to read it.\nSE post: \u0026ldquo;Why aren\u0026rsquo;t ZKPs used in practice for authentication?\u0026rdquo;, top answer is excellent.\nRunning SRP-6a # Shared: large safe prime \\(N\\) (suggested that \\(N = 2 * p \u0026#43; 1\\) where \\(p\\) is prime) and primitive root \\(g\\) . (I.e., \\(N\\) and \\(g\\) must be relatively prime.)\nIn this algorithm, the values \\(a\\) and \\(b\\) will be randomly generated. At the end, both parties will have a secret key \\(K\\) that they share.\nClient sends identifier \\(I\\) to Server. Server looks up the salt and the verification token \\((s,v)\\) associated with \\(I\\) and sends just \\(s\\) to Client. Client computes hash of salt, ID, and password \\(x = H(s, I, P)\\) . Client generates a random value \\(a\\) and computes \\(A = g^a\\) . Client sends \\(A\\) to Server. Server and client compute \\(k = H(N, g)\\) . This is an enhancement from the older SRP-6 algorithm. Server generates a random value \\(b\\) and computes \\(B = kv \u0026#43; g^b\\) . Server sends \\(B\\) to client. Server and Client both compute \\(u = H(A,B)\\) . This is called the scrambler. Now both parties have access to \\(A, B, k, u\\) and \\(g, N\\) of course. With this they can each create a shared session key:\nClient computation \\(K = (B-kg^x) ^ {(a \u0026#43; ux)}\\) Server computation \\(K = (Av^u)^b\\) The server and client must now both verify that they have the same value \\(K\\) . One simple way to do this is to hash \\(K\\) (potentially with some other salting information like \\(A\\) and \\(B\\) ) and transmit that. Example from the paper:\n\\( \\begin{aligned} M_1 \u0026amp;= H(A,B,K) \\\\ M_2 \u0026amp;= H(A,M_1,K) \\end{aligned}\\) The Client computes \\(M_1\\) and sends it to the server. The server should have enough information to recompute this value. Once that\u0026rsquo;s done, the server can compute \\(M_2\\) and send that back to the Client. (This last step is optional.) Now both parties know that they\u0026rsquo;ve got the right key. Use \\(K\\) as the session token.\nThe Wikipedia article mentions that it is important that the client send its proof of \\(K\\) (i.e., the proof is the value \\(M_1\\) ) first, and that the server should not reply with \\(M_2\\) if verification fails.\nHere\u0026rsquo;s what the communication flow would look like:\nClient \\(I\\) → Server Server \\(g,N,s,B\\) → Client Client \\(A, M_1\\) → Server Server \\(M_2\\) → Client Now the Server and Client can communicate using secret key \\(K\\) , which was only granted to the Client because it had the password that corresponded to the stored verifier \\(v\\) on the server.\n"},{"id":12,"href":"/posts/2024-07-29_note_mediums/","title":"How, Where, and Why I Take Notes","section":"Technical Blog","content":"I take a blend of digital and hand-written notes. It\u0026rsquo;s a bit of a hodgepodge, but it\u0026rsquo;s working. I used to lean heavily into full-digital notes, but I started drifting towards a mixture of digital and hand-written notes. Initially it was complicated, but I think I\u0026rsquo;m converging on a good setup. What I describe here will continue to evolve I am sure, but I am enjoying where it\u0026rsquo;s currently at.\nPen and paper is best for thinking # I\u0026rsquo;ve fallen down the fountain pen rabbit hole. I used to write with a Pilot G2 pen, and I loved how dark ink was. The primary drawback was that it bled through the paper of my Leuchtturm notebooks a little bit. I also had some problems with the extra-fine 0.38 pens: after a few months of use, they\u0026rsquo;d break before all the gel ink had been expended. This was frustrating.\nNow I write with a Lamy Al-Star with an extra-fine nib. I use Pilot\u0026rsquo;s black take-sumi iroshizuku ink. It is lovely to write with this pen. Compared to the G2, the fountain pen writes just as fine as the 0.38 G2, but the ink doesn\u0026rsquo;t skip, the tip never breaks, and the ink doesn\u0026rsquo;t bleed through the paper at all. Sure, the fountain pen requires a little more maintenance than a gel or ballpoint pen, but it is fun to have a little mechanical thing to maintain and form simple rituals around.\nGetting the fountain pen had the curious effect of making me want to take more notes by hand. I started writing a lot more. But I have a bunch of infrastructure set up for digital note taking, so when I initially started writing more, I would get a little lost as to where I had put certain notes. I didn\u0026rsquo;t like that.\nI did find that I enjoyed writing my thoughts out—it was like doing a one-person rubber-duck session. I strongly believe that writing helps you think: it forces you to be explicit with your thoughts and it helps you notice gaps in your thinking. This can push you to answer questions that you wouldn\u0026rsquo;t have asked otherwise.\nQuasi-digital for classes # In class I take notes on an iPad with an Apple Pencil. I like that I can keep all my notes for all my classes with me at all times. I also like that I can write in different colors when needed, the ability to download or take a picture of a slide and mark it up, or do some lightweight diagraming. I feel like it gives me the best of both worlds: I get the storage, versatility, and searchability of digital notes, but I get the memory benefits of handwritten notes since I am writing rather than typing.\nFull digital for research # Backlinks: The set of notes that link to a given note. Suppose note A has a link to note B. If I am looking at note B, then A will be in the set of B\u0026rsquo;s backlinks. Whenever I have something that I am researching, I typically keep notes in a plain-text file on my computer. (I use org-mode most of the time, naturally.) This lets me link and search through my notes really easily. Being on a computer means that it is easy to copy-paste things I want to remember and then store links to recover the source. I use Denote to organize my notes; Denote lets me format my notes consistently, as well as recover backlinks.\nFun aside: I recently contributed some code to Denote that adds an indicator in the mode-line if the currently-visited note has a backlink. I like getting a heads-up that there\u0026rsquo;s some digging to do.\nI also will put notes that I made by hand during a thinking session into my Denote files after they\u0026rsquo;ve had a little time to marinate in my head. I will typically use this step to flesh out ideas that I only got in skeleton form in my notebook.\nI really like Denote: it is simple, requires no external dependencies, and it plays nicely with synching systems. Today, thanks to my tag system, links, backlinks, and some searching, I ran into some notes I had taken a year ago and forgot about—but now these notes are helping me with my work right now!\nSummary: what I write and where # After thinking a little bit about what mode of note taking benefits most from a given medium, I came up with the following system for myself:\nMeeting with my advisor I take meeting notes by hand on paper, usually in my notebook. Thinking through something Again, hand-written, usually on my Rhodia pads as these are typically ephemeral notes. If I get a good idea, I\u0026rsquo;ll write it down in my notebook and then transfer it to my digital Denote notes later. Reading notes If I am reading a technical paper or book that I want to understand, I\u0026rsquo;ll take these notes in my notebook. Research lab notes Digital. I have a template that I fill out every day that helps me keep track of basic information and links all of my daily lab notes to a big note for the whole project. This makes it easy for me to go to that project note and flip through the backlinks. Class notes While I only have one more class left, I still take class notes on my iPad. I feel like class notes benefit the most from a digital-handwriting hybrid. Should you adopt the setup I have? No. You should arrive to your own system yourself. The only thing I would advise anyone to take from my experience is that you should put a little time and effort into being intentional about how you take notes and how your organize them. You need to find a system that works for you, and only you can do the work to make that happen.\n"},{"id":13,"href":"/posts/2024-07-15_type_tailoring/","title":"Evolving Languages Faster with Type Tailoring","section":"Technical Blog","content":"Programming languages are too slow! I\u0026rsquo;m not talking about execution speed—I\u0026rsquo;m talking about evolution speed. Programmers are always building new libraries and embedded DSLs, but the host programming language—particularly its type system—doesn\u0026rsquo;t understand the domain-specific aspects of these things.\nExample problem: my type system doesn\u0026rsquo;t speak PCRE # Consider regular expressions—most programmers would understand that a regular expression like [a-z]+([0-9][0-9]), if it matches, will capture two digits in the first capture group. If I try to write this code in Rust or Typed Racket, the type checker complains:\nExample: Rust 1 2 3 4 5 6 7 8 use regex::Regex; fn main() { let re = Regex::new(r\u0026#34;[a-z]+([0-9][0-9])\u0026#34;).unwrap(); if let Some(caps) = re.captures(\u0026#34;dent42\u0026#34;) { println!(\u0026#34;id number: {}\u0026#34;, caps.get(1)); } } error:\nrustc [E0277]: `Option\u0026lt;regex::Match\u0026lt;\u0026#39;_\u0026gt;\u0026gt;` doesn\u0026#39;t implement `std::fmt::Display` the trait `std::fmt::Display` is not implemented for `Option\u0026lt;regex::Match\u0026lt;\u0026#39;_\u0026gt;\u0026gt;` Example: Typed Racket 1 2 3 4 5 6 7 8 9 10 #lang typed/racket (define (user-idnum (username : String)) : Number (define re \u0026#34;[a-z]+([0-9][0-9])\u0026#34;) (define m (regexp-match re username)) (if m (string-\u0026gt;number (second m)) (error \u0026#34;bad username\u0026#34;))) (printf \u0026#34;id number: ~a\\n\u0026#34; (user-idnum \u0026#34;dent42\u0026#34;)) error:\nexample.rkt:7:22: Type Checker: Polymorphic function `second\u0026#39; could not be applied to arguments: Types: (List* a r (Listof t)) -\u0026gt; (r : ((! (cadr (0 0)) False) | (: (cadr (0 0)) False)) : (cadr (0 0))) (Listof a) -\u0026gt; a Arguments: (Pairof String (Listof (U False String))) Expected result: String The (U τ₁ τ₂) syntax is a type union of types τ₁ and τ₂, whatever types those are. The equivalent of Option\u0026lt;String\u0026gt; in Typed Racket is (U String False).\nThe problem is that getting the first capture group (caps.get(1) in Rust, (second m) in Typed Racket) returns an optional type (Option\u0026lt;regex::Match\u0026gt; in Rust, (Listof (U False String)). The thing is, we know that since the regex match succeeded on line 5, caps.get(1) (or (second m)) should definitely succeed because there was one capture group in the regex we matched. Instead, we\u0026rsquo;re forced to unwrap in Rust:\nprintln!(\u0026#34;id number: {}\u0026#34;, caps.get(1).unwrap().as_str()); Likewise, in Typed Racket, we have to insert some casts and checks manually to convince the type checker that this code should run.\nThis is a small example; the key point is this: type systems usually aren\u0026rsquo;t smart enough to know about the structure of regexes\u0026mdash;all the compiler sees are opaque strings. This goes for things beyond regular expressions. Consider SQL queries, which are so often embedded as strings in languages: when a query goes wrong, you usually only find out at runtime.\nWhat would a solution look like? Some people have tried making a new way of writing regexes with composable objects that the type system has a better chance of understanding; that is a neat approach, but that both requires me to rewrite my program and doesn\u0026rsquo;t solve the issue of indexing into lists of known size (the results of a capture) more efficiently.\nAnother option would be to make the type system smarter. But that too has its drawbacks: language implementers are often leery of tinkering with the type checker—and rightly so! So much relies on the type checker being correct. Moreover, even if you did make the type checker able to understand regexes, someone\u0026rsquo;s going to build a new library tomorrow that will stump your type checker just as before.\nHere\u0026rsquo;s a more attractive option: we can use the metaprogramming tools the language provides to teach the type system some new tricks. This is something that end-users of languages can do without waiting for the language designer. We call this type tailoring.\nType Tailoring is the title and subject of a paper I wrote with my advisor Ben Greenman and our coauthors Stephen Chang and Matthias Felleisen. It has been accepted at European Conference on Object-Oriented Programming (ECOOP). Like the ACM conference OOPSLA, ECOOP has in recent years focused on more than object-oriented programming. The name stuck around. ¯\\_(ツ)_/¯ You can get a preprint here.\nSketch of a solution # Here\u0026rsquo;s a high-level sketch of how we would solve the problem:\nSomething would notice that the regex has a single capture group. The re.captures function would get this information and update the its type. This information would further by leveraged by the type of caps, to indicate that get(0) or get(1) will always succeed. Some years ago, my advisor made the trivial library for Typed Racket. It can tailor the following code so that it typechecks and runs efficiently:\nThe trivial library is available as a Racket package. If you have Racket installed on your system, run raco pkg add trivial to install it.\n#lang typed/racket (require trivial trivial/list) ;; add this to tailor program (define (user-idnum (username : String)) : Number (define re \u0026#34;[a-z]+([0-9][0-9])\u0026#34;) (define m (regexp-match re username)) (if m (string-\u0026gt;number (second m)) (error \u0026#34;bad username\u0026#34;))) (printf \u0026#34;id number: ~a\\n\u0026#34; (user-idnum \u0026#34;dent42\u0026#34;)) Before Tailoring Type Checker: Polymorphic function `second\u0026#39; could not be applied to arguments: Types: (List* a r (Listof t)) -\u0026gt; (r : ((! (cadr (0 0)) False) | (: (cadr (0 0)) False)) : (cadr (0 0))) (Listof a) -\u0026gt; a Arguments: (Pairof String (Listof (U False String))) Expected result: String After Tailoring id number: 42 For specific details on how the trivial library works, see § Appendix: How does the trivial library work? at the end of this post.\nThe problem is that, like Rust, Typed Racket must assign an overly conservative type to the result of matching a regular expression. Consequently, the programmer has to insert casts. The trivial library can analyze Typed Racket and insert these casts and checks automatically. The end-result for the user is that this code Just Works™ as you would expect.\nNotice that the trivial library is a library\u0026mdash;it doesn\u0026rsquo;t require modifications to the compiler or type checker or anything. This means that normal users of programming languages can create their own tailorings without breaking the compiler or messing with the build pipeline.\nSupporting type tailoring # What do you need to make type tailoring work? Let\u0026rsquo;s step back a second and look at what we need to do in the first place. Our problem is that the type checker doesn\u0026rsquo;t know as much about our program as we do. What we can do to teach the type checker is program the elaboration step: surface syntax typically doesn\u0026rsquo;t have type annotations at every point; elaboration takes the syntax that a programmer writes, and adds types and type holes wherever needed. This elaborated syntax gets sent off to the constraint solver for type checking and inference.\nHow do we program the elaboration step? Almost all languages that have macros do type checking after macroexpansion. This is crucial for type tailoring. We can write macros that add checks, casts, type annotations, or whatever else we need to make the type checker happy.\nHere are the key features that you must have to make type tailoring work:\nType checking after elaboration Type checking must come after elaboration to check the results of tailoring. Without this, it would be too easy to break the type system. Furthermore, if type checking comes after elaboration, we can leverage all the power of the type checker to do the heavy-lifting for us; all a tailoring has to do is give a few hints to the type checker here and there. Elaboration-time computation Most of the time this means that you need procedural macros. Pattern-based macros (such as syntax-case from Scheme or macro_rules! from Rust) can only rearrange syntax, in a pattern → pattern transformation, and can\u0026rsquo;t perform arbitrary rewrites. AST datatype Without an AST datatype, tailorings are limited to using a token stream. Rust\u0026rsquo;s procedural macros operate on token streams unfortunately. Sometimes it\u0026rsquo;s possible to convert a token stream to an AST, but you loose metadata and becomes unwieldy quickly. These are the essential elements, without which tailoring can\u0026rsquo;t happen. Besides these three things, you also will want some of the following tailoring features:\nHygienic macros Hygienic macros avoid the variable capture problem. For more on the variable capture problem, see my post about fearless macros. In other words, I shouldn\u0026rsquo;t have to be concerned about the internals of the macros that I use. This also makes it so that I can compose macros with each other. Metadata Metaprogramming systems that can attach metadata directly to AST nodes can share information between different tailorings easily. (Keeping compile-time state off to the side is an alternative.) Controlling the order of expansion Tailorings that cooperate often need a way to control the order in which they run: one tailoring might depend on the results of another, and a third tailoring might analyze the output further. Accessing external data Some of the coolest tailorings reached out to external sources of data to augment type checking. Rust actually has a neat library called SQLx that, at compile time, checks SQL strings against the schema of a database. There are several systems that do something similar. Type information A few of the systems that we looked at (Idris 1 and Scala 3) could inspect the types of arguments to macros. After expansion, the type checker would run again to check that the transformation\u0026rsquo;s result was well-typed. Since there were so few examples of this, it\u0026rsquo;s hard to say just how beneficial this is. No language supports all of these features—that\u0026rsquo;s exciting because it means there\u0026rsquo;s room to explore! In our paper we go into detail about each of these features and the kinds of tailoring they enable. We also have a chart showing how a handful of languages stack up against each other.\nYou might have invented type tailoring # We invented the term \u0026ldquo;type tailoring\u0026rdquo;, but we didn\u0026rsquo;t invent the idea—programmers have wanted to teach their type systems how to understand domain-specific concerns for a long time. Here are just a few existing projects we found that were doing type tailoring:\nRust\u0026rsquo;s SQLx library reaches out to the database at compile-time to check if the schema in the code matches how the database is set up. This will warn you at compile-time if your query is malformed.\nJulia\u0026rsquo;s StaticArrays package rewrites lists of a static, known size into tuples. This lets the compiler track how long the lists are and automatically eliminates lots of bounds checks—handy when you\u0026rsquo;re doing lots of numerical work.\nElixir\u0026rsquo;s Phoenix web framework will check routes in your template files against your route handler; if you make a typo or forget to implement a handler for a route, Phoenix will warn you at compile-time. This feature is called verified routes.\nAgain, that\u0026rsquo;s just a small sample. Please see our paper for details on how these projects are using type tailoring, as well as for more examples that we found.\nType tailoring: new terms, new libraries, new horizons # The big contributions of our paper are:\nWe introduce the term type tailoring. The ideas have appeared in many forms across many languages, but there hasn\u0026rsquo;t been any underlying rationale unifying their efforts. Now that we\u0026rsquo;ve identified the phenomenon, we can talk about and support it directly and consciously.\nWe identified the main things you need to make tailoring work. Language designers can use this to build in better support for type tailoring in their languages.\nWe show users how tailorings can balance ease-of-use with features typically only found in dependent type systems.\nFurthermore, we built two libraries: trivial for Racket—which tailors things like vectors, regular expressions, etc., and Dyn for Rhombus—which turns Rhombus into a gradually-typed language through a tailoring. We expect more will be built in the future.\nAgain, please see our paper for all the details. Our paper comes with an artifact that contains all the code in the paper. You can simply download a Docker container to run the code and verify all our claims. Yay for reproducible research!\nIf you have any questions, feel free to email me. (Email in the paper, as well as here on my blog.) If you\u0026rsquo;re going to ECOOP in Vienna this year, let me know and we can talk in person there!\nAppendix: How does the trivial library work? # Here is the example with the trivial library that we saw in § Sketch of a solution:\n#lang typed/racket (require trivial trivial/list) ;; add this to tailor program (define (user-idnum (username : String)) : Number (define re \u0026#34;[a-z]+([0-9][0-9])\u0026#34;) (define m (regexp-match re username)) (if m (string-\u0026gt;number (second m)) (error \u0026#34;bad username\u0026#34;))) (printf \u0026#34;id number: ~a\\n\u0026#34; (user-idnum \u0026#34;dent42\u0026#34;)) Normally, Typed Racket rejects the code because the type of m is too general to be applied to second. Here is how the trivial library tailors the example to make it work:\nFirst, it overrides the implicit #%datum form that wraps literal values like the string \u0026quot;[a-z]+([0-9][0-9])\u0026quot;; this lets it read the string and collect any interesting information about it at compile time.\nThe library sees that the string has one set of matched parentheses; moreover, the pattern inside the parentheses consists entirely of digits. It attaches this information as a syntax property to the syntax object for that string.\nThis information gets propagated to all occurrences of the identifier re.\nThe library also overrides regexp-match, so that it looks at the syntax properties on its first argument. In this case, it sees that re is a string with one capture group. The library updates the return type of m from (Pairof String (Listof (U False String))) to (U (List String String) False).\nIn the true branch of the if statement, Typed Racket is automatically able to refine the type of m to (List String String).\nThe trivial library overrides second to check the type of its argument; it sees that (List String String) is long enough for this call to succeed, so it tailors this to a faster, unsafe lookup function.\nstring-\u0026gt;number also gets overridden to look at the information about the match. Since step 2 was able to see that the match consists only of digits, it updates its type from returning (U Complex False) to Number.\nThat\u0026rsquo;s a lot going on! The neat thing is that trivial is able to do all this in a fairly generalized way: one component works with strings, another works with regular expressions, and another works with lists of known size. They\u0026rsquo;re able to share all this information through syntax properties which respect the scoping rules of Typed Racket. It also plays nicely with other metaprogrammings; we could have written a macro that e.g., turns if into not-if and flips the branches, but the information we needed about the m variable still would have gotten to the right place.\nUnfortunately, there\u0026rsquo;s not a way right now that we could make this example work for Rust—at least, not in its current form. That\u0026rsquo;s because different languages have different support for different kinds of tailoring. In our paper, we explore all the different dimensions for how languages can support tailorings.\nAppendix: Building a tiny type tailoring # Here is how you might build a little tailoring. In this tailoring, we\u0026rsquo;d like to turn array lookups that are known to be in-bounds into versions that use a fast, unsafe lookup. In a dependently typed language, we would be able to do this by looking at index and the type of the vector, since the type of the vector would include its length. In Racket, we have no such power. However, we can get a little bit of that power through a tailoring.\nThis section is taken almost verbatim from §3.8 from our paper. This code actually runs!\nHere\u0026rsquo;s an example of what we would like to tailor: if we know the length of a vector and the index, then we can either tailor to unsafe-vector-ref, which skips the bounds check, or tailor to an error if the index is out-of-bounds. Otherwise, if we don\u0026rsquo;t know either the length of the vector or the index, we stick with the safe vector-ref function which does run the bounds check:\n(vector-ref (vector 5 2 8) 1) ; tailors to → (unsafe-vector-ref (vector 5 2 8) 1) (vector-ref (vector 4 9 1) 4) ; tailors to → error: out of bounds (vector-ref (read-vec) 9) ; tailors to → (vector-ref (read-vec) 9) Here\u0026rsquo;s how we do it:\n1 2 3 4 #lang racket (provide (rename-out [tailored-vector-ref vector-ref])) Code Snippet 1: mini-tailoring.rkt, part 1 of 5 The (provide (rename-out …)) bit says that, when this module gets imported, export the function tailored-vector-ref under the name vector-ref. This means, whenever this module gets imported, all calls to vector-ref automatically use tailored-vector-ref.\n5 6 7 8 9 10 11 12 13 (require (only-in racket/unsafe/ops unsafe-vector-ref) (for-syntax racket/base syntax/parse ;; metaprogramming support (only-in \u0026#34;tailoring-api.rkt\u0026#34; ⇝ ;; control **Order** of expansion φ ;; API to read/write static information (**Metadata**) V ;; domain-specific key for vector length information (**Hygiene**) I))) ;; domain-specific key for integer value information (**Hygiene**) Code Snippet 2: mini-tailoring.rkt, part 2 of 5 Now we import some helpers: racket/unsafe/ops gives us the unsafe-vector-ref function, which is what we tailor to. This function can segfault if misused, so we have to be careful. We pull in syntax/parse to get the excellent syntax-parse macro facility. We also pull in four symbols from tailoring-api.rkt, which deserve a mention:\n⇝ This is a syntax class that triggers macro expansion on a subexpression, which allows this tailoring to discover static information about its different components. φ This is a function that uses Racket\u0026rsquo;s syntax properties to store and retrieve static information. V, I These are unique keys (created with gensym) that we use for looking up vector length and integer value information. Since they\u0026rsquo;re unique, other tailorings won\u0026rsquo;t accidentally collide with this information. The file tailoring-api.rkt is small and really just provides these convenience functions; you can find it in our artifact.\nNow comes the meat of the tailoring: the tailoring is a macro so that it can statically rewrite source code. First it parses its input syntax object stx to extract and expand two subexpressions e1 and e2:\n14 15 16 (define-syntax (tailored-vector-ref stx) (syntax-parse stx [(_ e1:⇝ e2:⇝) Code Snippet 3: mini-tailoring.rkt, part 3 of 5 Now the tailoring checks whether these expanded expressions have the static information needed; specifically, it looks for a vector length (key: V) and an integer value (key: I):\n17 18 19 20 #:do [(define n (φ #\u0026#39;e1.⇝ V)) (define i (φ #\u0026#39;e2.⇝ I))] #:when (and (integer? n) (integer? i)) Code Snippet 4: mini-tailoring.rkt, part 4 of 5 If the information is present, we expand to unsafe-vector-ref if safe to do so; otherwise we expand to code that raises an error. If the information is not present, fall back to plain-old vector-ref:\n21 22 23 24 25 (if (and (\u0026lt;= 0 i) (\u0026lt; i n)) #`(unsafe-vector-ref e1.⇝ e2.⇝) #`(error \u0026#39;Index-Exn))] [(_ e1:⇝ e2:⇝) #`(vector-ref e1.⇝ e2.⇝)])) Code Snippet 5: mini-tailoring.rkt, part 5 of 5 That\u0026rsquo;s it! A Racket program can import this tailoring to make this code run faster:\n#lang racket (require \u0026#34;mini-tailoring.rkt\u0026#34;) (vector-ref (vector 5 2 8) 1) ; gets tailored to (unsafe-vector-ref (vector 5 2 8) 1) Save that program to a file and run raco expand \u0026lt;filename\u0026gt; to see the expanded version; you should see unsafe-vector-ref in the expanded code.\n"},{"id":14,"href":"/posts/2024-07-09_phd_tools/","title":"Skills That I Needed When I Started My PhD","section":"Technical Blog","content":"I\u0026rsquo;m starting my third year as a PhD student. I thought it would be good to look back on some of the things that have helped me to this point. I study programming languages, but I imagine these things will help anyone in computer science\u0026mdash;and some might have application to other STEM fields as well.\nThere are many softer skills that you need as a PhD student: curiosity, good work ethic, organization, etc. These are essential and nothing can replace them. (Note: that was not an exhaustive list.) I\u0026rsquo;m going to focus on some of the tools and hard skills that made the ride a little more comfortable. These compliment, rather than compete with, the softer skills that one develops as a beginning researcher.\nThis is a rough list, and not a how-to article. This is mostly just a collection of things I\u0026rsquo;ve seen other people lacking that have caused them to struggle. If you are considering doing a PhD, you might want to pick up some of these skills as you get ready to start to help you hit the ground running.\nSoftware engineering # I recommend reading The Pragmatic Programmer (Thomas, David and Hunt, Andrew, 2019). It\u0026rsquo;s written primarily for industry programmers, but there\u0026rsquo;s a lot in there that applies to anyone in CS research. All of the things I mention in this section are covered in detail in there.\nVersion Control # You have got to know Git. If you cannot wrangle versions of your software and papers (yes, put the papers you write under version control) you will waste much time shooting yourself in the foot and trying to recover work you lost. You will also be laughed to scorn should you ever depart academia for a stint in industry if you do not know Git.\nIn all of the papers I have worked on, we have used Git to collaborate. We\u0026rsquo;ve typically used GitHub, which is fine as forges go, but I\u0026rsquo;ve also worked with a self-hosted GitLab instance, and that was fine too.\nScripting # It is incredibly helpful to know a scripting language. I grew up on Perl, which makes munging large amounts of text a piece of cake. You don\u0026rsquo;t have to learn Perl; you should get really comfortable with a language that makes it easy to manipulate text and files.\nMakefiles are also super helpful. I like using Makefiles to simply give names to a particular workflow. A Makefile for building a paper might look like this:\npaper.pdf: paper.tex latexmk -lualatex paper .PHONY: clean clean: @echo Cleanup time latexmk -c rm -f paper.pdf Now, instead of remembering all the incantations necessary to do some task, I have given that task a name by which I can call it.\nCommand line # You must become proficient with the command line. If you are doing research, you will likely need to run software that other researchers have produced. And more likely than not, this will be rough software with bugs and sharp edges that is meant to demonstrate some research concept than be some practical tool ready for developers who only know how to code through YouTube videos and ChatGPT. That this software is rough is a feature of research software, not a bug. There is rarely, if ever, a GUI available. You are going to have to do stuff on the command line, so get used to it.\nGetting used to the command line helps with Scripting as well. Any task you do on the command line, you can write a script to automate. Building little scripts to e.g. build your paper, your homework, your experiments, etc. will save you time in the long run.\nKnow thy editor # Emacs or Vim\u0026mdash;pick one and learn it really well. VS Code is flashy and all, but it doesn\u0026rsquo;t have the same depth and breadth of customizations that Emacs and Vim give you. Also, Emacs and Vim are free software. You are in control!\nI, of course, love Emacs and I even made a starter kit called Bedrock to help some of my friends in my research lab get started with Emacs. I use Emacs to program, write papers, take notes, manage email, track tasks, and more. I made a list of my top Emacs packages a few weeks ago if you\u0026rsquo;d like more ideas on what is possible.\nVim is fine too and I will still respect you if you choose to go that route. ;)\nAuthoring papers # LaTeX # Familiarity with LaTeX has definitely helped me. Fighting with LaTeX is no fun, but you will have to do a little bit of it at some point. Lots of people like using Overleaf; I prefer the command line. Don\u0026rsquo;t get me wrong: Overleaf is awesome and makes collaborating in a Google Docs sort of way possible, but you loose some flexibility, and if something goes wrong on Overleaf right before your deadline, you\u0026rsquo;re toast.\nBibliographies # There is a lovely computer science bibliography hosted at dblp.org. When I was going through the bibliography for my last paper I was able to find lots of missing DOIs simply by putting in the title of the paper into the search bar; DBLP found all the bibliographic information that I needed.\nOrganization and communication # Note taking # Take notes whenever you learn how to do something that wasn\u0026rsquo;t obvious to you when you started out doing it. I like the Zettelkasten method for taking notes: whenever I learn how to e.g. do some complex layout in LaTeX or learn a neat Makefile trick, I write it down. You can think of it as writing your own personal man pages\nIf you don\u0026rsquo;t know what a man page is, this is the standard manual system available on UNIX-like systems (e.g. FreeBSD, macOS, and Linux). Open a terminal and run man man to read the manual page for man itself. You really need to get comfortable with the Command line.\nSome of these notes I rarely look back at. Others I revisit regularly. But even though I might not review some notes that frequently, there are cases where something on my system will break and a years-old note comes to my rescue from the last time I had to solve that problem. For example, I took notes on how to upgrade my language server for Elixir. I don\u0026rsquo;t upgrade that thing very often, but there is a little tweak I need to do just because of how my system is set up that is not obvious. It took me a few hours of debugging the first time, but, because I took notes, it now only takes me a few minutes.\nEmail # Academics generally love email. It\u0026rsquo;s simple, robust, and doesn\u0026rsquo;t change its UI every few weeks, unlike some popular chat platforms. Unfortunately many universities are forcing everyone to move to Outlook. This is a very bad thing. Fortunately, there are some workarounds that you can use to reclaim some control over your email.\nI have a sweet workflow with my email. That\u0026rsquo;s right, I do it all from Emacs. Now, while I do recommend you learn how to use Emacs, I understand that not everyone will start using Emacs. Everyone should get proficient with their email client and know how to use it well. I recommend anything that you can control entirely from the keyboard.\nYou should also get comfortable with editing replies. You know how, when you reply to an email, you usually see something like this:\nSome mail clients will make the \u0026gt; at the beginning of the line pretty with different colored lines and whatnot. It\u0026rsquo;s all angle brackets under the hood, and you can still edit it as described here.\nHey here is my reply! On Tuesday, 9 July 2024, Slartibartfast said: \u0026gt; Hey, \u0026gt; \u0026gt; You were asking me where I found that elvish blade of great \u0026gt; antiquity. Turns out it was just sitting on a shelf in the living \u0026gt; room the whole time! I had the darndest time escaping the theif \u0026gt; though; I think he locked me into the cellar as soon as I went down \u0026gt; there. … Just typing your reply above the email is called \u0026ldquo;top-posting\u0026rdquo;, and it\u0026rsquo;s considered bad form. You can actually edit the bit that was sent to interleave your reply with bits of the prior email. This makes it easier for people to know what you\u0026rsquo;re replying to.\nHey Slarti \u0026gt; Turns out it was just sitting on a shelf in the living room the \u0026gt; whole time! What!? No way! I must have missed it. I\u0026#39;ll grab it once I figure out how to get up this chimney in the art studio. \u0026gt; I had the darndest time escaping the theif though; I think he locked \u0026gt; me into the cellar as soon as I went down there. Yeah, I cornered the guy in his hideout. I won the knife fight though. When used appropriately, this makes emails much more pleasant to read. It doesn\u0026rsquo;t break the email thread either; you can still see the chain of replies.\nTask tracking # You need some way to keep track of tasks. I have a workflow based off of Org-mode, which I will not detail here. The short of it is that you need to be spending at least a little time with some regularity \u0026ldquo;sharpening the saw\u0026rdquo;1 by making sure that whatever tool you use to keep track of tasks is working for you.\nReferences # Thomas, David and Hunt, Andrew (2019). The Pragmatic Programmer, Addison-Wesley.\nhttps://en.wikipedia.org/wiki/The_7_Habits_of_Highly_Effective_People\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":15,"href":"/posts/2024-07-03_big_blog_update/","title":"Big Updates to My Blog","section":"Technical Blog","content":"I\u0026rsquo;ve made some big changes to my blog! This post is just for me to document what I\u0026rsquo;ve done and why, as well as to test some of the new features I\u0026rsquo;ve added.\nNew fonts # First off: new fonts! I am using Valkyrie for the body text and Concourse for the headings. I\u0026rsquo;ve increased the font size on larger displays for added legibility. I also made the background a little darker for better contrast.\nMargin notes and sidenotes # I stole the margin notes code from Tufte CSS. It\u0026rsquo;s still a little rough, but it\u0026rsquo;s getting there.\nNext up: margin notes. I wanted to try adding margin notes to this blog for some time. Adding margin notes necessitated a whole host of changes; the biggest one is that the table of contents has moved from the right side of the page to the left column. This is to free up some space.\nIn the original version, I was using the currency sign \u0026ldquo;¤\u0026rdquo; to mark in the text where you could click to expand the margin note.\nIf you\u0026rsquo;re on mobile, the margin note will appear as an inline block. This is a departure from how Tufte CSS works; I\u0026rsquo;m copying how Matthew Butterick does margin notes, as you can see on Practical Typography.\nThe blog now has sidenotes This is a sidenote. The big difference between a sidenote and a margin note is that sidenotes have numbers. as well as margin notes. I\u0026rsquo;m not yet sure which one I\u0026rsquo;ll use primarily. I like how clean the margin notes look, but the numbers on the sidenotes make it a.) easier to figure out what note goes where, and b.) act more like a drop-in replacement for footnotes. I understand there\u0026rsquo;s a significant amount of trickery involved in getting these sidenotes and margin notes to line up properly: it has something to do with floats, negative margins, and exclusion zones. Go check out the Tufte CSS source if you\u0026rsquo;re curious. I might go through some recent posts Recent, as in, since I started using ox-hugo to write my blog posts. and convert footnotes to sidenotes.\nEpigraphs # Typical quotes look like this:\nYou have moved into a dark place. You are likely to be eaten by a grue.\nZork I by Infocom\nIf you have not played Zork, you really should.\nThat\u0026rsquo;s all fine and well. But sometimes we need more… elegance.\nYou have moved into a dark place. You are likely to be eaten by a grue.\nZork I by Infocom\nThat will definitely add some pizzazz for when I want to quote something at the beginning or end of a post.\nOverkill? # Obviously. I\u0026rsquo;m liking how this is shaping up. It might be a little overkill for just my blog, but it makes me happy, so that\u0026rsquo;s a win!\n"},{"id":16,"href":"/posts/2024-06-27_language_hate/","title":"I Probably Hate Writing Code in Your Favorite Language","section":"Technical Blog","content":" The Tao gave birth to machine language. Machine language gave birth to the assembler.\nThe assembler gave birth to the compiler. Now there are ten thousand languages.\nEach language has its purpose, however humble. Each language expresses the Yin and Yang of software. Each language has its place within the Tao.\nBut do not program in COBOL if you can avoid it.\nThe Tao of Programming\nI probably hate writing code in your favorite programming language, whatever it may be. This is because I get frustrated by basically all of the top 10 languages you\u0026rsquo;ll find listed anywhere for various reasons. Do I hate programming in Python? You bet I do. \u0026ldquo;But it\u0026rsquo;s Python! Python is the best programming language on earth!\u0026rdquo; I can hear you say. I grant that it has its place. Python wins because its ecosystem of libraries is so huge and because there are so many resources for new users. It\u0026rsquo;s also garbage collected, which means memory safety is not an issue. It the current hot thing, because there is so much support for machine learning in Python.\nI don\u0026rsquo;t consider Python quite as boring as Java!\nBut my problem is that Python is a boring language. This isn\u0026rsquo;t a bad thing necessarily. If you\u0026rsquo;re interested in solving a problem with a known solution and you\u0026rsquo;re doing it for business, the a boring language is probably better for you than, say, Haskell.\nWhy do I think Python is boring? In part because of its philosophy:\nThere should be one—and preferably only one—obvious way to do it.\nThe Zen of Python\nPython has a model of how it wants you to solve problems. That\u0026rsquo;s right: it wants you to solve problems with objects, classes, and explicit loops. Got a problem that\u0026rsquo;s the perfect fit for a functional paradigm? Well, I guess you can use map and filter, but you only get a single expression inside of lambdas, data structures are all mutable, and you can\u0026rsquo;t use recursion to handle lists. Ugh.\nI could tell similar stories for other languages that I don\u0026rsquo;t like programming in. These languages include JavaScript, Go, Java, and C++. Go and Java seem to have been made with huge teams of programmers in mind: make the language and syntax as simple as possible, and then even simpler at the expense of expressivity! This guards against programmers coming up with a clever way to express their problem in a domain-specific way—that\u0026rsquo;s probably a virtue in large companies. But that\u0026rsquo;s not how I like to program.\nNo local reasoning # The thing I hate about all of the languages I listed is their emphasis on mutation. When I call a function and pass it a list or object or whatever, I have no guarantees about that thing\u0026rsquo;s value when the function returns. That means, to understand some code, I have to understand all of the functions that get called.\nIn contrast, when I write in a language like Elixir or Haskell, which have immutable data structures, I can look at some code like this:\nHaskell winningTeam :: GameLog -\u0026gt; Team winningTeam g = let (team_a, team_b) = getTeams g points_a = getPoints g team_a points_b = getPoints g team_b in if points_a \u0026gt; points_b then team_a else team_b Elixir @spec winning_team(g :: GameLog.t()) :: Team.t() def winning_team(g) do {team_a, team_b} = get_teams(g) points_a = get_points(g, team_a) points_b = get_points(g, team_b) if points_a \u0026gt; points_b do team_a else team_b end end and I don\u0026rsquo;t have to know what getTeams or getPoints do to their arguments; I just know they return a value of some kind; I\u0026rsquo;m free to continue using g, team_a, and team_b as much as I like because their value has not changed.\nIt might not seem like much in this example, but it is a big deal when you\u0026rsquo;re neck-deep in a debugging session. I once worked on a codebase that was half in Elixir and half in Ruby. I spent most of my time on the Elixir side. One time when I had to do some debugging in Ruby, I found it so difficult to trace the execution of the program because data was being changed in method calls. If this doesn\u0026rsquo;t make much sense to you, you might have to experience it first: once you\u0026rsquo;ve worked in a large functional codebase, you will find yourself bewildered by all the spooky-action-at-a-distance that goes on inside a large OO codebase.\nOther gripes # Other things that frustrate me in programming languages include:\nAutomatic type conversion (looking at you JavaScript). No type inference (if you\u0026rsquo;re gonna be statically typed, don\u0026rsquo;t make me write out the type every time Java). No structural typing (type is determined by the shape, not the class name). No good functional data structures. No metaprogramming. No TCO/limits on stack depth. That last one is something that really bothers me about Python: stack frames in Racket cost 2 words. Source: I asked Matthew Flatt about Racket\u0026rsquo;s stack frame size once. Either do proper tail-call elimination or, if you really absolutely must have all of your precious stack frames performance and elegance be darned, then allocate your stack frames on the heap and stop worrying about it already! (I seem to recall a conversation where someone with knowledge of these things implied that this was in the works. I don\u0026rsquo;t know any details about it though.)\nSeriously though: some solutions lend themselves really well to a nice tail-recursive solution. But can you rely on such an implementation to be performant or even run in Python? Nope. Argh!!\nMy favorite language # Clearly, I like functional programming: it fits how my mind works, and I think it is in a lot of ways objectively better than other paradigms for software engineering. Immutability gives you the ability to reason locally about your code—not to mention not having to worry about race conditions when mutating data in concurrent environments! To parallel the first list that I wrote, here are things that I like in a language:\nEasy, explicit conversions between different types of data. Dynamic typing or powerful type inference or gradual typing! Structural typing (having nominal typing too can be nice when needed; but given one or the other I\u0026rsquo;ll take structural over nominal any day). Functional data structures like cons cells, maps and sets supporting functional updates, and RRB trees! Powerful macros that let me extend the language. Proper TCO. Macros can be a two-edged sword. That said, a lot of the danger around macros has largely been ameliorated. Elixir is a great example of this: Elixir has a small core and uses macros a lot to define basic things like if in terms of simpler constructs.\nWhat languages do I enjoy programming in? Racket is my favorite: it\u0026rsquo;s designed to be flexible and give the programmer maximum ability to express their intent to the computer. Racket is a programmable programming language.\nOther languages I enjoy include Haskell, Elixir, and Rust. Haskell is the ur-functional language, and it\u0026rsquo;s really fun to use the type system to describe your domain. Pretty soon the compiler starts keeping you from making all sorts of mistakes that would be hard to catch with basic testing. In Elixir, you get lots of nice functional data structures, proper TCO, pattern matching, and soon gradual typing! Rust is great because it has a phenomenal type system with good type inference; its metaprogramming story could be improved though.\nNot a flame war # I want to make it clear that I am not attempting to start a flame-war or saying that Python, Java, et al. are useless: they have their place and are very respectable works of engineering. All I am saying is that, given a choice of language for a hobby project, I will pick something else because I don\u0026rsquo;t want to be frustrated by the language when I work.\nAnyway, that\u0026rsquo;s the end of my griping about languages. (For today, at least.)\nThere will always be things we wish to say in our programs that in all known languages can only be said poorly.\nA language that doesn’t affect the way you think about programming, is not worth knowing.\nAlan Perlis\n"},{"id":17,"href":"/posts/2024-06-21_writing_a_paper/","title":"Lessons From Writing My First Academic Paper","section":"Technical Blog","content":"I got a paper published at ECOOP this year! This is my first big paper published at a big conference. As such, I wanted to write down some things that I learned so that in the future I can remember a bit better what was hard for me. That way, should I one day advise PhD students working on their first papers, I can help them through the learning curve better.\nFor us, this artifact took the form of a Docker container with a bash script that ran all the code examples from our paper to support the claims we made. I really like that reproducibility like this is often an option in CS.\nConference deadlines may be flexible if you talk to the right people. We submitted an artifact along with our paper But some of the deadlines were really close. My advisor reached out to the folks in charge of the conference1 and asked if the artifact submission date could be moved back. The organizers agreed, and everyone got a little more breathing room between when the paper was due and when the artifact was supposed to be submitted. Conferences are run by humans—you can talk to them. Along the same lines, the conferences are run by people, and you can talk to the organizers to request clarification. You shouldn\u0026rsquo;t be a whiny jerk, of course, but the people running these things want people to submit good papers and will work to help you overcome blockers. The Call for Papers has everything you need. The \u0026ldquo;Call for Papers\u0026rdquo; describes what kinds of submissions fit the conference, as well as how to format and submit your paper. You can see the CfP for ECOOP here. Absorbing everything in the CfP can be challenging for first-timers. I was unclear about something and my advisor asked me if I had read the CfP. I had, but that didn\u0026rsquo;t mean that I remembered everything from it. It takes time and experience to absorb the salient parts of the CfP. Papers get easier to read as time goes on. When I first started research, I struggled to make it through a single paper. Moreover, I had a hard time understanding the point the paper was trying to make. I think part of the difficulty stems from the sheer amount of new terminology and dense technical material present in a typical paper. Everything is new and therefore requires effort to comprehend. As you get familiar with the field, however, previously arcane concepts become easy to grasp. This also makes it easier to see the main idea of the paper: you can tune out the noise and focus on what is novel.\nPart of it comes from how unfamiliar the form of papers is. When I started research, papers felt arbitrarily formulaic. Now, I can recognize common structures in papers and use these patterns to understand the paper quicker. I actually find that papers are an efficient way for me to learn about cutting-edge research. I hoped, but did not know, that that would eventually be the case when I started.\nKeep track of where every claim comes from. I did not do a very good job keeping a lab notebook for this paper. When I started writing the paper, I had to go back to my work and try and remember where I got a particular number or why I made a particular claim. I am doing a lot better with my current project, I think. I hope the next paper is a little smoother in this regard. Writing takes a long time! We started working on this paper about 7 months ago, according to git log. There were so many drafts, edits, and revisions. Get your contributions clear. Simon Peyton-Jones gives this advice: your list of contributions should drive the paper. Moreover, writing the paper drives the research. Research is useless unless shared! Collaboration is challenging. Writing joint papers can be tricky. I am really glad we were using git to track changes. I met with my advisor twice a week in person, as well as a few times remotely to hammer out the ideas and drafts in the paper. We sent lots of messages in Slack. Asking for feedback can be hard—and I don\u0026rsquo;t just mean in the emotional pride-bruising sense: prompting the people you ask for feedback can be tricky. I asked someone for some help on a different piece of writing, and they weren\u0026rsquo;t able to give me much useful help and instead focused on trivial issues. Part of that is on me: I should have prompted better. But it is hard to prompt well.\nI find it a little curious that different kinds of people have different affinities to methods of giving feedback. With this paper, there\u0026rsquo;s a flag in LaTeX that adds line numbers to the PDF. So, if someone wants to comment on something, they can write:\nl 42: \u0026#34;that\u0026#34; → \u0026#34;which\u0026#34;; the phrase is not essential, so use \u0026#34;which\u0026#34; instead of \u0026#34;that\u0026#34; l 46: \u0026#34;rocks are a kind of vegetable\u0026#34; do we have a citation for this? … This seems natural to me. I like that it\u0026rsquo;s software-agnostic. I guess some fields are tied to particular technologies (e.g. suggested edits in Word) and that seems burdensome to me.\nSpecifically, the program chair.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":18,"href":"/posts/2024-06-03_chorex_0_1/","title":"Chorex: Guaranteeing Deadlock Freedom in Elixir","section":"Technical Blog","content":"Chorex is a brand-new Elixir library for choreographic programming [3]: Chorex provides a macro-based DSL that lets you describe how processes communicate to perform a computation. This top-down description of interacting processes is called a choreography. From this choreography, Chorex creates modules for each process that handle all the message-passing in the system. The interactions performed by the generated code will never deadlock by construction because the choreographic DSL ensures that no processes will be waiting on each other at the same time.\nThis is a research project; if you like experimenting with new things, please try this out! The best way to leave feedback is by opening an issue on the Chorex repository. Chorex is still in active development, and we would love to see whatever you make with Chorex.\nChorex is available on hex.pm. Development is on GitHub. Try it out!\nWhat does Chorex do? # Chorex enables choreographic programming in Elixir. A choreography is a birds-eye view of communicating parties in a concurrent system: you describe the different actors and how they send messages to each other. From this choreography you can create an endpoint projection, which just means you create some code for each of the concurrent actors that handles all the communication.\nChoreographic programming ensures deadlock freedom by construction. That means you will not be able to accidentally create a system of actors that accidentally deadlock. It\u0026rsquo;s still possible to have other kinds of bugs that freeze the system (e.g. one of the actors hangs on an infinite loop) but it eliminates an entire class of bug that is difficult to track down in real applications.\nAdditionally, Chorex implements higher-order choreographies [1] which let you treat choreographies as first-class citizens in your language. This improves the modularity of code built with choreographies.\nChorex does all this by leveraging Elixir\u0026rsquo;s macro system: you write down a choreography using the defchor macro provided by Chorex. The macro expands into several modules: one for each actor in your system. You then create another module for each actor in the system which use​s the respective macro-generated module; the macro-generated module handles the communication between the different parties in the choreography, and your hand-written module handles all the internal bits to that node. Let\u0026rsquo;s look at an example.\nExample of a choreography # Here\u0026rsquo;s a simple, classic example: someone wants to buy a book, so they ask the seller for the price. The seller responds with the price. Here\u0026rsquo;s a diagram of that communication:\nAnd here is the corresponding choreography describing that:\ndefmodule BookSellerChor do defchor [Buyer, Seller] do Buyer.get_book_title() ~\u0026gt; Seller.(b) Seller.get_price(b) ~\u0026gt; Buyer.(p) Buyer.(p) end end The defchor macro will create (roughly) the following code:\ndefmodule BookSellerChor do defmodule Chorex do defmodule Buyer do @callback get_book_title/0 ... end defmodule Seller do @callback get_price/1 ... end ... end end along with a __using__ macro. Now we create modules for each of our actors (Buyer, Seller) and we use the generated Chorex module to handle the communication:\ndefmodule MyBuyer do use BookSellerChor.Chorex, :buyer def get_book_title(), do: \u0026#34;Zen and the Art of Motorcycle Maintenance\u0026#34; end defmodule MySeller do use BookSellerChor.Chorex, :seller def get_price(book_title), do: ... end To kick off the choreography, start up a process for each actor and send them everyone\u0026rsquo;s PID:\nbuyer_process = spawn(MyBuyer, :init, []) seller_process = spawn(MySeller, :init, []) config = %{Buyer =\u0026gt; buyer_process, Seller =\u0026gt; seller_process, :super =\u0026gt; self()} send(buyer_process, config) send(seller_process, config) Now you can wait for the processes to send you (the parent that started the choreography) their return values. From the choreography, we expect the Buyer actor to finish with the price p. We can get that like so after sending the actors the config for the network:\nreceive do {:choreography_return, Buyer, the_price} -\u0026gt; IO.puts(\u0026#34;Got price at buyer: #{the_price}\u0026#34;) end In sum, this is how you use Chorex:\nWrite a choreography to describe your system The defchor macro will create modules for each endpoint Implement each endpoint\u0026rsquo;s derived behaviour Fire of the choreography Await replies Choreographies can get a lot more complicated than this puny example here. See the Chorex README and module documentation for more extensive examples with Chorex. Lugović and Montesi built an IRC client and server in Java with a choreography [2]—I\u0026rsquo;m excited to see what\u0026rsquo;s possible in Elixir!\nChorex goals, non-goals, and roadmap # Chorex is a research project, meaning that its primary function is to prove out new ideas. Development speed takes priority over stability of features and API. This is a scout and a trailblazer, not a surveyor and road-laying machine.\nWe would like to make Chorex as useful as possible; historically choreographic programming libraries have been cutting-edge research projects. Chorex is still research-oriented, but if we can make it useful to people other than ourselves, then that\u0026rsquo;s a big win. :) Moreover, no one has done choreographic programming with Elixir-style concurrency, where processes have mailboxes and where there are existing idioms around processes and communication.\nThis is not intended to be a production-grade system. Maybe some day, but not today. Please don\u0026rsquo;t use this to build a production system then blame us when your system goes down. Please do use this in hobby projects and let us know what you manage to build!\nFeedback # Please send us any feedback you have! You can contact me directly or open an issue on the Chorex repository. We would love to see anything you make with Chorex.\nFun details on the implementation # While building the defchor macro, I realized I needed to walk an AST and gather up a list of functions an an endpoint would need to define. This inspired me to create a writer monad; I documented how I stumbled upon a pattern that a monad solved quite elegantly earlier on my blog.\nReferences # [1]Hirsch, A.K. and Garg, D. 2022. Pirouette: Higher-order typed functional choreographies. Proceedings of the acm on programming languages. 6, (Jan. 2022), 1–27. DOI:https://doi.org/10.1145/3498684. [2]Lugović, L. and Montesi, F. 2023. Real-World Choreographic Programming: Full-Duplex Asynchrony and Interoperability. The art, science, and engineering of programming. 8, 2 (Oct. 2023), 8. DOI:https://doi.org/10.22152/programming-journal.org/2024/8/8. [3]Montesi, F. 2023. Introduction to Choreographies. Cambridge University Press. "},{"id":19,"href":"/posts/2024-05-30_top_emacs_packages/","title":"My Top Emacs Packages","section":"Technical Blog","content":"If you ask anyone what the best Emacs packages are, you\u0026rsquo;ll almost definitely hear Magit (the only Git porcelain worth using) and Org Mode (a way to organize anything and everything in plain text) listed as #1 and #2. And they\u0026rsquo;re right! I use those packages extensively every day.\nBesides those two powerhouses, there are a handful of packages that make using Emacs a delight. If I had to ever use something else, I would miss these packages most:\nAvy\nJump around your screen crazy fast. Teleport to any character with ~5 key strokes. See https://karthinks.com/software/avy-can-do-anything/ for more reasons why it\u0026rsquo;s awesome. I almost exclusively rely on avy-goto-char-timer and have it bound to s-j.\nEmbark\nKind of like a super-charged right-click for Emacs. Works beautifully in dired, when selecting files in the minibuffer. There\u0026rsquo;s an easy way to make it play well with Avy which is just the best.\nEat\nEat is a terminal emulator that\u0026rsquo;s faster almost all the other terminal emulators for Emacs. The only emulator it\u0026rsquo;s not faster than is Vterm, which is pretty dang speedy. Eat has been more than fast enough for all my needs however. Additionally, it can make a terminal emulator in a particular region, so if you use Eshell, you can get a little terminal emulator for every command you run. Normally, if you run, say, cal, you see the ugly terminal escape characters printed as text. With Eat, however, those terminal escape characters get interpreted correctly. Interactive programs (e.g. the Julia and Elixir REPLs) work flawlessly with it.\nJinx\nBest spellchecking ever. It can spellcheck based off of the fontlock face; I keep this on when I program to get on-the-fly spellchecking of code comments and strings. I keep jinx-correct bound to C-; à la flyspell because it is so darn helpful. Supports checking documents with mixed languages. This is one of the packages I miss most when I\u0026rsquo;m editing text outside of Emacs.\nCitar\nThe best way to add citations in Emacs, hands-down. Reads bibtex, inserts in org-mode, LaTeX, whatever.\nUser interface enhancement # These next packages are all by Daniel Mendler. These packages improve selecting commands, buffers, files, etc. from the completing-read and completion-at-point interfaces. These make Emacs insanely ergonomic and excellent.\nThese replace packages like Helm, Ivy/Counsel/Swiper, and Company. In comparison to these packages, Vertico + Consult + Corfu are lighter-weight, faster, less buggy (in my experience; I\u0026rsquo;ve tried them all!), and work better with other Emacs packages because they follow the default built-in APIs.\nVertico\nLighter-weight, less buggy vertical completing-read interface. Replaces Ivy. Incredibly flexible. Works out-of-the-box with everything that has a completing-read interface, so you don\u0026rsquo;t need special *-ivy packages to make it play nice. Recommend adding Marginalia as well by the same author to add extra infos.\nConsult\nBetter than counsel. The live preview is amazing; I use consult-buffer instead of switch-to-buffer, consult-line instead of Swiper. consult-ripgrep is :fire: for searching large projects with instant previewable results. Pairs well with Embark to save results to a buffer.\nCorfu\nLightweight pop-up library. Pairs well with Cape by the same author.\nSee also Orderless which enhances everything from M-x to consult-line to the Corfu popup. Vertico + Consult + Orderless + Marginalia + Corfu + Cape + Embark is sometimes called the \u0026ldquo;minad stack\u0026rdquo;. Embark and Orderless are both developed by Omar Camarena (oantolin) who frequently collaborates with Daniel Mendler. When I asked Omar on Reddit about the name, Omar replied that \u0026ldquo;minad stack\u0026rdquo; is fine; another name they\u0026rsquo;ve tried for the stack is \u0026ldquo;iceberg\u0026rdquo;, which I think is a good name too. It\u0026rsquo;s the new hotness—that said, it\u0026rsquo;s gotten really really stable over the past two years.\nIf you like these packages, consider sponsoring their maintainers! These are some of my favorite open-source projects and I try to support them when I can.\nA starter kit built on these # If you like these packages, you might like my Emacs Bedrock starter kit which, unlike many other starter kits, is meant to be a no-nonsense no-fluff no-abstraction bare-bones start for you to fork and tinker with to your liking. The stock configuration only installs one package (which-key, which is amazing) but includes some extra example configuration. The extras/base.el file includes sample starter configuration for most of the above packages. (I should add eat to it, come to think of it…)\nErrata # Eat is not the fastest terminal emulator, Vterm is. Thanks to a Redditor who pointed this out. "},{"id":20,"href":"/posts/2024-05-01_definitely_not_about_monads/","title":"Boilerplate Busting in Functional Languages","section":"Technical Blog","content":"This is the story of how I solved a problem (ugly, cumbersome boilerplate code) that I ran into while writing a program in a functional language (Elixir). Functional programming languages often pride themselves on expressiveness and elegance; but occasionally they are not amenable to the most obvious solutions to the problems we wish to solve. In this case, the simplest solution to my problem would have been to have a global mutable variable. But no one likes those.\nThe solution most programmers would have found obviates mutation, but the code ends up being rather clunky. This inelegance stems from two intertwined issues pulling the code in different directions. However, the two concerns are so intertwined that it can be difficult to see them as separate issues at all! In this blog post, I hope I can show you a new way of looking at this class of problem that will let you see what those two issues are, and how to cleanly split them apart to get nice, maintainable, functional code.\nYou take your analytic knife, put the point directly on the term Quality and just tap, not hard, gently, and the whole world splits, cleaves, right in two… and the split is clean. There’s no mess. No slop. No little items that could be one way or the other. Not just a skilled break but a very lucky break. Sometimes the best analysts, working with the most obvious lines of cleavage, can tap and get nothing but a pile of trash. And yet here was Quality; a tiny, almost unnoticeable fault line; a line of illogic in our concept of the universe; and you tapped it, and the whole universe came apart, so neatly it was almost unbelievable.\nZen and the Art of Motorcycle Maintenance, Robert M. Pirsig\nThe Setup # I will use a concrete example to describe my specific problem, though the issue is general enough that you likely have encountered it. After I walk through the example I\u0026rsquo;ll cover the essential elements that make my solution work, and how it generalizes to similar problems.\nSuppose that you are writing an application that lets people track their workout habits. Every time that they succeed in meeting a goal, they register what they accomplished. Now you have a database full of logged events like \u0026ldquo;went to the gym\u0026rdquo; or \u0026ldquo;swam 1000 m\u0026rdquo; or \u0026ldquo;ran a mile\u0026rdquo;, etc. Now you need some way to convert this set of events into reward points—preferably in a way that the user finds motivating.\nTable 1: An example of such habit records for a user. user_id date event_type event_amount 69105 2024-05-01 gym 1 69105 2024-05-02 swim 1000 69105 2024-05-03 gym 1 69105 2024-05-04 run 1.61 But every user is different, so let\u0026rsquo;s say that you make it so that users can customize exactly how goal completions translate into reward points. Somewhere in your app you let users write a little equation that your program will then evaluate against the events that they have logged. In the end, the user gets a single point value.\nSurface Syntax points = get(\u0026#34;gym\u0026#34;) * 10 + get(\u0026#34;swim\u0026#34;) * (get(\u0026#34;run\u0026#34;) + get(\u0026#34;gym\u0026#34;)) Parsed AST { \u0026#34;op\u0026#34;: \u0026#34;+\u0026#34;, \u0026#34;args\u0026#34;: [ { \u0026#34;op\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;args\u0026#34;: [ { \u0026#34;query\u0026#34;: \u0026#34;gym\u0026#34; }, { \u0026#34;num\u0026#34;: 10 } ] }, { \u0026#34;op\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;args\u0026#34;: [ { \u0026#34;query\u0026#34;: \u0026#34;swim\u0026#34; }, { \u0026#34;op\u0026#34;: \u0026#34;+\u0026#34;, \u0026#34;args\u0026#34;: [ { \u0026#34;query\u0026#34;: \u0026#34;run\u0026#34; }, { \u0026#34;query\u0026#34;: \u0026#34;gym\u0026#34; } ] } ] } ] } Evaluation result points = get(\u0026#34;gym\u0026#34;) * 10 + get(\u0026#34;swim\u0026#34;) * (get(\u0026#34;run\u0026#34;) + get(\u0026#34;gym\u0026#34;)) = 2 * 10 + 1000 * ( 1.16 + 2 ) = 3180 def interpret(user_id, {op: op, args: [arg1, arg2]}) do arg1_eval = interpret(user_id, arg1) arg2_eval = interpret(user_id, arg2) case op do \u0026#34;+\u0026#34; -\u0026gt; arg1_eval + arg2_eval \u0026#34;*\u0026#34; -\u0026gt; arg1_eval * arg2_eval end end def interpret(_user_id, {num: n}), do: n def interpret(user_id, {query: q}), do: query_db(user_id, q) Code Snippet 1: Sample interpreter for the simple language. This is, in essence, a little interpreter. I will not go over how to build an interpreter here, but the gist of it is that you walk down the AST of the equation and evaluate the leaves and nodes recursively until you wind up with a single number of points at the end.\nNow let\u0026rsquo;s say that you are processing a large number of such requests, and you would like to batch all of the database calls. In the previous example, there were four database queries, one of which (\u0026quot;gym\u0026quot;) was a duplicate. (Each get in the surface syntax or query node in the AST induces a database query.) To improve performance, you could batch all of these database calls—thereby also eliminating duplicate queries—and then have this data on hand as you walk the AST.\nSo here is the new operation we would like to perform: we want to walk through AST, collect all of the database calls into a set, and replace each instance of a database query (query nodes) in the expression to a reference (query_ref nodes) that we can link to the batched results. We will create a fresh identifier every time we encounter a new query; duplicate queries will use the first reference.\nBefore optimization { \u0026#34;op\u0026#34;: \u0026#34;+\u0026#34;, \u0026#34;args\u0026#34;: [ { \u0026#34;op\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;args\u0026#34;: [ { \u0026#34;query\u0026#34;: \u0026#34;gym\u0026#34; }, { \u0026#34;num\u0026#34;: 10 } ] }, { \u0026#34;op\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;args\u0026#34;: [ { \u0026#34;query\u0026#34;: \u0026#34;swim\u0026#34; }, { \u0026#34;op\u0026#34;: \u0026#34;+\u0026#34;, \u0026#34;args\u0026#34;: [ { \u0026#34;query\u0026#34;: \u0026#34;run\u0026#34; }, { \u0026#34;query\u0026#34;: \u0026#34;gym\u0026#34; } ] } ] } ] } After optimization { \u0026#34;op\u0026#34;: \u0026#34;+\u0026#34;, \u0026#34;args\u0026#34;: [ { \u0026#34;op\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;args\u0026#34;: [ { \u0026#34;query_ref\u0026#34;: 0 }, { \u0026#34;num\u0026#34;: 10 } ] }, { \u0026#34;op\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;args\u0026#34;: [ { \u0026#34;query_ref\u0026#34;: 1 }, { \u0026#34;op\u0026#34;: \u0026#34;+\u0026#34;, \u0026#34;args\u0026#34;: [ { \u0026#34;query_ref\u0026#34;: 2 }, { \u0026#34;query_ref\u0026#34;: 0 } ] } ] } ] } { \u0026#34;queries\u0026#34;: [\u0026#34;gym\u0026#34;, \u0026#34;swim\u0026#34;, \u0026#34;run\u0026#34;] } Now we need to implement it.\nFirst attempt # We could just create a variable that we can mutate as we walk down the tree: every time we encounter a node that looks like { \u0026quot;query\u0026quot;: _ }, we generate a fresh identifier (or look up an old one if it\u0026rsquo;s a duplicate query) and replace it with { \u0026quot;query_ref\u0026quot;: _id }. Once we\u0026rsquo;re done walking the tree, we have a new AST with query_ref nodes instead of query nodes, and a list of queries that we can execute in one go.\nThis could work, but the fact that we are using global mutable state should ring alarm bells for anyone\u0026mdash;not just functional programmers. Whenever we call our transform function, we would have to ensure that we clear out the old list of accumulated information. Don\u0026rsquo;t forget about all the other problems that global mutable state brings. There must be a better way.\nSecond attempt # How might our function be more pure? Instead of just returning a modified tree, we can return a tuple of the new AST node plus a list of queries. (I\u0026rsquo;ll call this specific shape an AST-queries-tuple throughout.) This eliminates the need for a global variable, and now every call to our optimization function is pure. It\u0026rsquo;s easier to test and reason about.\ndef transform_queries({:query, query_text}) do query_id = fresh_query_id() {{:query_ref, query_id}, [{query_id, query_text}]} end def transform_queries({:+, lhs, rhs}) do {new_ast_l, queries_l} = transform_queries(lhs) {new_ast_r, queries_r} = transform_queries(rhs) {{:+, new_ast_l, new_ast_r}, queries_l ++ queries_r} end … However, this means that we have to take care to combine this information whenever we do a recursive call. It becomes even more cumbersome when we recur over elements in a list and we need to combine all their results together. A well-crafted reduce makes things work OK, but I think you can agree the following code isn\u0026rsquo;t the most straightforward to read and understand what\u0026rsquo;s going on.\ndef transform_queries({:max, args}) do # args is a list args |\u0026gt; Enum.map(\u0026amp;transform_queries) |\u0026gt; Enum.reduce(fn {x, qs}, {max_acc, q_acc} -\u0026gt; {max(x, max_acc), qs ++ q_acc} end) end This is quite a bit of boilerplate. It\u0026rsquo;s not the worst code ever—it\u0026rsquo;s certainly better than our first solution with a global variable—but we seem to be saying more than we need to here.\nFinding the cleavage point # How can we clean up this code? The code is messy because there are actually two competing concerns here: we have some main computation that we care about (transforming the tree) and some side information (the set of database queries) that we\u0026rsquo;d like to collect in parallel. If we can separate these concerns, our code will improve.\nNow that we see the two intertwined issues, how do we go about separating them? We will still carry around the AST-queries-tuple, but we are going to pull out the logic that governs how we keep track of the list of queries and keep it separate from the AST transformation logic.\nFirst, let\u0026rsquo;s define a module, a type to help us keep track of an AST-queries-tuple, and a function wrap that takes some AST and pairs it with an empty list of queries:\ndefmodule AstList do @type t() :: {Ast.t(), [Query.t()]} @spec wrap(Ast.t()) :: t() def wrap(v), do: {v, []} end Second, the clever bit: we write a function that lets us manipulate the AST value inside the tuple without worrying about how to combine the sets of queries. We\u0026rsquo;ll call this function thread, and it takes an AST-queries-tuple and gives it to a function argument that expects just the AST bit. That function argument should return a new AST-queries-tuple. Our function thread will then merge the two lists of queries together without the function parameter ever having to worry about it.\n@spec thread(t(), (Ast.t() -\u0026gt; t())) :: t() def thread({ast, queries}, f) do {new_ast, new_queries} = f.(ast) {new_ast, new_queries ++ queries} end Now we can use this to write our transform_queries function! Before we get there, remember that Elixir has a handy set of customizable infix operators that we can use as shorthand: It would be nice if we could use \u0026gt;\u0026gt;= for this shorthand… but I\u0026rsquo;m getting ahead of myself. def m ~\u0026gt;\u0026gt; f, do: thread(m, f) That means that instead of writing this:\ndef transform_queries({:+, lhs, rhs}) do {new_ast_l, queries_l} = transform_queries(lhs) {new_ast_r, queries_r} = transform_queries(rhs) {{:+, new_ast_l, new_ast_r}, queries_l ++ queries_r} end We can just write:\ndef transform_queries({:+, lhs, rhs}) do transform_queries(lhs) ~\u0026gt; fn new_lhs -\u0026gt; transform_queries(rhs) ~\u0026gt; fn new_rhs -\u0026gt; wrap({:+, new_lhs, new_rhs}) end end end You might be able to see now how this would make writing this little optimization pass a lot cleaner. We can go a step further on the syntax though: with a little metaprogramming imagination, we can write some shorthand for the ~\u0026gt; notation that looks more like variable assignment in a with. It\u0026rsquo;s not that hard to do.\ndefp transform_threading([{:\u0026lt;-, _, [var, expr]} | rst]) do quote do unquote(expr) ~\u0026gt;\u0026gt; fn unquote(var) -\u0026gt; unquote(transform_threading(rst)) end end end defp transform_threading([expr]), do: expr defmacro threading (do: {:__block__, _, lines}) do transform_threading(lines) end Now we can write the handler for + like so:\ndef transform_queries({:+, lhs, rhs}) do threading do new_lhs \u0026lt;- transform_queries(lhs) new_rhs \u0026lt;- transform_queries(rhs) wrap({:+, new_lhs, new_rhs}) end end And that gets transformed into the nested anonymous function notation we saw previously.\nWhat do we get? # Now we don\u0026rsquo;t have to think about merging the list of queries any more: the ~\u0026gt;\u0026gt; operator handles all that for us. Bigger savings come if we think about making a version of map that works with our AST-queries-tuples. We\u0026rsquo;ll call it mapM since it\u0026rsquo;s like a map that we\u0026rsquo;re mashing the results together:\n@spec mapM(vs :: [Ast.()], f :: (Ast.t() -\u0026gt; t())) :: t() def mapM(vs, f) do results = vs |\u0026gt; Enum.map(f) { results |\u0026gt; Enum.map(\u0026amp;elem(\u0026amp;1, 0)), results |\u0026gt; Enum.map(\u0026amp;elem(\u0026amp;1, 1)) |\u0026gt; Enum.reduce([], \u0026amp;++/2) } end Here we map over a list of Ast values, collect all the resulting sets of queries, and merge them together. This gives us a big savings when we write something like the max function:\nNew version def transform_queries({:max, args}) do args |\u0026gt; mapM(\u0026amp;transform_queries) ~\u0026gt;\u0026gt; \u0026amp;wrap({:max, \u0026amp;1}) end Old version def transform_queries({:max, args}) do # args is a list args |\u0026gt; Enum.map(\u0026amp;transform_queries) |\u0026gt; Enum.reduce(fn {x, qs}, {max_acc, q_acc} -\u0026gt; {max(x, max_acc), qs ++ q_acc} end) end Notice that all the handling of the extra information has been lifted out of our code. Not only does it make it clearer what the core intent of the functions are, but we also get some added flexibility around how we structure that extra data. If we wanted to use a map or a set instead of a list of tuples as the second element in the AST-queries-tuple, then with this refactoring we only have to modify the wrap, thread, and mapM functions. The rest of the code can stay the same!\nSo, with a little bit of work, we\u0026rsquo;ve gone from a solution using global mutable state 🤢 to passing around a AST-queries-tuple 😐 to abstracting out the tuple entirely, gaining clarity and flexibility along the way. 🤩 Our threading-related functions are actually generic enough that they don\u0026rsquo;t need to be about ASTs and lists of queries—as long as we are doing some main computation with a little extra data gathering on the side, this pattern should apply.\nWouldn\u0026rsquo;t it be nice if this pattern had a name?\nIt was a monad all along! # Surprise! This is exactly the writer monad! This whole post has been a monad tutorial in disguise!\nIf you\u0026rsquo;ve been exposed to monads before, you might recognize wrap as return and thread as bind or—as the Haskell programmers like to call it\u0026mdash;\u0026gt;\u0026gt;=. The thread do … end macro is just do notation. (I couldn\u0026rsquo;t think of a clever name for mapM, so I just pretended the M stood for mash instead of monad.)\n\u0026ldquo;Monad\u0026rdquo; is just an interface. There\u0026rsquo;s a subtle difference between interfaces and typeclasses, and I\u0026rsquo;ll get to that shortly. This is meant to build intuition. That\u0026rsquo;s all there is to it. To make your data structure (like our AST-queries-tuple) conform to the Monad interface, you need functions like wrap and thread. Once you have those, you have a monad. OK, there are certain properties (called the \u0026ldquo;monad laws\u0026rdquo;—don\u0026rsquo;t worry, they\u0026rsquo;re not that scary even though the name sounds ominous) that these functions need to satisfy, but they\u0026rsquo;re pretty easy to hit. If you don\u0026rsquo;t satisfy these laws, your monad won\u0026rsquo;t behave predictably in certain circumstances. If you\u0026rsquo;re getting started with monads, don\u0026rsquo;t worry about it right now. That\u0026rsquo;s pretty much all there is to it.\nDifferent kinds of monads # There isn\u0026rsquo;t a fixed number of monads; there are however a set of more-or-less \u0026ldquo;standard\u0026rdquo; monads which have been discovered to be generally useful; the Haskell Wiki has a nice list here. Among these is the \u0026ldquo;maybe\u0026rdquo; monad, which lets you focus on the happy-path of computation and abstracts away the failure path. In Elixir, you can see this pattern with the {:ok, term()} | :error idiom. (The with notation commonly seen in this idiom closely follows Haskell\u0026rsquo;s do notation.) There are many other useful monads besides the writer and maybe monads. Some of these (like the IO monad) are pretty specific to Haskell and other pure functional languages that don\u0026rsquo;t support the same kinds of control flow or constructs; others have wider application.\nWhat monad tutorials get wrong # Most of the value (I think) of monads is not having return and bind, but all the helper functions like mapM, do notation, and friends. While I was writing some Haskell, I got to know all the monad-related functions and how useful they were. These helper functions are what make programming with monads natural and powerful. The core functions bind and return are all you \u0026ldquo;need\u0026rdquo; to make a monad, but no one would actually program with just those.\nIf you ever find something that you think would work well modeled as a monad, be sure to implement additional functions beyond bind and return. You can see a list of functions Haskell implements for monads here if you want some inspiration.\nWhy Haskell uses monads so much # You hear a lot about monads with languages like Haskell, but not so much with other functional languages like Elixir or Rust. Part of this is need, and part is because of ergonomics.\nHaskell needs monads to implement effectful computation. Effects include exceptions (modeled by the maybe monad) or logging information (the writer monad). Languages that have these effects natively don\u0026rsquo;t strictly need these monads. (Though, as we\u0026rsquo;ve seen, writing a monad can help other languages, even when they have uncontrolled side-effects, like Elixir.)\nHaskell makes using monads ergonomic through its typeclass mechanism. Other languages have more constrained method dispatching mechanisms, so you have to jump through some hoops to get monads to work as seamlessly as they do in Haskell.\nTypeclasses vs. interfaces # If you\u0026rsquo;re familiar with an OO language, you\u0026rsquo;ve almost certainly come across the idea of an interface: it\u0026rsquo;s just a specification of methods an object needs to implement. Typeclasses are similar: they specify a set of functions needed for a type to belong to a typeclass. There are a few key differences between typeclasses and interfaces however:\nInterfaces are closed, meaning, if an object doesn\u0026rsquo;t implement the interface, you can\u0026rsquo;t do anything about it, unless you modify the definition of the object itself.\nIn contrast, typeclasses are open, meaning that I can implement the requisite functions to turn a datatype into a monad, even if I can\u0026rsquo;t modify the definition of the datatype itself.\nInterfaces specify methods that dispatch on their object. If I call thing.dance(), then I will look up the dance method in whatever class thing belongs to.\nTypeclass functions can dispatch on the return type of the function. For example, the wrap (i.e. return) function needs to dispatch on whatever type it\u0026rsquo;s expected to return. If I said something like:\nthing1 :: Robot = return \u0026#34;Marvin\u0026#34; thing2 :: Person = return \u0026#34;Arthur\u0026#34; return would dispatch to the version specified for the Robot type for thing1, and Person\u0026rsquo;s implementation for thing2. This makes the monad functions really generic; with a return that can dispatch on the expected return type, you can write return without thinking much about which monad exactly you\u0026rsquo;re using.\nUsing monads in non-Haskell languages # In languages that don’t have typeclasses, you need to take special steps to ensure that you dispatch to the proper variant of the monad. Racket has a monad library that works via a generics interface system, plus a few tricks to teach return (called pure in this library) what type it should return. I am sure the same tricks would apply to Elixir. Indeed, Elixir has protocols, which are like interfaces, but they are open. They still dispatch on the shape of the first argument passed to them, you would need to pull a trick like Racket\u0026rsquo;s pure function and pass an argument to ignore just to get the dispatch right.\nElixir has less need for monads than Haskell because its functions are impure. (A function can do arbitrary IO, send messages, throw exceptions, etc.) but there are still cases (as we have seen) where a monad can make life easier. Consider using a monad library the next time you need to avoid ugly side-effects!\nBreaking boilerplate in your functional projects # Functional languages are not immune to sprouting boilerplate. And while most of the design patterns in a certain OO cookbook are \u0026ldquo;invisible or simpler\u0026rdquo; in functional languages, Quote from Peter Norvig. See: https://norvig.com/design-patterns/design-patterns.pdf some patterns crop up when similar problems arise.\nMonads are a powerful tool for dividing the essential from the incidental in a program. Exactly what constitutes the essential versus incidental parts—along with how to separate them—can be tricky to see at first. I think this is because separating these concerns in mainstream functional languages get less visibility, and not because of any inherent difficulty of the problem. Perhaps if everyone started out programming by learning Racket and got comfortable with functional idioms, monads would be as natural as the Visitor pattern. Certainly it would be more comfortable than the AbstractSingletonProxyFactoryBean! I was surprised and delighted when a monadic solution appeared as the most natural solution to a problem I was working on. Now, you might say that\u0026rsquo;s because I work as a programming languages researcher. However, the last two times I was working in industry, we had some sort of language interpreter, and I had to walk an AST. Knowing the writer monad would have saved me a lot of time and effort. I hope you can start seeing some monadic patterns in your code, and that you\u0026rsquo;ll be able to make a monad to make it easier to reason about and refactor your code as well.\nFurther reading # https://wiki.haskell.org/All_About_Monads https://learnyouahaskell.com/a-fistful-of-monads Acknowledgements # Thanks to Scott Wiersdorf for the initial impetus to write this, as well as some thoughtful feedback on the prose and outline. Thanks also to Mark Ericksen for some additional comments.\n"},{"id":21,"href":"/posts/2024-03-27_haskell_editor_part_1/","title":"Building a Text Editor in Haskell, Part 1","section":"Technical Blog","content":"I am building a little text editor in Haskell.1 Why would I do such a thing? Because I\u0026rsquo;m in a class and this fulfills the requirement, and building a text editor is the kind of thing that I\u0026rsquo;ve always wanted to take a crack at.\nThis is part 1, and I will describe how to build a rope data structure in Haskell. A rope is a bunch of strings (literally, and in the CS sense) and is optimized for cheap edits. You can see my implementation on Codeberg.\nWhy ropes? # This has probably been discussed ad nauseam, but I\u0026rsquo;ll throw a brief justification for using a rope here to save you a click/search. Warning: this is not going to be in-depth or anything, so if you\u0026rsquo;re not persuaded that e.g. ropes are a good idea, it\u0026rsquo;s probably because I am trying to be brief here.\nHere\u0026rsquo;s the problem: when you\u0026rsquo;re working in a text editor, you usually are doing edits somewhere in the middle of the file. If you were to store a buffer of \\(n\\) characters in an array, inserting a character at position \\(i\\) would mean that you have to move all \\(n - i\\) characters after that point over one slot in memory—which gets extremely expensive for even moderately sized files. This leaves out the complexity of having to re-allocate the array periodically as it grows. Yuck!\nRopes, on the other hand, store bits of text in a balanced binary tree. Inserting some text never mutates existing nodes; instead, new nodes from the modified leaf up to the root (so, roughly \\(\\log(n)\\) nodes) need to be allocated on insertion.\nThis comes with two benefits: first, insertion and deletion scale extremely well. Second, since the structure is immutable, you could store the last \\(k\\) copies of the string to implement an \u0026ldquo;undo\u0026rdquo; feature in your editor. Moreover, all the chunks that didn\u0026rsquo;t get changed don\u0026rsquo;t take up any extra space, since the data structure enjoys nice structural sharing.\n\u0026ldquo;But what about all those nodes you need to allocate?\u0026rdquo; you might well ask. Modern garbage collectors are so good these days you won\u0026rsquo;t even notice. As soon as you\u0026rsquo;re working with a new copy of the string, or as soon as a copy of the string you\u0026rsquo;ve been holding onto in your undo buffer gets bumped out, the garbage collector is sure to swiftly reclaim any nodes no longer in use.\nBenchmarks # I implemented a rope and ran some benchmarks, comparing it with a naïve string insertion algorithm. Note: reproducing these in other languages will differ based on how your language implements strings. I\u0026rsquo;m using Haskell, which represents strings as linked lists of characters. This has some trade-offs:\nIndexing into the \\(n\\) -th element takes \\(O(n)\\) time, which isn\u0026rsquo;t great. However, joining a string onto the head of another only requires that you walk the first string to its end; you do not have to walk the entire length of the end string. Figure 1: Benchmark report comparing a series of random edits applied to a rope vs. a string. The rope shows minimal difference in time taken to perform 10 random edits (4.03 μs = 0.004 ms) to 10,000 edits (28.1 ms). In contrast, the naïve string implementation jumps from 2.56 μs = 0.002 ms for 10 edits all the way to 3.6 s = 3600 ms for 10,000 edits.\nI tried running the benchmarks for 100,000 random edits, and the last benchmark never finished even though I let it sit for over an hour. Arrays of characters are not sustainable for editors.\nBuilding a rope # The original rope paper [1] and the Wikipedia article on ropes both do a fine job of explaining the data structure. I\u0026rsquo;ll just outline some gotchas here.\nThe data structure # Here\u0026rsquo;s my definition of a rope:\ndata Rope = Concat Int Int Rope Rope -- Concat length height left right | Leaf Int String -- Leaf length content deriving (Show, Eq) A rope is either a Leaf node or a Concat​enation of two rope nodes. The Leaf variant contains two fields: a regular ol\u0026rsquo; string as well as how long the string is.2 The Concat variant holds left and right subtrees, the total length of its subtrees, and how high up in the tree it is. (This is important for balancing later on.)\nThe string gets broken up between the leaves and the concat nodes hold everything together.\nWhy do Concat nodes need to hold their length? This is to speed up searching through the tree: since every node knows how long the string underneath it is, we don\u0026rsquo;t need to go all the way down to the leaves to figure out where in the string we should jump if we\u0026rsquo;re looking for, say, the 1000th character. This keeps accesses \\(O(\\log(n))\\) which is pretty fast.\nBalancing algorithm # The balancing algorithm is the trickiest part of implementing a rope, and it\u0026rsquo;s a bit of a shame that the paper doesn\u0026rsquo;t have better examples. I did use the paper as a reference to implement the algorithm, so it was clear enough, but more examples are always good!\nAlternatives to ropes # The Rhombus language uses an RRB tree [2] for it\u0026rsquo;s primary list data structure. RRB trees would probably work pretty well for text editing. You can see the Rhombus implementation on GitHub.\nReferences # [1]Boehm Hans‐J., Atkinson, R. and Plass, M. 1995. Ropes: An alternative to strings. Software: Practice and experience. 25, 12 (Dec. 1995), 1315–1330. DOI:https://doi.org/10.1002/spe.4380251203. [2]Stucki, N., Rompf, T., Ureche, V. and Bagwell, P. 2015. RRB vector: A practical general purpose immutable sequence. Proceedings of the 20th ACM SIGPLAN International Conference on Functional Programming (Vancouver BC Canada, Aug. 2015), 342–354. I call it \u0026ldquo;ysue\u0026rdquo;, for Y​ou S​hould be U​sing E​macs. It actually works! I used it to edit its own source code! Get it here: https://codeberg.org/ashton314/ysue\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nHaskell strings are linked lists. This is nice for all sorts of functional operations, but it means that they don\u0026rsquo;t track how long they are. (As far as I know.) If you use a language that can get the length of the string in \\(O(1)\\) time, you might not need this.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":22,"href":"/posts/2023-12-20_functional_langauge_speed/","title":"Functional Languages Need Not Be Slow","section":"Technical Blog","content":"Somewhere in my adolescence I got stuck with the notion that functional languages were slow while languages like C were fast. Now, a good C programmer can eke more performance out of their code than probably anyone else, but the cost you pay to keep your code correct goes exponential as you get closer and closer to the machine.\nFunctional languages abstract a lot away from the machine. Higher languages in general abstract away the machine and make code easier to maintain. So I think I had it in my head that functional languages, being far away from the bare metal, must necessarily be slow. It didn\u0026rsquo;t help that I also thought of functional languages as being necessarily interpreted languages.\nTurns out, functional languages are just as amenable to compilation as imperative ones. Many popular/well-known functional are in fact compiled. (E.g. Haskell, Scala, Rust, Julia, etc.) Moreover, these languages can be just as fast—if not faster—than their more \u0026ldquo;mainstream\u0026rdquo; counterparts.\nI wanted to pit my favorite language (Racket) against a slightly more well-known language (Python) to see how they handled a simple single-threaded program. For good measure I threw Rust, Julia, and JavaScript into the mix for comparison.\nIf you\u0026rsquo;re impatient, just jump to the results.\nThe programs # I wrote the original program in Racket, then had ChatGPT help me rewrite it in Python. ChatGPT did astoundingly well. I eventually rewrote the program to be a little more idiomatic—I wanted it to use a loop instead of tail recursion, as Python is much better with loops than it is with lots and lots of function calls. I also had ChatGPT help me rewrite the program to Rust, Julia, and JavaScript. Impressive—and unsettling.\n#lang racket (define (count-collatz n [cnt 1]) (cond [(= n 1) cnt] [(even? n) (count-collatz (/ n 2) (+ 1 cnt))] [else (count-collatz (+ (* 3 n) 1) (+ 1 cnt))])) (define (count-collatz-upto n) (for/fold ([max-seen 0]) ([i (in-range 1 n)]) (max max-seen (count-collatz i)))) (displayln (format \u0026#34;\\nDone ~a\u0026#34; (count-collatz-upto 5000000))) Code Snippet 1: collatz_check.rkt def count_collatz(n): cnt = 1 while n != 1: if n % 2 == 0: n = n // 2 cnt += 1 else: n = 3 * n + 1 cnt += 1 return cnt max_seen = 0 def count_collatz_upto(n): global max_seen for i in range(1, n): the_count = count_collatz(i) max_seen = max(max_seen, the_count) return 42 count_collatz_upto(5000000) print(\u0026#34;\\nDone\u0026#34;, max_seen) Code Snippet 2: collatz_check.py fn count_collatz(n: u64) -\u0026gt; u64 { let mut cnt = 1; let mut num = n; while num != 1 { if num % 2 == 0 { num /= 2; } else { num = num * 3 + 1; } cnt += 1; } cnt } fn count_collatz_upto(n: u64) -\u0026gt; u64 { let mut max_seen = 0; for i in 1..n { max_seen = max_seen.max(count_collatz(i)); } max_seen } fn main() { println!(\u0026#34;Done {}\u0026#34;, count_collatz_upto(5000000)); } Code Snippet 3: collatz_check.rs function count_collatz(n::Int) cnt = 1 while n != 1 if n % 2 == 0 n = n ÷ 2 cnt += 1 else n = 3 * n + 1 cnt += 1 end end return cnt end max_seen = 0 function count_collatz_upto(n::Int) for i in 1:n-1 the_count = count_collatz(i) global max_seen = max(max_seen, the_count) end return 42 end count_collatz_upto(5000000) println(\u0026#34;\\nDone \u0026#34;, max_seen) Code Snippet 4: collatz_check.jl function countCollatz(n) { let cnt = 1; while (n !== 1) { if (n % 2 === 0) { n = n / 2; } else { n = 3 * n + 1; } cnt++; } return cnt; } function countCollatzUpto(n) { let maxSeen = 0; for (let i = 1; i \u0026lt; n; i++) { maxSeen = Math.max(maxSeen, countCollatz(i)); } return maxSeen; } console.log(`\\nDone ${countCollatzUpto(5000000)}`); Code Snippet 5: collatz_check.js The results # I ran these programs on my M1 Pro MacBook Pro. Here\u0026rsquo;s what I got:\nLanguage Time (seconds) Racket 4.68 Python 34.27 Rust 3.03 Julia 2.34 JavaScript 11.92 In graphical form:\nWow! I did not expect Python to get so pummeled by everything else! It makes sense that Julia with its sweet JIT engine is the fastest. Rust does well—no surprise there. (Note that I\u0026rsquo;m not counting compilation time here—all the more impressive for Julia!) Racket holds its own though, coming in third place by a wide margin. If you did take Rust\u0026rsquo;s compile time into account, I think that would make it switch places with Racket. Of course, you use Rust for compile-once-run-lots sorts of scenarios.\nDiscussion # Are these authoritative? No, of course not. This is a simple synthetic benchmark. I don\u0026rsquo;t consider myself expert programmer in any of these languages, so there are likely some performance tweaks that could make the respective language\u0026rsquo;s benchmark run faster. (Maybe I should in Racket… it\u0026rsquo;s kind of hard to consider yourself an expert in a language when its creator works down the hall from you though.)\nThat said, I hope this dispels the myth that functional languages are necessarily slow. That is not the case. If Python is fast enough for your use-case, then there\u0026rsquo;s no reason you shouldn\u0026rsquo;t consider using Racket on performance grounds.\nLibrary support is a different matter: of all the programming that goes on in the world, the majority is probably just gluing libraries together to do the thing you want. This is a good thing: it means we\u0026rsquo;re not reinventing so many wheels and people are getting good work done.\nThat said, there\u0026rsquo;s plenty of exciting work for which no library exists! If you find yourself in one of these exciting cases, consider using the tool of maximum power: in this regard, nothing beats Racket for its flexibility and extensibility.\nBonus: building the graph in Racket # I love the Racket Plot library. So easy to use, so powerful. If you run it inside of DrRacket, the graphs are actually interactive: you can rotate 3D graphs and zoom in on sections of 2D graphs. So neat!\nHere\u0026rsquo;s the code I used to generate the above graph:\n#lang racket (require plot) (define *data* (list #(\u0026#34;Racket\u0026#34; 4.68) #(\u0026#34;Python\u0026#34; 34.27) #(\u0026#34;Rust\u0026#34; 3.03) #(\u0026#34;Julia\u0026#34; 2.34) #(\u0026#34;JavaScript\u0026#34; 11.92))) (parameterize ([plot-font-face \u0026#34;Charter\u0026#34;] [plot-font-size 14.0] [plot-x-ticks (linear-ticks #:number 10 #:divisors \u0026#39;(1 2 5))]) (plot (list (discrete-histogram (reverse *data*) #:gap 0.3 #:invert? #true)) #:title \u0026#34;Simple benchmark results\u0026#34; #:out-kind \u0026#39;svg #:out-file \u0026#34;benchmark_shootout.svg\u0026#34; #:x-max 35 #:x-label \u0026#34;Seconds\u0026#34; #:width 800 #:height 200)) "},{"id":23,"href":"/posts/2023-10-17_fearless_macros/","title":"Towards Fearless Macros","section":"Technical Blog","content":"Macros are tricky beasts. Most languages—if they have macros at all—usually include a huge \u0026ldquo;here there be dragons\u0026rdquo; warning to warn curious would-be macro programmers of the dangers that lurk ahead.\nWhat is it about macros that makes them so dangerous and unwieldy? That\u0026rsquo;s difficult to answer in general: there are many different macro systems with varying degrees of ease-of-use. Moreover, making macros easy to use safely is an open area of research—most languages that have macros don\u0026rsquo;t have features necessary to implement macros safely. Hence, most people steer clear of macros.\nThere are many ways to characterize macro systems; I won\u0026rsquo;t attempt to cover them all here, but here\u0026rsquo;s the spectrum I\u0026rsquo;ll be covering in this post:\nFigure 1: A spectrum of how easy macro systems are to use safely\nC macros: advanced search-and-replace # If you\u0026rsquo;ve done any C programming, you\u0026rsquo;ve likely run into things like:\n#define FOO 42 printf(\u0026#34;The answer is: %s\\n\u0026#34;, FOO); /* prints \u0026#34;The answer is: 42\u0026#34; */ That #define bit is a macro—albeit a C macro. These operate just after the lexer: they work on token streams. It\u0026rsquo;s a bit like textual search-and-replace, though it knows a little bit about the structure of the language (not much: just what\u0026rsquo;s a token and what\u0026rsquo;s not) so that you won\u0026rsquo;t run into problems if you do something like this:\n#define FOO 42 printf(\u0026#34;It says FOO\u0026#34;); /* prints \u0026#34;It says FOO\u0026#34; not \u0026#34;It says 42\u0026#34; */ because that FOO in the string is not a token—it\u0026rsquo;s just part of a string.\nC macros can\u0026rsquo;t do very much: you scan the token stream for a macro, then fill in the variables to the macro, and then replace the macro and the arguments its consumed with the filled-out template that is the macro definition. This prevents you from doing silly things like replacing something sitting inside of a string literal, but it\u0026rsquo;s far, far from being safe, as we\u0026rsquo;ll see in the next section.\nLisp macros: operating on ASTs # In contrast to C\u0026rsquo;s macros, Lisp\u0026rsquo;s macros are much more powerful. Lisp macros operate after the lexer and the parser have had a go at the source code—Lisp macro operate on abstract syntax trees\u0026mdash;or ASTs, which is what the compiler or interpreter works with.\nWhy is this a big deal? The ASTs capture the language\u0026rsquo;s semantics around precedence, for instance. In C you can write a macro that does unexpended things, like this:\n#define DOUBLE(x) x + x 3 * DOUBLE(5); /* Does 3 * 5 + 5 = 20, not 3 * (5 + 5) = 30 */ The DOUBLE macro didn\u0026rsquo;t know anything about precedence and we computed the wrong thing. This means that, to use a macro in C, you have to have a good idea of how it\u0026rsquo;s doing what it\u0026rsquo;s intended to do. That means C macros are leaky abstractions that prevent local reasoning: you have to consider both the macro definition and where it\u0026rsquo;s used to understand what\u0026rsquo;s going on.\nIn contrast, Lisp macros are an improvement because they will rewrite the AST and the precedence you\u0026rsquo;d expect will be preserved. You can do this, for example:\n(defmacro double (x) `(+ ,x ,x)) (* 3 (double 5)) ; returns 30 Lisp macros are also procedural macros, meaning you can execute arbitrary code inside of a macro to generate new ASTs. Macros in Lisp and its descendants are essentially functions from AST → AST. This opens up a whole world of exciting possibilities! Procedural macros constitute a \u0026ldquo;lightweight compiler API\u0026rdquo;. [4]\nScheme macros: hygiene # \u0026ldquo;Same except for variable names\u0026rdquo; is also called alpha-equivalence. This comes from the λ-calculus, which states that the particular choice of variable name should not matter. E.g. \\(\\lambda x.x\\) and \\(\\lambda y.y\\) are the same function in the lambda calculus, just as \\(f(x) = x \u0026#43; 2\\) and \\(g(y) = y \u0026#43; 2\\) are the same function in algebra.\nLisp macros aren\u0026rsquo;t without danger—many a Lisp programmer has shot their foot off with a macro. One reason is that Lisp macros are not hygienic\u0026mdash;variables in the macro\u0026rsquo;s implementation may leak into the context of the macro call. This means that two Lisp programs that are the same except for different variable names can behave differently:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 (defmacro swap (x y) `(let ((tmp ,x)) ; (tmp-leaky) (setq ,x ,y) (setq ,y tmp))) (let ((foo 1) (bar 2)) (swap foo bar) (list foo bar)) ; produces \u0026#39;(2 1) (let ((tmp 1) (baz 2)) (swap tmp baz) ; (tmp-capture) (list tmp baz)) ; produces \u0026#39;(1 2) --- no swap! The fact that the macro implementation uses a variable named tmp (tmp-leaky) has leaked through to the user of the macro. (tmp-capture) This phenomenon is called variable capture, and it exposes this macro as a leaky abstraction! There are ways to mitigate this using gensym, but those are error-prone manual techniques. It makes macro writing feel like you\u0026rsquo;re writing in an unsafe lower-level language.\nScheme\u0026rsquo;s macros introduce a concept known as hygiene, which prevents variable capture automatically:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 (define-syntax swap (syntax-rules () ((swap a b) (let ((tmp a)) ; (tmp-intro-macro) (set! a b) (set! b tmp))))) (let ((foo 1) (bar 2)) (swap foo bar) (list foo bar)) ; produces \u0026#39;(2 1) (let ((tmp 1) ; (tmp-intro-let) (baz 2)) (swap tmp baz) (list tmp baz)) ; still produces \u0026#39;(2 1) In this case, the variable tmp that the swap macro introduces (tmp-intro-macro) is not the same thing that the variable tmp from the calling context (tmp-intro-let) refers to. This separation of scopes happens automatically behind the scenes, so there\u0026rsquo;s now no chance of accidental variable capture. Breaking hygiene has some utility in some cases—for example, one might want to add a break form inside the body of a loop. There are ways around hygiene, but these are not without some problems. For more details see [2]. If you\u0026rsquo;d like to know more about hygiene, [1] is an excellent resource.\nRacket macros: phase separation and scope sets # Since Scheme macros (and Lisp macros more generally) allow running arbitrary Scheme code—including code from other modules—the dependency graph between modules can get so tangled that clean builds of a Scheme codebase are impossible. Racket solves this problem with its phase separation, which puts clear delimiters between when functions and macros are available to different parts of the language. This detangles dependency graphs without sacrificing the expressive power of macros. I wrote a little bit about phase separation; you can read more on the Racket docs as well as Matthew Flatt\u0026rsquo;s paper [3] on phase separation.\nRacket also has a robust system for reasoning about where a variable\u0026rsquo;s definition comes from called a scope set. This is a notion makes reasoning about where variables are bound sensible. See a blog post as well as [NO_ITEM_DATA:flattBindingSetsScopes2016b] by Matthew Flatt for more on scope sets.\nPhase separation and scope sets make Racket macros the safest to use: Racket macros compose sensibly and hide their implementation details so that it is easy to write macros that are easy to use as if they were built-in language constructs.\nRacket also goes beyond the syntax-rules form that it inherited from Scheme; Racket\u0026rsquo;s syntax-parse macro-building system makes generating good error messages easy.\nThere\u0026rsquo;s a little bug in the swap macro we used earlier, and that is the set! form only takes an identifier (i.e. a variable) as its first argument. We don\u0026rsquo;t have any error checking inside the macro; if we were to call swap with something that wasn\u0026rsquo;t an identifier, we\u0026rsquo;d get an error in terms of the set! the macro expands to, not the macro call itself:\n(let ((foo 1) (bar 2)) (swap (+ foo 1) bar) (list foo bar)) \u0026gt; (swap (+ foo 1) bar) set!: not an identifier at: (+ foo 1) in: (set! (+ foo 1) bar) This isn\u0026rsquo;t good because there\u0026rsquo;s no set! in our code at all! We could add some error handling in our macro to manually check that a and b are identifiers, but that\u0026rsquo;s a little tedious. Racket\u0026rsquo;s syntax-parse helps us out:\n(require syntax/parse/define) (define-syntax (swap stx) (syntax-parse stx [(_ a:id b:id) #\u0026#39;(let ([tmp a]) (set! a b) (set! b tmp))])) (let ([tmp 1] [baz 2]) (swap tmp baz) (list tmp baz)) ; returns \u0026#39;(2 1) as expected (let ([foo 1] [bar 2]) (swap (+ foo 1) bar)) swap: expected identifier at: (+ foo 1) in: (swap (+ foo 1) bar) Much better! Now our error is in terms that the macro user will recognize. There are lots of other things that syntax-parse can do that make it easy to write correct macros that generate good error messages—a must for macros that become a part of a library.\nOther languages # Many modern languages use macros; I\u0026rsquo;ll only talk about a few more here. If something\u0026rsquo;s missing, that\u0026rsquo;s probably because I didn\u0026rsquo;t want to be exhaustive.\nJulia # Julia macros have a lot of nice things: they operate on ASTs and they\u0026rsquo;re hygienic, though the way hygiene is currently implemented is a little strange: all variables get gensym\u0026rsquo;d automatically Meaning, they all get replaced with some generated symbol that won\u0026rsquo;t clash with any possible variable or function name. whether or not they come from inside the macro or they originated from the calling code.\nPart of the problem is that all variables are represented as simple symbols, which [1] shows is insufficient to properly implement hygiene.\nEvidently there is some ongoing work to improve the situation. This is a good example of research ideas percolating into industry languages I think.\nElixir # Elixir has robust AST macros, and its standard library makes heavy use of macros; many \u0026ldquo;core\u0026rdquo; Elixir constructs like def, if, raise, |\u0026gt;, and others are actually macros that expand to smaller units of Elixir.\nElixir actually gets hygiene right! Unlike Julia, variables in Elixir\u0026rsquo;s AST have metadata—including scope information—attached to them. This and other aspects of Elixir\u0026rsquo;s macro system open it up to lots of exciting possibilities. The Nx library brings support for numerical and GPU programming to Elixir, and it works essentially by implementing a custom Elixir compiler in Elixir itself, and macros play a big role in this.\nMe thinking that Elixir is a big mainstream language should tell you something about the languages I spend my time with in my job as a PhD student.\nI think Elixir macros are really neat—they\u0026rsquo;re the most powerful I\u0026rsquo;ve seen in a \u0026ldquo;big mainstream\u0026rdquo; language.\nRust # Rust supports two kinds of macros: macros-by-example, and procedural macros.\nMacros-by-example are a simple pattern-to-pattern transformation. Here\u0026rsquo;s an example from The Rust Book:\n1 2 3 4 5 6 7 8 9 10 11 12 #[macro_export] macro_rules! vec { ( $( $x:expr ),* ) =\u0026gt; { // (pattern-repeat) { let mut temp_vec = Vec::new(); $( temp_vec.push($x); )* temp_vec } }; } This macro takes a pattern like\nvec!(foo, bar baz) and expands it to a pattern like\n{ let mut temp_vec = Vec::new(); temp_vec.push(foo); temp_vec.push(bar); temp_vec.push(baz); temp_vec } Notice how the * marks a part of the template that can be repeated. pattern-repeat This is akin to Racket or Scheme\u0026rsquo;s ... repetition form. Macros-by-example work on AST, but you can\u0026rsquo;t perform arbitrary computation on the AST. For that, you need procedural macros.\nRust\u0026rsquo;s procedural macros (called \u0026ldquo;proc macros\u0026rdquo;) work on a token stream, and you can perform arbitrary computation, which puts them in a bit of a funny middle ground between C and Lisp. There is a Rust crate that you can use to parse a Rust token stream into Rust AST, but you don\u0026rsquo;t get any nice source information from the AST nodes, which makes producing good error messages a challenge.\nI personally find Rust macros to be disappointing.\nConclusion # There\u0026rsquo;s a wide variety of macro systems. The best macro systems:\nOperate on the AST rather than on a stream of tokens Avoid leaking implementation details through inadvertent variable capture by being hygienic Produce good error messages that are in terms of the caller\u0026rsquo;s context (Bonus) have good phase separation to enforce clear separation between complex macro systems Different languages have different features in their macro systems; some languages make it easy to use macros sensibly, while for others macros are a formidable challenge to use properly—make sure you know what your language provides and the trade-offs involved.\nWhy shouldn\u0026rsquo;t you use macros? # Turns out you can do a lot with functions. Powerful function programming languages let you do so much with first-class functions. If you can get access to first-class continuations, as you can in Racket and Scheme, then you can create powerful new programming constructs without having to resort to macros.\nI came across the JuliaCon 2019 keynote talk, where Steven Johnson explains how many of the things that you can do with macros can be solved just with Julia\u0026rsquo;s type dispatch.\nIf you can do something with functions, you probably should: functions are first-class values in most languages these days, and you\u0026rsquo;ll enjoy increased composability, better error messages, and code that is easier to read and understand by your peers.\nMacros introduce little languages wherever you use them. For simple macros, you might not have any constraints on what you may write under the scope of a macro. As an example, consider a macro that adds a while-loop construct to a language by rewriting to another kind of looping mechanism: you shouldn\u0026rsquo;t have any restriction on what you can write inside the body of the while loop.\nHowever, more complex macros can impose more restrictions on what can and cannot be written under their lexical extent. These restrictions may or may not be obvious. Examples: accidental variable capture limits what can be safely written, and grammatical errors (e.g. using an expression where an identifier was expected) can lead to inscrutable errors.\nBetter macro systems mitigate these problems. It\u0026rsquo;s not enough to just have a macro system that uses ASTs; you need a macro system that makes it easy to write correct macros with clear error messages so they truly feel like natural extensions of the language. Few languages do this right.\nWhy should you use macros? # Macro systems have improved since the 1960s. While Lisp excluded many of the pitfalls of C macros by construction, you still had to use kluges like gensym to manually avoid variable capture. Scheme got rid of that with hygienic macros, and Racket improved matters further by improving macro hygiene through scope sets and introducing phase separation. It is so much easier to build robust macro-based abstractions.\nMacros are good—anyone can write macros and experiment with new syntactic constructs. This makes development and extension of the language no longer the sole domain of the language designer and maintainer—library authors can experiment with different approaches to various problems.\nWe see this a lot with Elixir: Elixir\u0026rsquo;s core language is really rather small; most of the magic powering popular libraries like Ecto or Phoenix comes from a choice set of macro abstractions. These and other libraries are free to experiment with novel syntax without fear of cluttering and coupling the core language with bad abstractions that would then need to be maintained in perpetuity.\nMacros can be powerful when used correctly—something made much easier by modern macro systems.\nReferences # [1]Adams, M.D. 2015. Towards the Essence of Hygiene. Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (Mumbai India, Jan. 2015), 457–469. [2]Barzilay, E., Culpepper, R. and Flatt, M. Keeping it Clean with Syntax Parameters. [3]Flatt, M. 2002. Composable and compilable macros: You want it when? Proceedings of the seventh ACM SIGPLAN international conference on Functional programming (New York, NY, USA, Sep. 2002), 72–83. [4]Krishnamurthi, S. 2006. EDUCATIONAL PEARL: Automata via macros. Journal of functional programming. 16, 03 (May 2006), 253. DOI:https://doi.org/10.1017/S0956796805005733. NO_ITEM_DATA:flattBindingSetsScopes2016b "},{"id":24,"href":"/posts/2023-10-30_why_no_callcc/","title":"Why Don't More Languages Have a call/cc Operator?","section":"Technical Blog","content":"Something I\u0026rsquo;ve wondered about for a little while: why don\u0026rsquo;t more languages have a call/cc operator? Having first-class continuations in your programming language gives your programmers a powerful construct. So why do only a handful of languages have it?\nThe short answer is: it\u0026rsquo;s tricky to implement efficiently. One way to get call/cc is to convert your code into continuation-passing style. Then, call/cc simply takes the continuation in that representation and binds it to a variable. Most languages don\u0026rsquo;t seem to go through a continuation-passing style conversion pass though, so there\u0026rsquo;s no continuation to grab.\nI asked Matthew Flatt about this today, and his answer was that most languages use the C model of functions: when you call a function, you push the arguments to the function onto a stack along with the return address. Then, when you return, you pop those element back off the stack. To get call/cc, you\u0026rsquo;ve have to copy the entire stack and pass that around.\n"},{"id":25,"href":"/posts/2023-10-03_recursion_from_first_principles/","title":"Deriving Recursion from First Principles","section":"Technical Blog","content":"Or: Approaching the Y Combinator\nThese are some of my class notes. Learning to derive the Y Combinator from first principles is something I\u0026rsquo;ve always wanted to do. This isn\u0026rsquo;t quite the Y Combinator, but it\u0026rsquo;s very close and it still gets you recursion without relying on recursive structures to begin with.\nIn the beginning, we write a recursive function to compute the length of a list:\n(let* ([len (λ (lst) (if (null? lst) 0 (+ 1 (len (cdr lst)))))]) (len \u0026#39;(1 2 3))) The let* syntax allows us to create local variable bindings that can reference themselves. But let\u0026rsquo;s suppose we don\u0026rsquo;t have let*\u0026mdash;what do we do?\nWe can make a function that we give to itself. That then returns the function we want, with the outer function in scope. So, the outer function len in this example has \u0026ldquo;type\u0026rdquo;1 $self → Int → Int. That makes it clear that to get the Int → Int function we want, we have to pass the function to itself.\n(let ([len (λ (len) (λ (lst) (if (null? lst) 0 (+ 1 ((len len) (cdr lst))))))]) ((len len) \u0026#39;(1 2 3))) But it\u0026rsquo;d be nice if we could pull out that (len len) in the body of the function. Let\u0026rsquo;s call that len1.\n(let ([len (λ (len) (let ([len1 (λ (l) ((len len) l))]) (λ (lst) (if (null? lst) 0 (+ 1 (len1 (cdr lst))))) ))]) ((len len) \u0026#39;(1 2 3))) Note that what we can\u0026rsquo;t do is this:\n(let ([len (λ (len) (let ([len1 (len len)]) ; problem here! (λ (lst) (if (null? lst) 0 (+ 1 (len1 (cdr lst))))) ))]) ((len len) \u0026#39;(1 2 3))) Because this is an eager language, so that\u0026rsquo;d loop forever.\nLet\u0026rsquo;s do that same trick for the outer len len:\n(let ([len (λ (len) (let ([len1 (λ (l) ((len len) l))]) (λ (lst) (if (null? lst) 0 (+ 1 (len1 (cdr lst))))) ))]) (let ([len1 (len len)]) ; type of len1 is Int → Int (len1 \u0026#39;(1 2 3)))) Note that the (len len) at the end of that is OK because we\u0026rsquo;re not doing another self application.\nLet\u0026rsquo;s change that inner let to a λ just for fun.\n(let ([len (λ (len) ((λ (len1) (λ (lst) (if (null? lst) 0 (+ 1 (len1 (cdr lst)))))) (λ (l) ((len len) l))))]) ((λ (len1) (len1 \u0026#39;(1 2 3))) (len len))) Rename len → self, len1 → rec, and just return the function without calling it:\n(let ([self (λ (self) ((λ (rec) (λ (lst) (if (null? lst) 0 (+ 1 (rec (cdr lst)))))) (λ (x) ((self self) x))))]) (self self)) Ok, we are ready… let\u0026rsquo;s go ahead an extract that part (λ (lst) ...): that\u0026rsquo;s the only part of this that knows anything about computing the length of lists. We\u0026rsquo;ll wrap the whole thing in a function called mk_rec which takes a function of two arguments: the first argument we will pass rec to, and the second is the actual argument to the function.\n(define (mk_rec fn_x) ; takes two args: the recursive thingy and the argument (let ([self (λ (self) ((λ (rec) (λ (x) (fn_x rec x))) (λ (x) ((self self) x))))]) (self self))) (define len (mk_rec (λ (rec lst) (if (null? lst) 0 (+ 1 (rec (cdr lst))))))) (len \u0026#39;(1 2 3)) ; returns 3 (define fact (mk_rec (λ (rec x) (if (zero? x) 1 (* x (rec (- x 1))))))) (fact 5) ; returns 120 Note that that isn\u0026rsquo;t actually the the Y combinator exactly. But hey we have recursion without using recursion!\nJust for fun:\nNote that we could have defined let as:\n(let ((let \u0026#39;`(let ((let \u0026#39;,let)) ,let))) `(let ((let \u0026#39;,let)) ,let)) Source: FreeBSD fortune files; this is probably my favorite quine ever.\nScare quotes intentional: you can\u0026rsquo;t have self-referential types in the simply-typed lambda calculus like you see here. The STLC is called strongly normalizing, which means every well-typed term reduces to a value of that type. Thus, you can\u0026rsquo;t have something like the Y Combinator or Omega (((λ (x) (x x)) (λ (y) (y y)))) because these could loop forever (diverge).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":26,"href":"/posts/2023-09-23_all_original/","title":"My Commitment to Intellectual Integrity","section":"Technical Blog","content":"I got a strange email the other day. Here it is, with parts redacted:\nHi there,\nMy name is G\u0026mdash;, I am the main editor at \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;.\nWhile browsing your site, I noticed you have an amazing article from this page:\nLink to an extremely old post of mine\nMy team actually just published a comprehensive article on \u0026ldquo;Semi-related title\u0026rdquo; which I think your visitors would truly appreciate and add value to your awesome article.\nYou can check it out here: \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nIf you were willing to add our link to that page, I would be more than happy to share it to more than a thousand of our social followers to help you gain some visibility in exchange.\nLet me know what you think and thank you for your consideration!\nCheers,\nG\u0026mdash; \u0026mdash;\u0026mdash;\u0026mdash;\nMy mail program correctly marked it as spam, which I appreciate. (Besides the spammy feel of the text, the article of mine they reference is an \u0026ldquo;amazing\u0026rdquo; \u0026gt;300 word blurb about a one-day project I did in 2017. Sheesh…) I was a little shocked that someone would ask me to engage in the kind of social-metrics-engineering which I feel has contributed directly to many of the social problems plaguing us today.\nI decided to make a public promise that I would hold myself to. Here it is:\nI am a scholar. As such, I have a sacred duty to uphold truth at all times and to share knowledge freely. I will never do anything that might compromise my ability to do such. If there is anything beautiful, truthful, or honorable, I will promote it. I will never accept bribery or engage in influence peddling; I find it intellectually and morally repugnant to use my station as an academic for personal gain.\nI\u0026rsquo;ll make mistakes—and I won\u0026rsquo;t stop talking about tools and services that I think genuinely serve my desires for greater knowledge, understanding, and freedom—but I will never do this in exchange for money, social clout, or whatever. If I attain any fame, it will not be because it was my end goal.\nSo, G\u0026mdash;, here is what I think of your offer: get lost—your proposal disgusts me.\n"},{"id":27,"href":"/posts/2023-08-14_types_with_macros/","title":"Implementing Type Systems as Macros","section":"Technical Blog","content":"There\u0026rsquo;s a neat paper Type Systems as Macros by Chang, Knauth, and Greenman [1] that describes how to implement a typed language using an untyped host language and macro expansion. The paper is neat, but I found the code hard to follow—the paper uses a compact notation that\u0026rsquo;s convenient for print, but not so much for reproducing on one\u0026rsquo;s own. This post is my attempt to implement and explain in more accessible terms what\u0026rsquo;s presented in the paper.\nThe working source for the paper is available on the first author\u0026rsquo;s BitBucket, but that code uses a lot of auxiliary helper files and it can still be pretty hard to follow.\nMy implementation consists of a single file implemented in plain Racket. I try to keep as many of the function names the same, so hopefully it\u0026rsquo;s not too hard to follow if you\u0026rsquo;re coming from reading the paper. If you\u0026rsquo;re impatient to try running the code, the full example can be found at the bottom in § Full solution or on my Codeberg account.\nIf you haven\u0026rsquo;t read the paper, you can just skip this box: it\u0026rsquo;s meant to signpost to people who\u0026rsquo;ve read the paper what I\u0026rsquo;m going to be attempting to do different.\nA few specific things that tripped me up most were:\nUsing local-expand:\nIn the paper, this function is only ever given one argument. The real function in Racket takes 3 arguments. Moreover, this function can only be called during macro-expansion, so you can\u0026rsquo;t play with it at the top level to understand it better.\nGeneral elision of syntax-parse:\nThe code makes heavy use of syntax-parse. However, the paper never shows it. It\u0026rsquo;s mentioned in a few footnotes, but for one who\u0026rsquo;s new to Racket\u0026rsquo;s macro-writing ecosystem, it\u0026rsquo;s hard to spot.\nUnderstanding how to implement type environments:\nI got lost with the \\(\\bar{\\lambda}\\) and the different highlighting patterns in the comp+erase-τ/ctx function.\nMaking sure the right functions are available at the right phases:\nI\u0026rsquo;m still new to Racket\u0026rsquo;s macro system, and phase-separation can be tricky to grok.\nA few terms # A few terms that will crop up in this post:\nSource language Generally, this refers to the input to a compiler or interpreter—it\u0026rsquo;s the language of the source code that we want to eventually be able to write. In our specific case, this will be the simply typed lambda calculus. Target language Generally, the output of a compiler. For example, the target language of a compiler might be x86 assembly or WASM. In our case, we want to transform the typed source language (the simply typed lambda calculus) into the untyped target language of Racket. Procedural macro Procedural macros are ones that let you use the entire power of the language to operate on the AST you are transforming: you can write conditionals, loops, and even call functions on the AST under expansion. Contrast with pattern macros, like Rust\u0026rsquo;s macros made with macro_rules!, which match a pattern of syntax and transform that into new syntax just by filling holes in a pattern. Pattern macros are immensely useful, but their power is a strict subset of procedural macros. Essentials of building a typed language with macros # Let\u0026rsquo;s take a quick look at the language we want to write:\n;; Identify function ;; λx :: a → a; in Racket notation, (→ a a) (λ ([x : a]) x) ;; Function call ;; λx :: (b → b) → (b → b) takes an argument ;; of type b → b (which is what λy is) ((λ ([x : (→ b b)]) x) (λ ([y : b]) y)) ;; More complicated function ;; λfx :: (a → b) → a → b (λ ([f : (→ a b)] [x : a]) (f x)) Our macros should expand, check, and rewrite this into something that looks like this:\n;; Identify function again (λ (x) x) ;; Function call ((λ (x) x) (λ (y) y)) ;; More complicated function (λ (f x) (f x)) All the types have been erased. The trick is: we want to do this so that we catch any type errors. That way, if we mistakenly write:\n(λ ([f : (→ a b)] [x : c]) (f x)) ; x is the wrong type! We should get a compile-time type error, and our macros will refuse to expand this into plain Racket.\n; play_stlc.rkt:16:27: #%app: play_stlc.rkt: Function expected ; args with type (a), got type (c) instead How are we going to do this? Basically, we want to interpose on every function creation and function call to check that the types at these locations line up. We\u0026rsquo;ll be working with a very simple language, but this kind of work generalizes to the kinds of languages you\u0026rsquo;re used to working with.\nThe overall architecture looks like this:\nFigure 1: Transforming STLC to Racket via macros\nThe important thing to remember is this: expanding erases types and attaches type information to the resulting syntax while checking that the types are consistent throughout expansion.\nExpanding syntax with type annotations does two things:\nResulting syntax has all the type annotations erased. Resulting syntax has its type stored as a syntax property\u0026mdash;just some metadata on the AST node. Throughout this paper, we will use notation like x or e to refer to syntax from the source language—type annotations and all—and x- and e- to refer to syntax that has had the types erased from the source, and added as metadata.\nLet\u0026rsquo;s take a look at how we would implement that middle block.\nInterposing on every function definition and call site # The first thing we need to do is to be able to inspect every function definition and call site. In other languages, this might only be possible by writing some kind of wrapping macro that walks down the AST of your entire module and replaces ordinary function calls into a call to a macro you control.\nHowever, we\u0026rsquo;re using Racket, and Racket is designed to make language construction easy! Racket\u0026rsquo;s reader will expand function calls like (foo bar baz) into calls to a special function #%app: (#%app foo bar baz). We can override what this symbol refers to when our code gets imported as a #lang with rename-out:\n#lang racket (require syntax/parse/define) (provide #%module-begin #%top-interaction) ; needed for #lang (provide (rename-out [checked-app #%app] [checked-λ λ])) Code Snippet 1: stlc.rkt The highlighted portion means to rename checked-app to #%app and checked-λ to λ in the requiring module\u0026rsquo;s scope. See the docs on #lang creation for more details.\nWith that in place, we can write some macros checked-app and checked-λ which will then be used when we import stlc.rkt as a #lang:\n(define-syntax (checked-app stx) …) (define-syntax (checked-λ stx) …) Code Snippet 2: stlc.rkt #lang s-exp \u0026#34;stlc.rkt\u0026#34; ;; This λ referrs to checked-λ (λ ([x : a]) x) Code Snippet 3: play_stlc.rkt Implementing the checks # We\u0026rsquo;ve seen a few clever tricks that we can exploit in Racket to automatically interpose on every function definition and call. Now we begin the type checking.\nCore macros # Let\u0026rsquo;s first take a look at the stars of the show: checked-λ and checked-app.\nRemember: these are macros that our source language will use under the names λ and whenever there\u0026rsquo;s a normal function call. These macros need to expand to untyped Racket, albeit with the type information added as a syntax property.\nFirst macro: checked-λ # 48 49 50 51 52 53 54 55 56 57 (define-syntax (checked-λ stx) (syntax-parse stx [(_ ([x (~literal :) τ_in] ...) e) (pat) #:with [-xs -e τ_out] (comp+erase-τ/ctx #\u0026#39;e #\u0026#39;([x τ_in] ...)) (comp-erase) #:do [(printf \u0026#34;derived ~a :: ~a → ~a\\n\u0026#34; (syntax-\u0026gt;datum stx) (syntax-\u0026gt;datum #\u0026#39;(τ_in ...)) (syntax-\u0026gt;datum) #\u0026#39;τ_out)] (add-τ #\u0026#39;(λ -xs -e) #\u0026#39;(→ τ_in ... τ_out))])) (lam-return) Code Snippet 4: stlc.rkt We\u0026rsquo;re defining a macro checked-λ, which is invoked any time a λ is used in the module requiring this one, thanks to the rename-out bit.\nWe\u0026rsquo;re using the excellent syntax-parse macro, introduced in [2] I believe. syntax-parse gives us fancy keywords like #:with, #:when, and #:fail-unless The full list of pattern directives can be found here in the documentation. which gives us a rich language to build macros with. You should be using syntax-parse to write anything more complex than a basic \u0026ldquo;macro-by-example\u0026rdquo;. I have an out-of-date blog post comparing a few ways to write macros in Racket. In the words of Ben Greenman, \u0026ldquo;syntax-case is old baggage!\u0026rdquo; Let\u0026rsquo;s step through this line-by-line.\nThe line pat describes the pattern we\u0026rsquo;re matching in stx: _ is a wildcard, and in our case will just match checked-λ. Next we have a list with elements looking like [var_name : type_name]. We bind all the variable names to x and the corresponding types to τ_in. Finally we bind some expression to the variable e. Syntax like (checked-λ ([x : a] [y : (→ a b)]) (y x)) should match this.\nThe next line comp-erase calls a helper function comp+erase-τ/ctx (yes that\u0026rsquo;s a mouthful) to compute the type of the body whilst erasing the type annotations at the same time. Moreover, it should do this type computation in the context of the variables x ... and their types τ_in .... This just means that when computing the type of the body of (λ ([x : Int]) {lambda body here...}), it should know that variable x has type Int.\ncomp+erase-τ/ctx returns three things:\n-xs the variables x ... but with the type annotations erased -e the body e but, again, with the type annotations erased from the source τ_out the derived return type of the function We\u0026rsquo;ll dig into how this function works in Support functions: compute and erase types.\nThe call to printf just shows us some pretty information about the work that the macro type checker is doing. It\u0026rsquo;s not necessary and you could delete lines 52–55 with no consequences.\nIn the final line lam-return we return some new syntax #'(λ -xs -e). Note that this bit of syntax has no type annotations! We do add the type to this bit of syntax with add-τ\u0026mdash;we will need this later. The type of a λ is an arrow type with arguments provided by the type annotations on the arguments, and the return type of the function supplied by the derived type of the expression from the comp-erase line.\nRemember: when our macros expand, they check the types and erase them. We don\u0026rsquo;t have any checks to do here in checked-λ, but the type information we\u0026rsquo;ve added will come in handy when we check the arguments to this function in the next macro.\nSecond macro: checked-app # 58 59 60 61 62 63 64 65 66 67 68 69 70 (define-syntax (checked-app stx) (syntax-parse stx [(_ e_fn e_arg ...) (app-pat) #:with [-e_fn (_ τ_in ... τ_out)] (comp+erase-τ #\u0026#39;e_fn) (fn-type) #:with ([-e_arg τ_arg] ...) (stx-map comp+erase-τ #\u0026#39;(e_arg ...)) (arg-types) #:fail-unless (τ= #\u0026#39;(τ_arg ...) #\u0026#39;(τ_in ...)) (typecheck) (format \u0026#34;~a: Function expected args with type ~a, got type ~a instead\u0026#34; (syntax-source stx) (syntax-\u0026gt;datum #\u0026#39;(τ_in ...)) (syntax-\u0026gt;datum #\u0026#39;(τ_arg ...))) (add-τ #\u0026#39;(#%app -e_fn -e_arg ...) #\u0026#39;τ_out)])) (app-return) Code Snippet 5: stlc.rkt Like before, let\u0026rsquo;s go through this line-by-line.\nThe line app-pat describes the pattern for function application: the first thing you see e_fn is a function, and the rest e_arg ... are arguments.\nNext, in fn-type we expand the syntax of the function, which means the syntax we get back (-e_fn) has passed type checking and now has the type annotations erased. The erased syntax does have its type stuck on it, lam-return which we retrieve in comp+erase-τ with get-τ and store in τ_in ... τ_out.\nThen we compute the types of the arguments using the same function comp+erase-τ; this time we use stx-map​ Brought into scope with (require syntax/stx). to map over the syntax object #'(e_arg …).\nThe short answer for why we have to use stx-map is this: the e_arg variable is a template variable, which means we can\u0026rsquo;t pass it directly to comp+erase-τ: we have to use it in a syntax pattern (which we get from #') but then we have some syntax, not a list.\nWe could use syntax-\u0026gt;list here to map over the list, as this only converts the top-most layer of syntax into a list:\n(map comp+erase-τ (syntax-\u0026gt;list #\u0026#39;(e_arg ...))) but stx-map does exactly that, so we might as well use it.\nOnce we have the type of the function (→ τ_in ... τ_out) and the types of the arguments (τ_arg ...) it becomes a simple matter to check that these types match. typecheck If they don\u0026rsquo;t, the #:fail-unless keyword will break the macro expansion with a parse error and will display a nicely-formatted message, complete with source information from syntax-source as well as expected and received types.\nLike with checked-λ, we return the function application with all the type annotations erased in both the function and the arguments, but we tack on the function\u0026rsquo;s return type τ_out to the syntax we build and return: #'(#%app -e_fn -e_arg ...).\nSupport functions: compute and erase types # We\u0026rsquo;ve covered the major macros, but now we need to inspect the helper functions comp+erase-τ and comp+erase-τ/ctx.\nComputing and erasing types: comp+erase-τ # The first support function that we need is comp+erase-τ, which we call from the checked-app macro on lines fn-type and arg-types.\nNote that we do not expand to a call to comp+erase-τ with the checked-app macro—we call this function _as part of expansion_​—i.e. this function gets called at compile-time.\nNormally we define functions with define. But, because we need this function to be available for macros to call, we use define-for-syntax. This makes the function available at compile time. More about this in § Putting the phases together.\n29 30 31 32 (define-for-syntax (comp+erase-τ e) (let* ([-e (expand-stx e)] [τ (get-τ -e)]) `[,-e ,τ])) This function is pretty simple: we take in some syntax e, expand the macros in e to get -e, which is just the same as e, but with all the type annotations erased and some type information added as a syntax property. Then we use a helper function get-τ (defined in § Convenience functions) to pull the type off of -e. Finally we return -e and its associated type τ.\nAgain, but with context: comp+erase-τ/ctx # Now we need to do the same thing, but this time, we\u0026rsquo;ll be adding a context to the expansion.\nWhat is a context? Consider the following function:\n(λ ([x : Int] [y : Bool]) (… body using variables x and y …)) Inside the body of the function, we need to somehow remember that the variable x has type Int and y has type Bool. That way, if we run into something like (+ x y) we can know that y isn\u0026rsquo;t the right type for that operation.\ncomp+erase-τ/ctx does the same thing and comp+erase-τ, but we add a context, which is just a list of variable ↦ type mappings. Like comp+erase-τ, we define comp+erase-τ/ctx with define-for-syntax so it\u0026rsquo;s available for checked-λ to use at compile time.\n1 2 3 4 5 6 7 8 9 10 11 (define-for-syntax (comp+erase-τ/ctx e ctx) (syntax-parse ctx [([x τ] ...) (ctx-destruct) #:with (y ...) (temps) (generate-temporaries #\u0026#39;(x ...)) #:with (λ xs- e-) (erased-version) (expand-stx #`(λ (y ...) (let-syntax ([x (make-rename-transformer (add-τ #\u0026#39;y #\u0026#39;τ))] ...) (rename-transformer) #,e))) #:with τ_out (get-τ #\u0026#39;e-) (body-type) #\u0026#39;[xs- e- τ_out]])) We use syntax-parse here just to destruct the list of variable ↦ type pairs [x τ] from ctx. ctx-destruct Then, for each of the variables x ..., we create a brand new variables y ... with generate-temporaries. temps\nI\u0026rsquo;ll talk about variables x, τ, and y in this next section. Remember that these are all template variables in a repetition .... This means that x has to show up in some expression that has one ... after it, and it will repeat that template fragment for every item that x matched against. See the guide on matching sequences if you need a primer or a refresher.\nNow comes the tricky bit: we\u0026rsquo;d like to expand e, but remembering that a given variable x has type τ. To accomplish this, we do something a little sneaky: we create a lexically-scoped macro with let-syntax that has the name x. We bind this to a macro that expands to the brand new variable y that has the type information for x attached to it.\nThis is what the let-syntax and make-rename-transformer bit does: it makes a macro that can expand in places other than application positions, (i.e. identifier position) along with a host of other convenience functions.\nSo, starting with a lambda like this:\n(λ ([a : Int] [b : Bool]) (and b (zero? a))) comp+erase-τ/ctx creates some new syntax that looks like this:\n(λ (y_tmp1 y_tmp2) (let-syntax ([a (make-rename-transformer (add-τ #\u0026#39;y_tmp1 #\u0026#39;Int))] [b (make-rename-transformer (add-τ #\u0026#39;y_tmp2 #\u0026#39;Bool))]) (and b (zero? a)))) Which gets expanded into:\n(λ (y_tmp1 y_tmp2) (and y_tmp2 (zero? y_tmp1))) But the symbols y_tmp2 and y_tmp1 on the second line have extra type information attached to them to help with the remainder of the type checking: add-τ simply returns the syntax you gave it in the first place, but with the second thing attached as type metadata.\n(Ab)using λ forms this way is a convenient hack for us to get the correct behavior: we don\u0026rsquo;t have to worry about any of the scoping rules of the language because Racket\u0026rsquo;s macro expander will just Do the Right Thing™—we get the proper semantics for free.\nIn languages where you can\u0026rsquo;t use macros outside of function-call position, you\u0026rsquo;ll have to come up with another way to realize type environments. One way you might do this is to start passing around a structure mapping symbols to types. You\u0026rsquo;ll have to be careful as you walk down your AST that you respect scoping rules.\nIf you figure something clever out, please let me know what you did—I\u0026rsquo;d be curious to see how other languages solve this problem.\nNow we\u0026rsquo;ve expanded the body e of the original λ that we got but with the variables and the type information added as context. Now we simply pull off the type data for the body—i.e. the function return type—with (get-τ e-) and return the erased variables, body, and function return type.\nNormally we wouldn\u0026rsquo;t have to worry about details like this, but because of how we\u0026rsquo;re using local-expand via expand-stx and the let-syntax clause inside the macro, the body of the λ gets wrapped in two layers of let-values, so we end up having to destructure all of that. The real implementation of comp+erase-τ/ctx ends up looking a little messier:\n34 35 36 37 38 39 40 41 42 43 44 45 46 (define-for-syntax (comp+erase-τ/ctx e ctx) (syntax-parse ctx [([x τ] ...) #:with (y ...) (generate-temporaries #\u0026#39;(x ...)) ;; Not sure why I need to unwrap the let-values… must be something with how ;; Racket automatically wraps the body of λ\u0026#39;s. ;; This is consistent with the paper\u0026#39;s implementation. #:with ((~literal #%plain-lambda) xs- ((~literal let-values) () ((~literal let-values) () e-))) (expand-stx #`(λ (y ...) (let-syntax ([x (make-rename-transformer (add-τ #\u0026#39;y #\u0026#39;τ))] ...) #,e))) #:with τ_out (get-τ #\u0026#39;e-) #\u0026#39;[xs- e- τ_out]])) The ~literal just tells the pattern matching that we\u0026rsquo;re looking for the identifier let-values in the syntax, and we\u0026rsquo;re not trying to have some variable named let-values that we\u0026rsquo;d like to bind to whatever is there. It\u0026rsquo;s a little more complicated than that: what I said is actually what ~datum does. ~literal considers bindings: it\u0026rsquo;s looking for something that\u0026rsquo;s bound to whatever ~let-syntax is bound to. In the simplest case, it just matches let-syntax because it\u0026rsquo;s binding hasn\u0026rsquo;t changed. See the docs for ~literal for more information. Convenience functions: working with type information # We are going to go from explicitly typed code to untyped code, but with type annotations on the syntax objects (AST nodes). It happens to be a convenient place to put the derived type of the data, but there\u0026rsquo;s nothing intrinsically important about this, as long as you can tie a particular syntax object back to its derived type somehow.\nWe define two functions: add-τ and get-τ to put and fetch data into the 'type field of a syntax object.\n;; Convenience functions (define (add-τ e t) (syntax-property e \u0026#39;type t)) (define (get-τ e) (syntax-property e \u0026#39;type)) Code Snippet 6: stlc.rkt We also define type equality here. For this demo, type quality is syntactic equality in the type. E.g. a ≡ a and a → b ≡ a → b, but a ≢ b and a → a ≢ b → b. This is a choice we\u0026rsquo;re making to keep things simple. It\u0026rsquo;s possible (and the authors in [1] do this) to define alternate type comparison operations to support existential types as well as subtyping.\n;; Dumb equality check: just check for syntactic equality (define (τ= t1s t2s) (define t1 (syntax-\u0026gt;datum t1s)) (define t2 (syntax-\u0026gt;datum t2s)) (equal? t1 t2)) Code Snippet 7: stlc.rkt We will want one small piece of convenience code in the next part:\n(define-syntax-rule (expand-stx stx) (local-expand stx \u0026#39;expression null)) Code Snippet 8: stlc.rkt local-expand is a function that takes some syntax and expands all the macros in it. It\u0026rsquo;s a little more complicated than that: local-expand expands the syntax in the lexical context of the currently expanding expression. What that means is that you can only call local-expand during macro expansion. This makes it hard to play with at the top-level REPL as a Lisp/Scheme is wont to do. If you are wanting to play around in the REPL, expand and expand-once are your friends. Inside our use case, expanding in the lexical context of the currently expanding macro makes this macro expansion safer.\nexpand-stx simply makes it so we don\u0026rsquo;t have to include so many arguments to local-expand, as they\u0026rsquo;d be the same every time we call it. See the documentation for local-expand for more details on what these arguments do.\nPutting the phases together # We\u0026rsquo;ve covered all the essential bits, but we haven\u0026rsquo;t talked about what functions need to be available when: this isn\u0026rsquo;t such a big deal in Lisp or Scheme when you can call pretty much any function from any macro, but Racket takes great pains to ensure that there is a clear dependency graph between macro expansion time and runtime. See Flatt\u0026rsquo;s Composable and Compilable Macros: You want it when? paper [3] for all the details you could ever want on this. That paper does a good job of motivating why you need clear phase separation.\nThat said, let\u0026rsquo;s talk about the dependency graph of the functions and macros in our code.\nFigure 2: Dependency graph: functions are blue, macros are green.\nNormally, functions are defined at phase level 0, which is the \u0026ldquo;runtime\u0026rdquo; phase of the module. Macros are defined at phase level 1, which is the \u0026ldquo;compile time\u0026rdquo; or \u0026ldquo;expand time\u0026rdquo; phase. You can only refer to things defined at the same or higher phase level. So, normally, macros can\u0026rsquo;t call functions in the same module.\nOur two main macros, checked-λ and checked-app, both depend on the functions comp+erase-τ and comp+erase-τ/ctx, along with a few other auxiliary functions. These functions in turn depend on the expand-stx macro.\nThe purple box is at phase level 1, since checked-λ and checked-app are both macros. Normally, the functions in the orange box would be at phase level 0, and would be unavailable for our macros. However, we can raise the phase level by using define-for-syntax instead of define, or wrap the things we need at a higher phase level in begin-for-syntax.\nAll the functions now at phase level 1 use the expand-stx macro, so it has to be defined at phase level 2—we can simply put the define-syntax​ This macro is simple enough that we\u0026rsquo;ll just use define-syntax-rule. inside of define-for-syntax.\nThat\u0026rsquo;s it! The full solution below puts all the functions together at the right phases.\nFull solution # The code can also be cloned from my Git repository on Codeberg.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 #lang racket ;; The Simply Typed Lambda Calculus (require syntax/parse/define) ;; make this a sensible #lang (provide #%module-begin #%top-interaction) (provide (rename-out [checked-app #%app] [checked-λ λ])) (begin-for-syntax (require syntax/stx) ; needed for stx-map ;; Shorthand to expand macros in syntax ;; Yes, this is a macro for use inside other macros (or functions at phase level 1) (define-syntax-rule (expand-stx stx) (local-expand stx \u0026#39;expression null)) ;; Convenience functions (define (add-τ e t) (syntax-property e \u0026#39;type t)) (define (get-τ e) (syntax-property e \u0026#39;type)) ;; Dumb equality check: just check for syntactic equality (define (τ= t1s t2s) (define t1 (syntax-\u0026gt;datum t1s)) (define t2 (syntax-\u0026gt;datum t2s)) (equal? t1 t2))) (define-for-syntax (comp+erase-τ e) (let* ([-e (expand-stx e)] [τ (get-τ -e)]) `[,-e ,τ])) (define-for-syntax (comp+erase-τ/ctx e ctx) (syntax-parse ctx [([x τ] ...) #:with (y ...) (generate-temporaries #\u0026#39;(x ...)) ;; Not sure why I need to unwrap the let-values… must be something with how ;; Racket automatically wraps the body of λ\u0026#39;s. ;; This is consistent with the paper\u0026#39;s implementation. #:with ((~literal #%plain-lambda) xs- ((~literal let-values) () ((~literal let-values) () e-))) (expand-stx #`(λ (y ...) (let-syntax ([x (make-rename-transformer (add-τ #\u0026#39;y #\u0026#39;τ))] ...) #,e))) #:with τ_out (get-τ #\u0026#39;e-) #\u0026#39;[xs- e- τ_out]])) (define-syntax (checked-λ stx) (syntax-parse stx [(_ ([x (~datum :) τ_in] ...) e) #:with [-xs -e τ_out] (comp+erase-τ/ctx #\u0026#39;e #\u0026#39;([x τ_in] ...)) #:do [(printf \u0026#34;derived ~a :: ~a → ~a\\n\u0026#34; (syntax-\u0026gt;datum stx) (syntax-\u0026gt;datum #\u0026#39;(τ_in ...)) (syntax-\u0026gt;datum #\u0026#39;τ_out))] (add-τ #\u0026#39;(λ -xs -e) #\u0026#39;(→ τ_in ... τ_out))])) (define-syntax (checked-app stx) (syntax-parse stx [(_ e_fn e_arg ...) #:with [-e_fn (_ τ_in ... τ_out)] (comp+erase-τ #\u0026#39;e_fn) #:with ([-e_arg τ_arg] ...) (stx-map comp+erase-τ #\u0026#39;(e_arg ...)) #:fail-unless (τ= #\u0026#39;(τ_arg ...) #\u0026#39;(τ_in ...)) (format \u0026#34;~a: Function expected args with type ~a, got type ~a instead\u0026#34; (syntax-source stx) (syntax-\u0026gt;datum #\u0026#39;(τ_in ...)) (syntax-\u0026gt;datum #\u0026#39;(τ_arg ...))) (add-τ #\u0026#39;(#%app -e_fn -e_arg ...) #\u0026#39;τ_out)])) Code Snippet 9: stlc.rkt 1 2 3 4 5 6 7 8 9 10 11 12 13 #lang s-exp \u0026#34;stlc.rkt\u0026#34; ;; Smallest example: function a → a (in Racket notation, (→ a a)) (λ ([x : a]) x) ;; a bigger example ((λ ([x : (→ b b)]) x) (λ ([y : b]) y)) ;; ;; Functions! (λ ([f : (→ a b)] [x : a]) (f x)) ;; an example of an ill-typed expression ;; ((λ ([x : (→ b b)]) x) (λ ([f : (→ b c)] [y : b]) (f y))) Code Snippet 10: play_stlc.rkt Acknowledgments # Thanks to Ben Greenman for reading and providing suggestions and improvements on this post.\nReferences # [1]Chang, S., Knauth, A. and Greenman, B. 2017. Type systems as macros. Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages - POPL 2017 (Paris, France, 2017), 694–705. [2]Culpepper, R. 2012. Fortifying macros. Journal of functional programming. 22, 4-5 (Sep. 2012), 439–476. DOI:https://doi.org/10.1017/S0956796812000275. [3]Flatt, M. 2002. Composable and compilable macros: You want it when? Proceedings of the seventh ACM SIGPLAN international conference on Functional programming (New York, NY, USA, Sep. 2002), 72–83. "},{"id":28,"href":"/posts/2023-08-05_one_year_into_phd/","title":"Reflections one year into a PhD program","section":"Technical Blog","content":"I started my PhD program about a year ago. In my first year I have:\nTaken 4 \u0026ldquo;normal\u0026rdquo; 3-credit-hour classes Participated in 3 seminars Switched advisors Attended 2 conferences (PLDI @ FCRC, JuliaCon) Presented my work at JuliaCon It\u0026rsquo;s been a lot of work, and there\u0026rsquo;s been a lot of stress. I\u0026rsquo;m in a much better place now than when I started, and over all I\u0026rsquo;m happy where I\u0026rsquo;m at and where I\u0026rsquo;m headed.\nChanging advisors # Some of the stress has come from finances: it\u0026rsquo;s hard to support a family on a PhD stipend with rising costs of living.\nThe most stress I felt was in my first semester. I got hired on as an RA1 with a nice researcher and we hit it off well. But I discovered half way through the semester that I was not enjoying the work. This wasn\u0026rsquo;t anyone\u0026rsquo;s fault—I had to do a little bit of the work to find out that I wasn\u0026rsquo;t that interested in what I was doing.\nAt first I thought that I might be able to power through. I didn\u0026rsquo;t want to be the kind of student that hops from advisor to advisor or from project to project just as the going gets tough, boring, or unpleasant. But I talked with my advisor from undergrad, and he explained that a PhD sets the tone of your research basically until you get tenure. That\u0026rsquo;s a long time—and I didn\u0026rsquo;t want to work in that area for a decade or better. I realized that I either had to change what I was working on, or I needed to quit and go back to industry.\nI started looking around at what my options were. My school assigns every grad student a \u0026ldquo;faculty mentor\u0026rdquo;—a faculty member who is not your advisor that\u0026rsquo;s \u0026ldquo;assigned\u0026rdquo; to you. In my experience, most professors are more than happy to talk to you if you need help—this one just happened to be assigned to me. At some point I discovered that Ben Greenman was coming to the U as a professor. I called him, we talked, and we figured out that our interests were much more closely aligned. Problem was, Ben wasn\u0026rsquo;t starting at the U until the fall. I found a fellowship for one semester, and was able to do work with Ben and another professor through the summer.\nFinding an advisor whose interests aligned with mine was a huge improvement for my work and my mental health. If you are looking into going to grad school, I would make that your top priority. And it wasn\u0026rsquo;t that my first advisor was bad in any way—we\u0026rsquo;re still friends, we chat when we run into each other in the hall, and I learned a lot from him—it\u0026rsquo;s just that our interests were less aligned than I originally thought, and it took a little time to discover that. Better sooner rather than later, though.\nReading papers # One thing I noticed this week that made me really happy: reading research papers is a lot easier for me now. When I started getting interested in research back in my undergrad, I found reading papers to be so arduous. It took me a week or more to get through a single paper, and I never got a lot out of them. I felt like it was difficult for me to even understand the questions that the paper was trying to answer.\nNow I\u0026rsquo;m more familiar with the context and the jargon, and I can grasp the questions the paper is trying to answer better. The format of research papers is familiar to me now, and that familiarity reduces the amount of friction I encounter when reading. It took time and exposure, and I don\u0026rsquo;t think there\u0026rsquo;s a substitute for that. Reading papers and discussing them with my advisors was a big help too.\nThe paper How to Read a Paper is probably the single most valuable bit of help an aspiring researcher can get. You should read it. (It\u0026rsquo;s short: 2 pages)\nClasses # Grad classes have a different tone than undergrad classes. As one of my professors put it, you will get an A or a B unless you persuade the professor that you should get a lower grade. This is nice because I have to keep a particular GPA to qualify for tuition benefit.2 That means I can do the minimum to learn the material and spend the majority of my time and energy on research.\nAfter switching research projects, I noticed a switch in my priorities: my first semester, I would do my class work and then do research if I had time left over. My second semester, I did research first and class work happened when I had nothing else to do. I like the second balance better.\nConferences and speaking # I got to present my work at JuliaCon 2023. I\u0026rsquo;ll put up a link to the video when it comes out, but if you poke around the recordings you should be able to find the talk in the middle of a long recording.\nIt was fun to prepare and present our work at a conference. It was also a ton of effort. I have never put that much time and energy into preparing a talk as I did for that conference. And it turned out pretty well, if I do say so myself. Hopefully subsequent talks will be less stressful, less effort, and even higher-quality!\nJuliaCon was hosted in Boston; before that I went to PLDI in Orlando. Boston is far superior to Orlando. Orlando is a wasteland of hotels and conference centers and has nothing walkable anywhere. In contrast, Boston is a vibrant city that is a delight to walk around with plenty of interesting things to see.\nIt has been satisfying getting to know people in the PL community. It\u0026rsquo;s also been nice to work more closely with professors in my department. I\u0026rsquo;m lucky I get to hang around with so many curious, intelligent, and friendly people.\nSatisfaction # I\u0026rsquo;m happy with where I am. The PhD program was hard at first—and it\u0026rsquo;s still hard—but it\u0026rsquo;s a different, more interesting kind of hard, and I like that.\nI think I\u0026rsquo;ll like the next few years. I still don\u0026rsquo;t know if I want to go into industry for a few years after or find a post-doc position in academia. Long-term I want to be a professor. We\u0026rsquo;ll see how it pans out though.\nIf you are looking for interns to study topics related to static analysis, macro systems, type systems, and language design, please drop me a line!\nResearch Assistant. At least where I attend, there are Research Assistants, Graduate Assistants, and Teaching Assistants. RAs have funding and get paid to do research. GAs either have some kind of fellowship (some kind of grant/fund/pool of money from the school rather than a research grant) or are paying their own way. TAs teach classes in exchange for tuition and stipend money.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nTuition benefit: PhD students at my school in my field (CS) get their tuition paid for by the school. There are some obligations around this, such as taking a certain number of credit-hours each semester and maintaining a decent GPA.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":29,"href":"/posts/2023-05-31_warp_factor_refactor/","title":"Warp Factor Refactoring in Emacs","section":"Technical Blog","content":"Here\u0026rsquo;s a nifty Emacs workflow for doing a project-wide search-and-replace on steroids. While I do use refactor tools that come with language servers,1 sometimes those aren\u0026rsquo;t enough. Consider the case where you not only need to change the name of a function, but also e.g. need to swap the order of two of its arguments. Or you\u0026rsquo;ve broken one function out into two that need to be chained together. Whatever—there are plenty of ways where the IDE won\u0026rsquo;t be able to do everything that you need. Enter: Emacs.\nHere is what it looks like in action:\nHere\u0026rsquo;s what I did:\nI searched for lines matching set_ and _config in my project, and got over 90 matches. I moved all the matches to their own buffer. I used a regex replace on the buffer to transform patterns matching /set_([a-z]+)_config!/ into config_\\1!. I saved those changes back into the files where the came from. Note that this replaced two symbols simultaneously: set_logger_config! and set_injector_config!. Moreover, this updated all the documentation as well, because I wasn\u0026rsquo;t relying on my language server to find instances of that symbol in the source code: I could look inside of doc strings and README files as well! (That can be a two-edged sword, so you\u0026rsquo;ll want to be careful with this.)\nHere is why this workflow rocks: Once you\u0026rsquo;ve dumped the search results into a buffer, you have the full power of Emacs at your disposal. I have recorded keyboard macros, used regex replace from evil-mode, and done other zany things to effect large-scale edits with elegance and speed. You\u0026rsquo;re not limited to dumb exact-match symbol replacement—you\u0026rsquo;ve got a lot of tools that you already know at your disposal.\nEngage the editor # You will need the following third-party packages to make this work, as well as ripgrep installed on your system:\nVertico2 Consult Embark (also embark-consult, but that ships with Embark anyway) wgrep All except wgrep are available from GNU ELPA, and you can get wgrep Non-GNU ELPA, so you shouldn\u0026rsquo;t have trouble finding and installing these—especially if you\u0026rsquo;re running Emacs 28 or newer.\nWhy all the packages? That sure seems like a lot (4 whole packages!) for something that seems pretty complicated for a single feature. Well, Vertico, Consult, and Embark are mostly there for the slick UI. wgrep does all the heavy lifting. I\u0026rsquo;d recommend installing Vertico, Consult, and Embark3 anyway for how much they improve discoverability and add really useful ways of interacting with Emacs.\nHere\u0026rsquo;s the short of what each package contributes:\nVertico Turns the default minibuffer completion UI into an auto-updating list of candidates. This lets us interact with \u0026ldquo;candidates\u0026rdquo;—or more specifically in our case, lines matching a pattern across our entire project—in a fast and accessible way. Consult Adds a bunch of completing-read-based functions. This lets us use ripgrep with Vertico\u0026rsquo;s UI. Embark Kind of like a generalized keyboard-focused right-click on crazy steroids. This lets us export our list of matches out of Vertico\u0026rsquo;s UI and into a buffer that wgrep can use. wgrep Takes a buffer of search results, lets us edit that buffer, and then reflect those changes back into the files from the lines that they came from. Installing and configuring # Here are some sample configurations you can use.\nIf use use-package,4 here is how you can set it up to automatically install next time you evaluate your init.el:\n(use-package vertico :ensure t :config (vertico-mode)) (use-package consult :ensure t :bind ((\u0026#34;C-c r\u0026#34; . consult-ripgrep))) (use-package embark :ensure t :bind ((\u0026#34;C-c a\u0026#34; . embark-act))) (use-package embark-consult ;; comes bundled with Embark; no `:ensure t\u0026#39; necessary :after (embark consult)) (use-package wgrep :ensure t) Alternatively, you can install the packages with M-x package-install-package, and your config should look like this:\n;; make sure all your packages are installed before using these (vertico-mode) (define-key global-map (kbd \u0026#34;C-c a\u0026#34;) \u0026#39;embark-act) (define-key global-map (kbd \u0026#34;C-c r\u0026#34;) \u0026#39;consult-ripgrep) If you use fancy package managers like Elpaca (what I use) or Quelpa, I trust that you know how to modify the above to suit your needs.\nMake it so # Once you have the packages installed, here are the steps you take to do this:\nInvoke consult-ripgrep. (Bound to C-c r in the sample config.) Type your search query. Note that space-separated patterns can match different parts of the line in different orders. Invoke embark-act. (Bound to C-c a in the sample config.) This will open a buffer with a list of keys you can press next. Hit E for embark-export. This opens up a new buffer with all the matches. Note that you should be able to further filter results with something like consult-keep-lines. Hit C-c C-p to run wgrep-change-to-wgrep-mode. Make your edits. Hit C-c C-c to finish editing, then hit q to close the buffer. Hit C-x s to run save-some-buffers to make sure writes are committed.5 That\u0026rsquo;s it. Happy hacking!\nJulia\u0026rsquo;s language server, for instance, comes with a nice \u0026ldquo;rename symbol\u0026rdquo; feature. I know lots of other IDEs and language servers offer this sort of thing.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThis one isn\u0026rsquo;t strictly necessary with Emacs 28 and beyond thanks to enhancements made to the default minibuffer interface, but I can\u0026rsquo;t think of a good reason to not use Vertico: it is small, well-maintained, and it never ceases to impress me with how robust and flexible it is.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLet\u0026rsquo;s not forget also the excellent Marginalia and Orderless packages too!\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nNow built-in to Emacs 29! So many excellent features in Emacs 29!\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThere is, of course, a way to do this automatically. Per the wgrep docs, put (setq wgrep-auto-save-buffer t) in your config.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":30,"href":"/posts/personal/2023-05_26_hike/","title":"Hike up Desolation Trail","section":"Personal Blog","content":"I hiked up Desolation Trail with Scott Wiersdorf. It had rained a little bit the night before, so the trail was neither dusty nor muddy—perfect for hiking.\nFigure 1: Hike overview\nLots of pretty plants on the way.\nFigure 2: This flower is called Arrow Leaf\nFigure 3: Some pretty ground cover\nFigure 4: A neat old tree that got split\nThe way up was nice and scenic.\nFigure 5: View from the trail looking at Church Fork or Grandeur Peak—I forget which\nViews at the top were spectacular.\nFigure 6: Looking south at some snow in the draws\nFigure 7: View over the valley\nFigure 8: Panorama from the Salt Lake Valley Overlook\n"},{"id":31,"href":"/posts/2023-05-19_racket_macros/","title":"Writing Racket Macros: define-syntax and phases","section":"Technical Blog","content":"There are a bunch of different ways of writing a macro in Racket. There are also some tricky things around phases to keep in mind. This is to help me keep them all straight.\n3+1 ways to make a macro # This form:\n(define-syntax-rule (foo args ...) (use args ...)) is equivalent to:\n(define-syntax foo (syntax-rules () ([foo args ...] (use args ...)))) Which, is in turn equivalent to:\n(define-syntax foo (λ (stx) (syntax-case stx () [(gensymed-foo args ...) #\u0026#39;(use args ...)]))) ; gensymed-foo is like foo but doesn\u0026#39;t match in the template because syntax-rules expands to syntax-case with some fancy wrapping around it.\nThis makes syntax-case the most powerful of them all, and it\u0026rsquo;s here that we\u0026rsquo;re treating syntax as data comes to the forefront: you can bind the syntax object directly (in our example, with the (λ (stx) ...) part), pattern match on it, and finally return new syntax with the #' notation.\ndefine-syntax-rule is the weakest of the three, but handles a common case: just a single form that you\u0026rsquo;d like to transform a little bit. This version doesn\u0026rsquo;t allow for writing multiple clauses.\ndefine-syntax with syntax-rules is in the middle: the bodies of each of the rule match arms ((use args ...)) are assumed to be syntax objects. This works well for the majority of cases I think. It\u0026rsquo;s only when you need to do really hairy stuff and manually generate code that can\u0026rsquo;t be put together with repeats (...) that you need the full power of syntax-case at your disposal.\nNote that there are two forms of define-syntax: (define-syntax (id stx) body ...) is shorthand for (define-syntax id (λ (stx) body ...)) much like the shorthand for building functions with define.\nBonus: more power # A cousin of syntax-case is syntax-parse. I was confused about this one for a bit because the names are so close, and they share a lot of similarities. syntax-case\u0026rsquo;s documentation is in the Racket Reference proper, while syntax-parse\u0026rsquo;s documentation lives with the syntax module documentation.\nOur previous example would be written like this:\n(define-syntax (foo stx) (syntax-parse stx [(_ args ...) #\u0026#39;(use args ...)])) or equivalently:\n(define-syntax foo (λ (stx) (syntax-parse stx [(_ args ...) #\u0026#39;(use args ...)]))) syntax-parse supports keyword arguments like #:with and #:when to do some pattern matching and predicate checking. syntax-parse will backtrack through match arms until it finds a matching and satisfying clause.\nAs far as I can tell, syntax-parse is strictly the most powerful of the syntax manipulating forms that I\u0026rsquo;ve outlined here.\nPhases # It doesn\u0026rsquo;t seem like macros can use the functions in their current module by default. However, if you wrap your function definitions in begin-for-syntax, this shifts the function definitions \u0026ldquo;up\u0026rdquo; a phase, and they can be used at the same level as functions.\n(begin-for-syntax (define foo (stx) (add-stx-prop stx \u0026#39;bar \u0026#39;baz))) (define-syntax my-macro (syntax-parse stx #:with foo-ed (foo stx) #\u0026#39;foo-ed)) You can also require a module with the for-syntax keyword:\n(require (for-syntax \u0026#34;util.rkt\u0026#34;)) For more information on phases, see the Racket Docs on phase levels.\n"},{"id":32,"href":"/posts/2023-05-13_rss_fixup/","title":"Meta: Update should fix RSS feeds","section":"Technical Blog","content":"I recently made an update to how I build my blog. I like writing my posts with Org-mode because it provides a richer markup language than Markdown. Plus, more Emacs = more good. Hugo has support for Org files, but there was a problem with the RSS feed generation: all of my posts written in Org got truncated at some point. I don\u0026rsquo;t know if the fault lies with Hugo itself or with some problem in the theme I use—whatever it was, I don\u0026rsquo;t have the time right now to debug that and submit a good bug report or a fix. Instead, I\u0026rsquo;m using the ox-hugo org-mode exporter, so I still can write my posts with Org, but then let Emacs export them to Markdown for Hugo to process.\nYes, it\u0026rsquo;s a Rube Goldberg machine. But what would a programmer\u0026rsquo;s blog be if the build wasn\u0026rsquo;t convoluted like this? Anyway, RSS feeds are fixed now—I checked. If you happened to read anything only via RSS, and found the content cut off at a strange point, this might have fixed it for some posts. Let me know if you run into any other strange issues.\nCheers!\n"},{"id":33,"href":"/posts/2023-05-11_thinking_cs/","title":"The kind of thinking computer science enables","section":"Technical Blog","content":"I believe computer science plays as integral of a part to a well-rounded liberal arts education as does mathematics and linguistics. Why? A liberal arts education is designed to help you think in new and better ways. Computer science teaches novel ways of thinking, reasoning, and approaching problems that are hard to get anywhere else.\nI took a class on pedagogy when I encountered this puzzle. I answered the question easily, and I caught myself using reasoning patterns from work in programming coming to the forefront.\nConsider the following problem: suppose you have four cards, each of which has a letter on one side, and a number on the other. The cards are arranged like so:\n+-------+ +-------+ +-------+ +-------+ | | | | | | | | | A | | 2 | | B | | 3 | | | | | | | | | +-------+ +-------+ +-------+ +-------+ Suppose the cards follow the rule that, if a card has a vowel on one side, the other side must be an even number. What is the smallest number of cards you need to turn over to verify that the rule holds for these cards? Which cards?\nGive yourself a second to think about it, and try and figure it out.\nAnswer The answer is 2, and the cards are A and 3 Did you get that? I translated the rule into the logical implication if vowel → then even number. It says nothing about the opposite side of a card if the number is even. Thus, we only need to check cards A and 3.\nThe point of the exercise that we were doing was to showcase how difficult reasoning with abstract symbols is. After showing this example with the cards, our instructor gave us another equivalent problem, but this time using familiar terms around conditions on the legal drinking age. The point was that familiar analogies reduce cognitive load, thereby freeing the students\u0026rsquo; minds for grasping bigger and more important ideas.\nYet I found it easy to answer the first and more abstract problem. I\u0026rsquo;m not a genius or anything—I\u0026rsquo;ve just practiced this kind of reasoning with computer science. Anyone can do that.\nComputer science teaches abstract reasoning in a way that nothing else can. I suppose once you get far enough into mathematics you get to experience a lot of the same sorts of ideas—but only math majors ever make it that far. Programming forces you to confront abstract reasoning about conditions and rules and how they combine from the outset.\nMoreover, teaching programming can be fun! You don\u0026rsquo;t have to go all out into gamification to elicit delight in seeing a computer follow your instructions. The feedback loop between writing code and getting a response is so tight; I think students have an easier time in computer science pushing themselves to reason through problems because they can get fast immediate and real feedback from the computer.\nI think more people should learn programming to learn how to think like a programmer. We also need to do a better job designing our CS courses in high school and university to focus on this kind of transferable skill, and we need to de-emphasize whatever $hot_new_framework is being pushed by industry in the classroom.\n"},{"id":34,"href":"/posts/2023-05-03_email_with_outlook/","title":"Using a Real Mail Client with Outlook","section":"Technical Blog","content":"I recently managed to get access to my Outlook email from Emacs. This took some doing as my university had disabled app passwords. I consider Outlook to be harmful, but inasmuch as companies and schools continue to enforce OAUTH-only authentication with email systems, it is good to find workarounds.\nThis is how I set up email sending/receiving on my computer running macOS with DavMail. I also use mbsync (confusingly also known as isync) to actually fetch my email, and mu/mu4e to index and read mail. Douglas Rumbaugh has an awesome blog post that I followed to get this working. You should read that. This will mostly be my specific configuration settings as well as some tips and tricks.\nDavMail configuration # I just installed DavMail using brew:\nbrew install davmail I tried installing the cask version, but that never worked for me. Oh well. Command line is better anyway.\nConfig file # Now comes the tricky part: we need to point DavMail the right direction to fetch a token. Start with the following in a config file: (I used ~/.davmail.properties as my config file)\n# Disallow access to the davmail server from remote hosts (i.e., other # computers on the network) davmail.allowRemote=false # Don\u0026#39;t use SSL (between email client and davmail) davmail.ssl.nosecurecaldav=false davmail.ssl.nosecureimap=false davmail.ssl.nosecureldap=false davmail.ssl.nosecuresmtp=false # Ports to run the different services on. You\u0026#39;ll need these to connect # your clients. If you have several Exchange accounts, each one will need # to run on different ports davmail.caldavPort=5000 davmail.imapPort=5001 davmail.ldapPort=5002 davmail.smtpPort=5003 # Connection details for your exchange account. Odds are good that the # url listed here will work for you. If not, see if your University/employer # has any details on the correct host URL to connect to their email services # with. davmail.url=https://outlook.office365.com/EWS/Exchange.asmx # Set the authentication mode to manual davmail.mode=O365Manual # Run davmail in server mode davmail.server=true davmail.enableKeepAlive=true That\u0026rsquo;s snarfed verbatim from the Douglas Rumbaugh post. The davmail.url worked for me, and will probably work for you. My university uses a Duo-2FA powered authentication system, and that\u0026rsquo;s still the right URL. Go figure.\nWith that in place, fire up DavMail on the terminal like so:\ndavmail ~/.davmail.properties # put the path to your config file here This sets up a mail server proxy running locally on your computer.\nEmail client config # Douglas Rumbaugh has some examples for mbsync, which is what I use too. I like using the built-in macOS security tool to store my passwords in my system keychain, so I don\u0026rsquo;t have to type a gpg decryption key every time I want to sync.\nsecurity add-generic-password -a umail -s mbsync -w # this will prompt for the secret I put the login I use for my school account in there.\nNow, inside my .mbsyncrc I can do this:\nIMAPAccount uni Host 127.0.0.1 Port 1143 User XXXXXXXX@XXXXX.edu PassCmd \u0026#34;security find-generic-password -a umail -s mbsync -w\u0026#34; SSLType None AuthMechs LOGIN IMAPStore uni-remote Account uni MaildirStore uni-local Path ~/Mail/Umail/ Inbox ~/Mail/Umail/INBOX SubFolders Verbatim Channel uni Far :uni-remote: Near :uni-local: Patterns * SyncState * Create Both Sync All Expunge Near Fetching the secret token # With DavMail running and an IMAP-speaking client ready to go, you are prepared to fetch a secret token.\nSync your mail through DavMail—in my case, by running mbsync -a uni. You should see a link pop up in the DavMail log output:\nPlease open the following link: https://login.microsoftonline.com/common/oauth2/authorize?\u0026lt;...\u0026gt; proceed through authentication steps and paste back the final url that contains authentication code (blank page) Authentication code: Follow the instructions on the page—I finished doing a DUO push. Once that was done, I got redirected to a blank screen. COPY THE URL of that page, and dump it into a text editor to pull out the key you will need from the query string.\nThe key will look something like {AES}\u0026lt;really long base64 encoded string\u0026gt;, and for me it was sandwiched between a few of the query parameters.\nWith that key in hand, you can either paste it into the terminal, or you might have to open the DavMail config file. Douglas\u0026rsquo;s instructions said pasting the whole URL worked for him, but it never did for me.\nHere\u0026rsquo;s what my config file looked like in the end:\ndavmail.ssl.keystoreType= davmail.ssl.keystorePass= davmail.proxyPassword= davmail.oauth.tenantId= davmail.oauth.clientId= davmail.smtpPort=1025 davmail.enableKerberos=false davmail.folderSizeLimit= davmail.forceActiveSyncUpdate=false davmail.imapAutoExpunge=true davmail.useSystemProxies=false davmail.proxyUser= davmail.caldavEditNotifications=false davmail.ssl.nosecuresmtp=false davmail.caldavPastDelay=0 davmail.ssl.keyPass= log4j.logger.httpclient.wire=WARN davmail.noProxyFor= davmail.server=true davmail.popMarkReadOnRetr=false davmail.ssl.nosecureimap=false davmail.disableTrayActivitySwitch=false davmail.caldavAutoSchedule=true davmail.enableProxy=false davmail.proxyPort= davmail.logFileSize= davmail.mode=O365Manual davmail.smtpSaveInSent=true davmail.bindAddress= davmail.ssl.nosecurepop=false davmail.ssl.pkcs11Library= log4j.rootLogger=WARN davmail.ssl.keystoreFile= log4j.logger.davmail=DEBUG davmail.ssl.clientKeystoreType= davmail.clientSoTimeout= davmail.ssl.pkcs11Config= davmail.ssl.clientKeystorePass= davmail.imapPort=1143 davmail.url=https://outlook.office365.com/EWS/Exchange.asmx log4j.logger.org.apache.http.conn.ssl=WARN davmail.sentKeepDelay=0 davmail.ssl.nosecureldap=false davmail.imapAlwaysApproxMsgSize=false davmail.ssl.nosecurecaldav=false davmail.popPort=1110 davmail.defaultDomain= davmail.showStartupBanner=true log4j.logger.httpclient=WARN davmail.proxyHost= davmail.ldapPort=1389 davmail.server.certificate.hash= log4j.logger.org.apache.http.wire=WARN davmail.disableGuiNotifications=false davmail.imapIdleDelay= davmail.allowRemote=false davmail.disableUpdateCheck=false log4j.logger.org.apache.http=WARN # FIXME: make sure the username is correct here; for me it was \u0026#34;uXXXXXXX@umail.utah.edu\u0026#34; davmail.oauth.USERNAME.refreshToken={AES}THIS IS WHERE THE SECRET KEY GOES!!! davmail.caldavPort=1080 davmail.enableKeepAlive=true davmail.ssl.clientKeystoreFile= davmail.logFilePath= davmail.carddavReadPhoto=true davmail.keepDelay=30 davmail.oauth.redirectUri= davmail.caldavAlarmSound= Try re-running your email sync, and see if it works!\nConfiguring Emacs for sending mail # I use mu4e, but I think the smtpmail-* variables are also used by gnus and notmuch for sending mail—I could be wrong though, so if I am, someone please correct me. :)\nI use the following in my mu4e work context; adjust as needed:\n(make-mu4e-context :name \u0026#34;Work\u0026#34; :match-func (lambda (msg) (when msg (string-prefix-p \u0026#34;/Umail\u0026#34; (mu4e-message-field msg :maildir)))) :vars \u0026#39;((user-mail-address . \u0026#34;ashton.wiersdorf@utah.edu\u0026#34;) (user-full-name . \u0026#34;Ashton Wiersdorf\u0026#34;) (mu4e-compose-signature . \u0026#34;SIGNATURE GOES HERE\u0026#34;) ;; ↓ this is a neat function ↓ ;; (message-send-mail-function . message-send-mail-with-mailclient) (mu4e-get-mail-command . \u0026#34;mbsync uni\u0026#34;) (mu4e-bookmarks . ((:name \u0026#34;Inbox\u0026#34; :query \u0026#34;maildir:/Umail/INBOX\u0026#34; :key 105) (:name \u0026#34;Flagged\u0026#34; :query \u0026#34;g:f AND NOT flag:trashed\u0026#34; :key 102) (:name \u0026#34;Unread messages\u0026#34; :query \u0026#34;flag:unread AND NOT flag:trashed\u0026#34; :key 117) (:name \u0026#34;Today\u0026#39;s messages\u0026#34; :query \u0026#34;date:today..now\u0026#34; :key 116) (:name \u0026#34;Last 7 days\u0026#34; :query \u0026#34;date:7d..now\u0026#34; :key 119) (:name \u0026#34;Messages with images\u0026#34; :query \u0026#34;mime:image/*\u0026#34; :hide-unread t :key 112) (:name \u0026#34;Drafts\u0026#34; :query \u0026#34;maildir:/Umail/Drafts\u0026#34; :key 100))) (message-send-mail-function . smtpmail-send-it) (smtpmail-smtp-server . \u0026#34;localhost\u0026#34;) (smtpmail-smtp-user . \u0026#34;XXXXXXXX@XXXXXXXXX.edu\u0026#34;) ; base username email, not my nice first.last@utah.edu alias (smtpmail-stream-type . plain) (smtpmail-smtp-service . 1025) (mu4e-drafts-folder . \u0026#34;/Umail/Drafts\u0026#34;) (mu4e-sent-folder . \u0026#34;/Umail/Sent\u0026#34;) (mu4e-trash-folder . \u0026#34;/Umail/Trash\u0026#34;) (mu4e-refile-folder . \u0026#34;/Umail/Archive\u0026#34;))) I also had to add the following to my ~/.authinfo.gpg:\nmachine localhost port 1025 login XXXXXXXX@XXXXXXX.edu password XXXXXXXXX Note that the URL is localhost —this is because we are using DavMail as a proxy for Outlook.\nIf you have not set up your authsources, might be a good time to do that to manage secrets with Emacs. I have this in my config:\n(setq auth-sources \u0026#39;(\u0026#34;~/.authinfo.gpg\u0026#34;)) David Wilson has an awesome video on how to set up gpg to manage passwords with Emacs. I\u0026rsquo;d check out all his videos because he covers some seriously great stuff in the Emacs and the Guix space.\nAnyway, email with Outlook sucks—we wouldn\u0026rsquo;t have to do any of this crap if app passwords were a thing. But if there is no other way, then DavMail can bring a little sanity back to your email workflow.\nUpdate 2023-09-24: I used to have my affiliate link for Fastmail here. I\u0026rsquo;ve genuinely enjoyed their services and have received no financial compensation for the little recommendation I gave them here. However, I\u0026rsquo;ve decided to remove the affiliate link because I don\u0026rsquo;t think it\u0026rsquo;s appropriate for my blog.\nI personally use Fastmail, and I\u0026rsquo;ve enjoyed it. There are some good alternatives too. If you have the choice of email provider, just use something that respects your privacy and lets you use your own domain. Above all, never use Outlook if you can avoid it.\n"},{"id":35,"href":"/posts/2023-04-11_delimited_continuations/","title":"Delimited Continuations","section":"Technical Blog","content":"I\u0026rsquo;ve talked at some length about continuations and what they can do. In short, continuations let us manipulate the control flow programmatically. Among other things, it lets us implement generic non-deterministic backtracking search constructs, exception handlers, and cooperative threading—all without changes to the runtime or standard library!\nIf you need a refresher, see my previous post on continuations. The continuations that I talked about there were unbounded continuations, meaning that they captured the entire call stack. There\u0026rsquo;s another kind of continuation called a delimited continuation, which can do a superset of the things that an unbounded continuation can do.\nTo talk about continuations—delimited and regular—let\u0026rsquo;s look at a model of how a programming language get implemented. For that, we\u0026rsquo;ll talk about an abstraction of a language runtime with a thing called a CEK machine. Then we\u0026rsquo;ll realize the model with a simple implementation in Racket, and then we\u0026rsquo;ll talk about continuations.\nThe CEK machine # To understand continuations, it will be helpful to talk about an idealized machine: one that isn\u0026rsquo;t tied to any CPU architecture or memory constraints. Our machine is the CEK machine described by Felleisen et al. 1\nThe letters \u0026ldquo;CEK\u0026rdquo; stand for the three parts of the machine:\nC: Control The control state of the machine. This translates to the expression currently being evaluated. E: Environment An environment is a mapping of variables to values. K: Kontinuation A thing that answers, \u0026ldquo;once I\u0026rsquo;m done with this bit, what do I do next?\u0026rdquo; We\u0026rsquo;ll talk about this some more. Yeah, yeah, I know that\u0026rsquo;s not how you spell continuation, but the C was taken by \u0026ldquo;control\u0026rdquo;, so they went with K instead. Often times you\u0026rsquo;ll see interpreters defined in what\u0026rsquo;s called \u0026ldquo;big-step\u0026rdquo; semantics. All that means is that the interpreter takes an expression and produces a result, often calling itself recursively. It might look something like this:\nImplementing a CEK machine in Racket # Capturing continuations # Felleisen, Matthias, Robert Bruce Findler, and Matthew Flatt. Semantics Engineering with PLT Redex. Cambridge, Mass: MIT Press, 2009.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":36,"href":"/posts/2023-04-10_case_for_esoteric_langs/","title":"The Case for Picking a Non-Mainstream Programming Language","section":"Technical Blog","content":"How many JavaScript developers are there? A lot. What are your odds that a given candidate is a good programmer? Not great.\nIdentifying with a single language is rather myopic, in my view. Languages evolve, new ones arise, and old ones get discarded. It\u0026rsquo;s true that you can make a killing as a COBOL developer—I had a professor once who said that he took a COBOL job and made a good amount of money from it. Thing is, as soon as that job was over, he took COBOL off his résumé.\nI used to identify as a developer in a particular language. But hey, I\u0026rsquo;m still under 30 and I\u0026rsquo;ve moved away from that, so that\u0026rsquo;s good.\n"},{"id":37,"href":"/posts/2023-03-16_appreciation_for_business_programmers/","title":"Praise for the pragmatic third camp","section":"Technical Blog","content":"Some years ago I came across a blog post that described programmers as being in one of three camps. It\u0026rsquo;s a fun, short post, so I encourage you to go read that real quick, but the gist of it is that programmers generally fall into one of three categories according to what they primarily value:\nApplied mathematicians, who appreciate elegant solutions to problems. Program execution on von Neumann machines is incidental. These programmers like high-level languages and mathematically correct reasoning about programs.\nBit hackers, who like making the machine run as efficiently as possible. Without a von Neumann machine, programs are pointless. These programmers like low-level languages that let them get into the guts of things.\nProduct makers, who care about the ideals of the first and second camps in as much as they help them accomplish the task of delivering more features. Most industry programmers probably fall into this category. They like high-level languages as long as performance doesn\u0026rsquo;t suffer too much and that it\u0026rsquo;s pragmatic. (E.g. JavaScript, Ruby, Python, Go, etc.)\nThe author of the post talks a little bit about the tension between the camps. I won\u0026rsquo;t reproduce it here, but it can be amusing, so you should give it a read.\nI\u0026rsquo;ll go ahead and add one more camp to the list: the code monkey for whom coding is just a job. They care about the quality of their work in as much as it allows them to hit their deadlines and collect a paycheck. They don\u0026rsquo;t care too much about what language they use, as long as it\u0026rsquo;s the one they learned in school or their bootcamp. They\u0026rsquo;re generally not curious about learning new languages, understanding how things are implemented, or making a good UI.\nMost people I\u0026rsquo;ve worked with have fallen into the first three camps, fortunately. I\u0026rsquo;ve encountered a few who fall into the fourth camp I just outlined, and they\u0026rsquo;re miserable to work with if you care about anything. When you work with someone from camps 1–3, there\u0026rsquo;s some passion there to channel to make a better program, for whatever your metric of \u0026ldquo;better\u0026rdquo; is—and you can usually come to some consensus so that a program is better on multiple axes. But with the fourth, there\u0026rsquo;s nothing there to push on.\nI\u0026rsquo;ve found it to be a helpful paradigm: whenever I have a disagreement about someone about what constitutes good or valuable programming, I consider what kinds of things they value. (In a way, it\u0026rsquo;s a little like Jonathan Haidt\u0026rsquo;s Moral Foundations Theory for programmers.) Maybe you can think back to some disagreement you had and see the value mismatch manifesting.\nThe other day I experienced a burst of appreciation for camp 3—the pragmatic makers—more so than I had ever felt before. I was fighting with a crappy health insurance website. Instead of a \u0026lt;select\u0026gt; dropdown element, they had built a \u0026lt;div\u0026gt; with some on-click handler to make a faux dropdown. The website was janky, bloated, slow, and difficult to navigate. It must have been made by programmers in camp 4.\nI realized that the only camp that stands a chance of fighting this kind of crappy experience online is those programmers in camp 3: the soldiers who care about their craft enough to make the user happy. I realized that I would never ever want to build a better insurance site because that\u0026rsquo;s not an interesting problem to me, but there are those who have different motivations than I do, and these people can channel those motivations into hammering out better experiences for all of us.\nSo, here\u0026rsquo;s to the pragmatists—the people who care about the end and not so much the means. I\u0026rsquo;m going to stay in my camp working on more elegant tools for you to use. It\u0026rsquo;s nice that there\u0026rsquo;s some symbiosis between the three groups. We should all recognize that we need each other.\nExcept for camp 4. You\u0026rsquo;re the reason why we have crappy insurance portals.\n"},{"id":38,"href":"/posts/personal/2023-03-15_grandpa/","title":"Grandpa","section":"Personal Blog","content":" My grandfather G William Wiersdorf passed away Monday morning. He was 82 and survived COVID, a decades-long existence with MS, and World War II. While his health wasn\u0026#39;t the best, none of us were expecting this. You can read his obituary here.\nGerman obituary UPDATE 2023-03-18: I\u0026#39;ve translated my grandpa\u0026#39;s obituary into German. Here it is:\nG William \u0026#34;Bill\u0026#34; Wiersdorf verstarb friedlich am 13. März 2023 mit seiner liebevollen Frau Kathy an seiner Seite.\nBill wurde am 11. Dezember 1940 zu Anna Marrie Hedwig Bohnenstengel Wiersdorf und Wilhelm Franz Wiersdorf in Beyersdorf, Landsberg, Brandenburg, Preußen, Deutschland als Günther Willi Klaus Wiersdorf geboren.\nBills Vater wurde im letzten Tagen des zweiten Weltkriegs von Russische Soldaten gefangen genommen und starb in einem Zivelarbeitslager im Russland. Bill und seine Mutter waren dann Flüchtlinge nach dem Krieg und zog häufig währen die nächste paar Jahren in Deutschland zwischen gutherzige Familien um. Im Juni 1951, wanderten Bill und seine Mutter in die Vereinigten Staaten aus.\nBill lernte Englisch und als Teenager arbeitete für seinen Onkel Walter Stover in seinem Bettwaren- und Möbelfabrik in Salt Lake City. Bill lernte Möbel zu bauen und Lastwagen zu fahren. Bill diente eine Mission für die Kirche Jesu Christi der Heiligen der Letzten Tagen in Deutschland, und während seines Aufenthalts nahm er Kontakt mit vielen seinem verlorenen Verwandten wieder auf.\nBill schloss sein Studium an der Universität von Utah ab mit einem Grad in Spanisch. Bill unterrichtete Spanisch und trainierte Basketball an der Olympus Junior High, und später unterrichtete er Spanisch und Deutsch und trainierte die Fußballmannschaft der Olympus High School.\nBill erkrankte 1995 an Multipler Sklerose, und deswegen vorzeitig in Rente ging. Die Krankheit raubte ihm nach und nach seinem Gehfähigkeit und damit auch viele Aktivitäten, die er liebte. Er fand Befriedigung bei seiner Arbeit an seiner Utah Enzyklopädie Website (OnlineUtah.com) und verbrachte Tausende von Stunden Fotos und schriftliches Material dafür zu erstellen und kuratieren.\nBevor er von MS erkrankte war, wurde er von seine körperliche Stärke und Ausdauer bekannt. Mit wenig Hilfe, baute er ein Haus im Bergen und dort für Jahren veranstaltete Jugendgruppen und Familientreffen. Im Winter grub Bill eine Viertelmeile \u0026#34;Rodelbahn\u0026#34; in den Schnee, damit die Kinder im Schlitten herunterfahren konnten.\nNach MS war er für seiner geistliche Ausdauer bekannt. Obwohl die Krankheit sein Leben schwer machte, erlaubte Bill seinem Gesundheitszustand seine Seele in Geduld zu läutern. Bill folgte Jesus Christus nach und liebte es, andere Menschen wie er konnte zu dienen. Er liebte es auch, Zeit mit seiner Familie zu verbringen und freute sich besonders an seine wöchentlichen Video-Chats mit seinen Cousins, die in Deutschland wohnen.\nBill hinterlässt seine Frau Kathy Pearson Wiersdorf, seine Kinder Scott (Ana) Wiersdorf, Ryan (Liz) Wiersdorf, Jason (Erin) Wiersdorf, Rachel Wiersdorf, dreizehn Enkelkinder und eine Urenkelin.\n"},{"id":39,"href":"/posts/2023-02-21_metric_worship/","title":"Metric Worship, or: How a bad manager wrecked a (small) company","section":"Technical Blog","content":"I once worked as a part of a company with four employees, all of us programmers. We formed a sort of daughter company with a bigger—though still modest-sized—company that handled our payroll and whatnot. Our work directly helped the parent company, but we were organizationally independent development-wise. I really liked working with that small team: we had a one-hour meeting each week to plan out our work, and a short, casual stand-up each morning to get things rolling. Almost all my time was spent building features and squishing bugs. I got a lot of really good feedback on all my pull-requests, as everyone there really cared about making a good-quality product.\nThen we got acquired by a big, old, ossified company.\nWe got a new manager. Corporate dictated that all teams follow a two-week sprint, orchestrated through JIRA, and that every minute of our work be tracked. We now had three or four \u0026ldquo;SCRUM ceremonies\u0026rdquo; a week, each of which lasted between one to three hours. Our new manager had a baroque system to track our velocity and carefully calculated how many story points our team could complete a week.\nMy team\u0026rsquo;s interactions with our manager could be summarized in this meme:\nFigure 1: Metric-worshiping SCRUM manager encounters a programmer who cares\nMaybe I was (or am) a bit naïve, but it was such a deep shock for me to be forced to work at the cadence of someone who cared more about metrics than about the quality of the actual product. There were some funny moments we had with our new manager and company:\nManagers got worried about what the programmers would do in a three-hour window between the end of one sprint and the start of another. Clearly, work may only happen during a sprint!\nThe new company bragged about having gotten their 4-week-long release cycle down to the blazing speed of only 2-weeks. Someone from my company asked, \u0026ldquo;but we do CI/CD and deploy multiple times a day!\u0026rdquo; Management didn\u0026rsquo;t know how to work with such a tight release cycle. This was a SaaS product, mind you, so daily deployments was an easy way to squish bugs quickly.\nI was working part-time, and over 50% of my work hours were now spent in meetings determining how the rest would go.\nI had to clock every minute I spent on a ticket, and my manager got visibly frustrated when I forgot, because now his spreadsheet would be broken.\nI once forgot to move a ticket into the \u0026ldquo;done\u0026rdquo; column, and my manager got visibly flustered. I guess I had wrecked his precious little metrics.\nMy manager frequently bragged about having worked all weekend. What was this guy even doing? He\u0026rsquo;s a middle manager! Tweaking spread sheets and \u0026ldquo;grooming the backlog\u0026rdquo;, I guess.\nAnyway, the profound amount of crap I and my team had to put up with (combined with other passive-aggressive hostility from HR and other parts of management) sent my entire team packing within a matter of weeks. I don\u0026rsquo;t know who they found to maintain that code base. I\u0026rsquo;m not sure if anyone is maintaining it now. I feel sorry for the customers who liked our product. Management didn\u0026rsquo;t care about the product. All they cared about were their stupid little metrics.\nHow did this happen? # Maslow\u0026rsquo;s Hammer suggests one reason why this happens:\nIf all you have is a hammer, everything looks like a nail.\nManagement at this company had a huge hammer in the form of an overly-complicated JIRA setup. Every problem could be broken apart into little atomic pieces of work, scheduled into sprints, and orchestrated from afar.\nThere\u0026rsquo;s also Goodhart\u0026rsquo;s Law, which states:\nAny observed statistical regularity will tend to collapse once pressure is placed upon it for control purposes.\nWhen management fixates so much on metrics and ties rewards, praise, and incentives to hitting metrics rather than shipping good things, stuff will go downhill quickly. In our case, it drove out the people who cared. In other cases, mediocrity sets in.\nMonetary metrics are often a bad proxy for quality # It is an incredible privilege to work on something that you care about with people that also care about it. There\u0026rsquo;s a big difference between people who care about the quality of something and the people who only know what the monetary value of things are. This isn\u0026rsquo;t to say that business needs and financial questions are always bad to ask: at one job, many of my bright ideas (so I thought) got shelved because there simply wasn\u0026rsquo;t enough time and/or programmers to get the thing done, and we were working really hard to give people what they wanted.\nNow that I write that, the decision-makers in those instances were still completely different than that bad manager I had at the last company: the managers at the new company cared about the experiences that our users were having with our product and wanted to make that a high-quality experience. Their questions had a much better motivation than the bean-counting metric-chasing origins of the bad manager\u0026rsquo;s decisions.\nMoney can sometimes be an indicator for quality, but not always. Money just points you to what people are willing to pay for. Quality is multi-faceted and there can be many (sometimes competing) approaches to getting at quality. Maybe some of the complexity is why it\u0026rsquo;s tempting to move away from hard to quantify questions about quality and towards metrics that can be put on a linear scale and compared.\nThe two companies # I wrote a little bit about the differences between staff and line workers. I\u0026rsquo;ve been a line worker my whole life, and so I get frustrated when staff gets in my way to (in my view) the detriment of the end of the institution. There\u0026rsquo;s probably some needs of the staff that I don\u0026rsquo;t fully appreciate—I bet a lot of people are just trying to perfect the institution as a thing in itself, which could be a good and needed thing.\nAs I write this, I realize that I, a tool-lover, sometimes focus on making tools better an und für sich. It\u0026rsquo;s probably good that I\u0026rsquo;m in academia where researching and making better tools (e.g. better programming languages) is my objective, rather than trying to make a product to sell. Not that I\u0026rsquo;m bad at the latter—I shipped some pretty sweet stuff—it\u0026rsquo;s just that my decision making might be a little skewed at times. I\u0026rsquo;ll try and work on that.\nIn any case, focusing in metrics rather than the real quality of your product is bound to frustrate people who care. If you believe that JIRA and better metrics will be the key to making a better product, don\u0026rsquo;t: metrics have their place, but they can quickly get in the way.\n"},{"id":40,"href":"/posts/personal/2023-02-03_aspiration_changes/","title":"Changes in Career Aspirations","section":"Personal Blog","content":" It\u0026#39;s interesting for me to reflect on how my aspirations have changed as I\u0026#39;ve grown up. When I was a little kid I wanted to be a computer programmer like my daddy. I wanted to have my own cubicle and a work station and write Perl programs all day long in Emacs.\nThere was a phase where I had to shake my head at that—a cubicle-dweller? Seriously? After experiencing some open-office work spaces, the shoulder-high walls afforded a privacy and sound muffling that any hipster coder would be envious of.\nWhen I turned 16 I got my first job as an intern at my dad\u0026#39;s company. My dad was an architect at this point I think, and writing web apps with APIs and clean separation of concerns was the gold standard. My efforts were focused on web development and learning the tech stacks one normally learns with the web.1\nBy the time I got to college I wanted to be an architect. I knew I would have to rise through the ranks though, so I put a lot of effort into learning how to program web applications. I studied my data structures and algorithms so I could hit that sweet \\(O(\\log(n))\\) bracket of the Programmer Competency Matrix.\nThat started to change as I worked in industry. I landed some really nice jobs with TazWorks and Spiff. Spiff was basically the perfect job for me—or so I thought.\nHalf way through college I started leaning harder into my love of programming languages and mathematics. I didn\u0026#39;t know programming languages was a field in its own right until a professor asked me if I would be interested in doing PL research. That opened a door to me to paths that I didn\u0026#39;t know existed, but always wanted. I admired the likes of Larry Wall and José Valim who built languages rather than just used them. I could see a path towards working on languages now.\nNow I\u0026#39;m in the middle of a PhD at the University of Utah. The life of an academic is really appealing: I\u0026#39;d get to do research, maybe some consulting on the side, and I would be able to teach others about the beauty I find in computer science. The plan right now is to one day teach, but I\u0026#39;m glad there are other options available to me I\u0026#39;m incredibly grateful for the time I was able to spend in industry honing my craft. It\u0026#39;s nice to have a fallback if academia doesn\u0026#39;t work out. I sampled the good and bad of industry jobs, so that way, should I choose to remain in academia, it will be an informed decision. I\u0026#39;m glad I was able to sample so much and choose; I\u0026#39;m also grateful I was able to undo some of the self-inflicted pigeonholing of my younger years—instead of chasing what I thought was the end-goal of my interests, I followed my real interests and they led me to something different entirely.\nFootnotes 1 For sufficiently niche values of \u0026#34;normal\u0026#34;—I didn\u0026#39;t get too deep into JavaScript, hated PHP, and never touched any of the big enterprisey languages like Java or the shudder .NET framework.\n"},{"id":41,"href":"/posts/2023-01-17_what_is_a_type_system_really/","title":"What is a type system, really?","section":"Technical Blog","content":" Background # This is a question I\u0026rsquo;ve been wrestling with for a little bit. My first experience with a type system was with Java, and I didn\u0026rsquo;t like it. It just felt like an annoying constraint on the kinds of programs I could write. I was coming from Perl, which sports weak dynamic typing, so Java\u0026rsquo;s rigidity came as a bit of a shock.\nAfter Java I learned some C, which too has types. C\u0026rsquo;s types are different from Java\u0026rsquo;s in a big way: in C they\u0026rsquo;re really just directives to the compiler on how to interpret some bytes. \u0026ldquo;Everything is just void *\u0026rdquo; is kind of true. In C, bytes can be interpreted however you wish.\nAs I matured as a developer, I realized that sometimes I wanted constraints on what I could program. I wanted to have some way to narrow the scope of possibilities of things my program could do. While that may sound bad at first glance, consider if you could narrow the scope of ways your program would go wrong. That\u0026rsquo;s what types are designed to do.\nNot all type systems are equally powerful: while Java\u0026rsquo;s type system prevents certain classes of errors, a NullPointerException crops up here and there to blow your (well-typed!) program out of the water. Languages like Rust or Kotlin sport type systems that prevent NullPointerExceptions or segfaults from ever cropping up. The trade-off is that these type systems often take a little more time to get used to, and might make it harder to write certain kinds of programs.\nNew advances in type systems are mitigating those trade-offs, however. Kotlin\u0026rsquo;s type system does away with NullPointerExceptions without being too much more complex than Java\u0026rsquo;s, and things like gradual typing1 make the cost curve of adding static types to a dynamically typed codebase much smoother. The more I learn, the more I see that I can do with types.\nWhat is a type system? # In one sense types are just sets of values that an expression can take on. Suppose I have a variable of type Int: this implies the values it will be bound to belong to the set ℤ. This view of types is really good for thinking about how algebraic types work: when I take the product of two types (e.g. Int × Bool), I\u0026rsquo;m describing values that belong to the set of ordered pairs {(n,b) | n ∈ ℤ, b ∈ 𝔹} or the cross-product of the sets ℤ × 𝔹. Tuples and structs are usually how product types are realized in a programming language.\nThe same goes for sum types and set unions. A sum type is the union of two or more types; if I have a variable of type Nat + Bool, then it can be a number or a boolean. Tagged unions and enums are typically how you see sum types in programming languages.\nIf you consider the cardinality of a type, the metaphor continues to work.2 For example, if I have a type called a Byte that holds an integer between 0 and 255, and I pair it with a boolean in a tuple to produce the type Byte × Bool, then there will be 256 × 2 = 512 different values that inhabit the type Byte × Bool. Likewise with a sum type, where a value can be either Byte or Bool, then there are 256 + 2 = 258 different inhabitants of the type.\nEvery type system that I know of has some set of primitive types along with ways of combining those types into bigger structures. Primitive types typically include numbers, booleans, and strings, while combining structures usually include records (or structs, i.e. product types) and enumerations (i.e. sum types).\nStatic typing, dynamic typing, and type inference # Languages with a static type system are ones where the type of an expression—be it a variable, literal, compound expression, function call, etc.—is discernible without running the program. Haskell, Rust, Java, C, C++, Go, etc. are all statically typed languages.\nIn contrast, in a dynamic type system, the types of expressions are not knowable until runtime. The language implementation has to insert checks before e.g. performing an addition to make sure the types line up right. Perl, Python, Ruby, JavaScript, Scheme, Clojure, etc. are dynamically typed languages.\nSome static languages like Java require you to write down the type of every variable, expression, and function. Others, like Rust and Haskell, do something called type inference: this is where the type checker is able to infer, based off of the types of literal data as well as the operators in use, what the types for a program should be. This is different than a dynamic type system: just because you didn\u0026rsquo;t write down what type a variable was, doesn\u0026rsquo;t mean it is now dynamically typed. In Rust, Haskell, etc., every expression still has a type—it\u0026rsquo;s just inferred rather than explicitly given by you, the programmer.\nNominal vs. Structural # Some types are nominal and others are structural. These notions describe how two types are considered equal. Nominal types are what you get all over in Java: for two objects to be of the same type, they must both be of the same class. It doesn\u0026rsquo;t matter if you have two classes like:\npublic class Foo { int thing_1; boolean thing_2; } public class Bar { int thing_1; boolean thing_2; } Even though the members of Foo and Bar have the same interface and even the same names, a value of type Foo will never be the same as type Bar.\nStructural types determine equivalence based off of their algebraic structure. Most types in Haskell, ML, Typed Racket, and others work this way. This is kind of like a generalization of interfaces: if two types \u0026ldquo;implement\u0026rdquo; the \u0026ldquo;same interface\u0026rdquo; of having the same structure, they can be considered equivalent and interchangeable. However, some types in Typed Racket, like those based off of structures, are nominal—you don\u0026rsquo;t have to be all structural or all nominal in your language.\nMost of the time I find it easier to think in terms of structural types. There are times when nominal types make more sense, though. It\u0026rsquo;s nice when your language gives you the flexibility to choose.\nWhy do we care about type systems? # I think most computer scientists are familiar with the Halting Problem, but Rice\u0026rsquo;s Theorem is slightly less well-known.3 Rice\u0026rsquo;s theorem states:\nAll non-trivial semantic properties of programs are undecidable.\nWikipedia\nWhat is a semantic property? In contrast with a syntactic property, which is aspect apparent in the text of the program, a semantic property deals with what happens when the program runs. For example, \u0026ldquo;does this program halt?\u0026rdquo; is a semantic property, and the same semantic property covered by Turing\u0026rsquo;s Halting Problem. \u0026ldquo;Does this program contain any if statements?\u0026rdquo; is a syntactic property. \u0026ldquo;Does control reach this point in the program?\u0026rdquo; or \u0026ldquo;What values flow here?\u0026rdquo; are both semantic questions.\nType systems can turn certain semantic properties into syntactic ones: we can turn questions about the program\u0026rsquo;s runtime behavior (e.g. \u0026ldquo;Does a function taking integers get applied to a boolean causing a type error?\u0026rdquo;) into questions we can answer by examining the syntax of our program—if we have a statically typed language, we can tell—without running the program itself—whether or not no type errors ever occur.\nThere will still be programs when it\u0026rsquo;s impossible to decide whether or not the program has a type error:\n(+ (if (goldbach-conjecture-true?) \u0026#34;not a number\u0026#34; 42)) but in these cases we can restrict ourselves to programs that definitely do not have any type errors.\nBeyond sets: types as a meta language # Something I\u0026rsquo;ve learned recently is that \u0026ldquo;type system\u0026rdquo; is just what we call meta-languages for our programming languages. The language of types describes the behavior of a program written in another language.\nConsider the following program in Typed Racket:\n(: add1 (-\u0026gt; Number Number)) (define (add1 n) (+ 1 n)) The annotation (: add1 (-\u0026gt; Number Number)) is a proposition that add1 is a function that takes some value belonging to the set ℕ and gives back another thing in the set ℕ.\nNow if we call that function:\n(let ([seven : Number 7]) (add1 seven)) the : Number bit on the first line is a proposition that the variable seven will take on a value in the set ℕ.4\nNow, in the meta-language of types, we can check that the type of the argument seven matches with the type of the parameter n in add1. In this case, the types match, so we proceed. If the declared or inferred type of the argument did not line up, our type checker would complain that we had violated the rules of the meta-language. These rules in the meta-language, of course, correspond to the actual runtime properties of Racket. More on that later in § Erasure.\nTypes other than values # Many object-oriented (OO) languages have a notion of public and private variables. Visibility is another thing type systems enforce. Annotating a variable as being private is a proposition that it is only accessed in certain parts of the program, which is something the type checker can then ensure is enforced.\nTainting is another thing you might want from a type system: tainting refers to marking user-supplied data as \u0026ldquo;tainted\u0026rdquo;, and any attempt to e.g. modify this data or branch off of the value is prohibited, unless the data has been \u0026ldquo;sanitized\u0026rdquo; by e.g. explicitly parsing well-formed data with regular expressions or the like. This is supposed to help protect against injection attacks.\nA type system could have a wrapper type Tainted\u0026lt;A\u0026gt; that takes some data of any type and protects it from dangerous operations. Then you\u0026rsquo;d have functions like regex_sanitize :: Tainted\u0026lt;String\u0026gt;, Regex → String for when you want to parse a tainted string to get some data out of it.\nErasure # There is usually some kind of check to make sure that the propositions in the meta-language correspond to the program we\u0026rsquo;re describing. Without this check, there wouldn\u0026rsquo;t be anything stopping me from writing:\n(let ([seven : Number \u0026#34;definitely not a number!\u0026#34;]) (add1 seven)) and the program would still type check if it just blindly trusted the type annotations. Of course, as soon as the program runs, the runtime would explode at the add1 exception. Removing the types after checking is called \u0026ldquo;type erasure\u0026rdquo;, as the types are erased after type checking and the program gets run as if they had never been there.\nSome languages like Haskell and Java do this. This is safe to do because we\u0026rsquo;re only running programs that we\u0026rsquo;ve proven are well-typed. The upside to this is that we can save a lot of overhead by removing type checks. The downside is that certain kinds of runtime introspection might not be possible. Java, for example, doesn\u0026rsquo;t keep type parameters around on generics. Wikipedia has a good example of where ArrayList\u0026lt;Integer\u0026gt; and ArrayList\u0026lt;Float\u0026gt; both report the same thing under .getClass() at runtime.\nOne place to be careful is when typed and untyped code mix. This is where gradual typing comes in. Most languages are either statically typed or dynamically typed, but a growing number of languages are either being adapted to support or are being developed out of the box with support for gradual types. In these languages, like Typed Racket, you have to insert runtime checks to make sure code coming from an untyped module into a typed module agrees with the type guarantees.\nThere\u0026rsquo;s a lot of hidden complexity around gradual typing. Ben Greenman has many papers outlining some of the intricacies around the semantics of gradual typing.\nWat can go wrong # TypeScript is a bit of an odd language. The main page proclaims \u0026ldquo;TypeScript becomes JavaScript via the delete key\u0026rdquo; and just erases all types after type checking. You can call TypeScript modules from JavaScript, and TypeScript doesn\u0026rsquo;t put in any runtime checks. For example, you can do:\nfunction add2(a : number, b number) : number { return a + b; } console.log(add2(2, 7)); console.log(add2(\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;)); and get the result:\n9 foobar TypeScript\u0026rsquo;s type guarantees are only locally sound. As soon as your typed and untyped parts mix, your program will fall back on the very wat-worthy typing rules of JavaScript.\nWhen layers mix # How much can you program in this meta language of types? I\u0026rsquo;m still trying to understand this. Dependent types allow types to depend on values; i.e. you can have a type for \u0026ldquo;list with three integers\u0026rdquo;. Dependent typing, as I understand it, opens up complete programmability of the type system, at the cost of type checking becoming undecidable. These type systems allow you describe the behavior of your programs with incredible precision.\nI\u0026rsquo;ve done a little work with Coq, which supports dependent types. I haven\u0026rsquo;t done enough yet to really understand it well though!\nTypes as a design tool # Beyond the neat safety properties that type systems give me, I really like using types as a design tool. So often I\u0026rsquo;ll be working on transforming some data or pulling together information from multiple different sources to decide something, and it\u0026rsquo;s easy to get lost in the lines of code. What helps is for me to think of a function in terms of the shape of its inputs and the shape of the needed output. (This is part of the reason why I like structural type systems so much.) With the types in hand, the program almost writes itself.\nIndeed, there are times when the program can write itself! If you write down the type of a function, it\u0026rsquo;s not hard for an editor to suggest programs that satisfy that type. With more expressive types, the better the suggestions will be. To see an example of this in action, check out the type checker I made with μKanren, which can accept a type and generate expressions that satisfy it.\nOne thing that I like about this kind of program generation is the programs will definitely be correct, in the sense they\u0026rsquo;ll be well-typed. ML systems like GitHub Copilot are very impressive, but there\u0026rsquo;s always some chance that they\u0026rsquo;ll go completely wrong. Type-driven code suggestions can always be safe!\nDespite how cool type-driven code generation is, and how valuable the safety guarantees that types provide are, I find types to be of greatest aid as a tool for thinking and reasoning about my programs.\nAgain, what are type systems? # Type systems provide a way of writing down properties of our programs that we would like to be true, and then mechanically checking that those properties hold. Type systems come in all shapes and sizes; some are more expressive than others. Types are also a great tool to use when actually writing code.\nStatic type systems provide strong guarantees about program behavior at the expense of some friction in programming: dynamic languages make it easy to throw together a prototype, but can become unwieldy or difficult to maintain once the codebase grows. Gradual typing is an increasingly popular method to get the best of both worlds.\nFurther reading # I\u0026rsquo;d recommend checking out the Lambda Cube. Other books that I\u0026rsquo;ve read or am reading that have helped me understand types a bit better include:\nPractical Foundations for Programming Languages, by Robert Harper Types and Programming Languages, by Benjamin Pierce Semantics Engineering with PLT Redex, by Matthias Felleisen, Robert Findler, and Matthew Flatt Programming Languages: Application and Interpretation, by Shriram Krishnamurthi5 I\u0026rsquo;ve also written a post about how to write a type checker that hopefully should be pretty easy to follow.\nAcknowledgments # Thanks to my advisor Ben Greenman for reading a draft and correcting some inaccuracies in the erasure and gradual typing portions. Thanks also to Scott Wiersdorf and Alex Larsen for providing feedback and some much-needed polishing.\nGradual typing was first proposed by Jeremy Siek. The Wikipedia page on Gradual Typing has a decent introduction.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThis should suggest the relationship between sums and products in types and algebra is a deep one!\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nNext time someone asks you to write a program that does some static analysis of a semantic property, you can say to them (in your best Vizzini voice of course), \u0026ldquo;you fell for one of the classic blunders! The first is never get involved in a Turing-machine halting problem. The second which is slightly less well-known, never attempt to use static analysis when semantics are on the line!\u0026rdquo;\nAt this point it\u0026rsquo;s generally appropriate to laugh manically before falling over dead from iocane poisoning.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nTyped Racket would actually derive the type Positive-Byte for seven which is a subtype of Number. Typed Racket\u0026rsquo;s numeric type hierarchy is quite impressive!\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe book is available online here: https://www.plai.org/ The sections on types and type checking are quite excellent.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":42,"href":"/posts/2022-12-27_repl_buffer_on_the_right/","title":"Make an Emacs Buffer Open the Way You Want","section":"Technical Blog","content":"Are you tired of having a particular buffer pop open in the wrong direction? Do you wish, for example, that the Racket REPL buffer showed up on the right in a vertical split, rather than below in a horizontal one? Look no further. I give you, display-buffer-alist:\n(add-to-list \u0026#39;display-buffer-alist \u0026#39;(\u0026#34;\\\\*Racket REPL \u0026lt;/\u0026gt;\\\\*\u0026#34; (display-buffer-in-direction) (direction . right))) That little snippet will make sure when you hit C-c C-k inside of a racket-mode buffer, a REPL will pop up on the right-side instead of on the bottom. I find that much more comfortable to use.\nThe variable display-buffer-alist is a fantastically useful variable. There\u0026rsquo;s so much to it that I can\u0026rsquo;t write it up in a blog post. Fortunately, the indomitable Mickey Petersen has written up a fantastic article about how Emacs manages windows which you should definitely check out. Here are just some of the settings that I use:\nConfiguration for dedicated Eshell buffers # If you don\u0026rsquo;t use Eshell already, it\u0026rsquo;s definitely worth a look. You might justly wonder, \u0026ldquo;why should I use something that\u0026rsquo;s inferior to $TERMINAL_EMULATOR_OF_CHOICE?\u0026rdquo; Good question. I still make heavy use of my terminal, but I really like how I can use completion frameworks like Vertico or Corfu with Orderless to search through history. If you\u0026rsquo;ve put a bunch of effort into configuring Emacs in those ways, it\u0026rsquo;s really nice to port that across.\nI also used Eshell to great effect when I was debugging my implementation of Raft for a class. I had a ton of log messages getting dumped out to the screen, and on my terminal, the lines always wrap. Maybe there\u0026rsquo;s a setting to enable horizontal scrolling, but I couldn\u0026rsquo;t find it. With Eshell, that just comes right out of the box.\nOn top of getting long lines to play nice, I can also use the powerful search and filtering operations that I\u0026rsquo;m used to using to navigate my code to navigate through my terminal history.\nThere\u0026rsquo;s a lot more, but those features have intrigued me enough that I wanted to make it easy to pop open to Eshell whenever I could. Here\u0026rsquo;s what I use:\n;; Don\u0026#39;t forget to bind these functions to convenient keys (defun startup-eshell () \u0026#34;Fire up an eshell buffer or open the previous one\u0026#34; (interactive) (if (get-buffer-window \u0026#34;*eshell*\u0026lt;42\u0026gt;\u0026#34;) (delete-window (get-buffer-window \u0026#34;*eshell*\u0026lt;42\u0026gt;\u0026#34;)) (eshell 42))) (defun tab-to-eshell () \u0026#34;Open a tab with eshell. If that tab doesn\u0026#39;t exist, create it. If already in that tab, switch to previous tab.\u0026#34; (interactive) (if (equal (tab-bar-tab-name-current) \u0026#34;*eshell*\u0026lt;43\u0026gt;\u0026#34;) (tab-bar-switch-to-prev-tab) (eshell 43))) (add-to-list \u0026#39;display-buffer-alist \u0026#39;(\u0026#34;\\\\*eshell\\\\*\u0026lt;43\u0026gt;\u0026#34; (display-buffer-in-tab) (tab-name . \u0026#34;*eshell*\u0026lt;43\u0026gt;\u0026#34;))) (add-to-list \u0026#39;display-buffer-alist \u0026#39;(\u0026#34;\\\\*eshell\\\\*\u0026lt;42\u0026gt;\u0026#34; (display-buffer-in-side-window) (side . left) (window-width . 0.5) (window-height . fit-window-to-buffer))) I wanted to be able to open an Eshell buffer on the left side of the window whenever, and I also wanted to be able to make a dedicated tab that I could toggle between easily. With startup-eshell and tab-to-eshell respectively, I can do just that.\nOrg-Roam # I like using Org-roam for note taking. I wanted to make the backlinks buffer always appear in a narrow-ish window on the right. Here\u0026rsquo;s all the config needed:\n;; Dedicated side window for backlinks (add-to-list \u0026#39;display-buffer-alist \u0026#39;(\u0026#34;\\\\*org-roam\\\\*\u0026#34; (display-buffer-in-side-window) (side . right) (window-width . 0.4) (window-height . fit-window-to-buffer))) Things to note # There\u0026rsquo;s a difference between display-buffer-in-side-window and display-buffer-in-direction: the first, if I\u0026rsquo;m not mistaken, makes a dedicated window, which you can read about on Mickey Petersen\u0026rsquo;s site. The short of it is, that buffer will stay in that space and will not move, even if you\u0026rsquo;re used to your windows automatically re-laying out with e.g. evil-mode enabled.\nThe second is a little gentler, at least in my mind. It asks Emacs to open the buffer in one direction rather than another, and it\u0026rsquo;s just as if you had done C-x 2 or C-x 3 for up/down or left/right respectively.\nYet again, this is another testament to the fantastic power and flexibility of Emacs. This isn\u0026rsquo;t a life-changing configuration per se, but it definitely makes Emacs more comfortable to use for me.\n"},{"id":43,"href":"/posts/personal/2022-12-25_christmas/","title":"Christmas 2022","section":"Personal Blog","content":" This year I discovered the profound joy of giving toys to a little girl. Our daughter is beginning to babble and walk, and nothing has brought me more happiness than playing with her and watching her grow in her capabilities. She\u0026#39;s still young enough that she has no clue as to what is going on, but she did like getting some new toys wrapped in paper and bows! Christmas is so much better giving presents to your kids than it is getting presents as a kid.\nI am grateful for good health. My family got COVID earlier this year, and what a miserable time that was. Our little girl has been sick off and on, as happens with little kids. But by and large we\u0026#39;ve been unimpeded from doing things that bring us joy.\nI started my PhD! It was difficult for me to leave Spiff: I enjoyed working there, the work was interesting, and I have never worked on a team that cared so much about programming as a craft. It was the perfect job for me. Starting a PhD has been challenging—I discovered a deep mismatch between my interests and the interests of my advisor and I decided that I needed to switch advisors or try and get back into industry. Fortunately I\u0026#39;ll be working with someone whose interests are much better aligned—but more on that later.\nBooks I\u0026#39;ve started a small host of books. I think the only books that I finished were How to Write a Lot by Silvia and The Lost Metal by Sanderson. Some other books that I\u0026#39;m in the process of reading are: (in no particular order)\nBernoulli\u0026#39;s Fallacy, Clayton The Closing of the American Mind, Bloom The Constitution of Knowledge, Rauch Range, Epstein And technical books:\nSemantics Engineering with PLT Redex, Felleisen, Findler, and Flatt Compiling with Continuations, Abel Essentials of Programming Languages, Friedman and Wand Practical Foundations for Programming Languages, Harper There are some others, but that\u0026#39;s what I\u0026#39;ve got running around in my head right now.\nPeace I have never been so grateful for peace in my country. Watching the war in Ukraine unfold has reminded me of how much I have to be thankful for. I\u0026#39;ve tried to give a little extra in charity this year to help. I\u0026#39;d encourage you to do the same. It doesn\u0026#39;t feel to me that this comes up very often: there\u0026#39;s one clear bad and one clear good in this fight. Sure, individuals and groups will be doing bad things on both sides, but there\u0026#39;s nothing defensible about an invasion that regularly launches missiles against hospitals and children\u0026#39;s schools.\nBut whoso shall offend one of these little ones… it were better for him that a millstone were hanged about his neck, and that he were drowned in the depth of the sea.\nMatt. 18:6\nI am grateful my little girl is far away from war.\nI pray, and I hope, that I can do a little bit to temper hate and anger. I worry about a lot of things that seem small but, I feel, lead to the kind of collapse of dignified civilization that we see in increasingly authoritarian regimes. Technology is not going to save society—we need more people who are conscientious, moderate, kind, and forgiving.\nI am grateful for peace in my family. There are differences between myself and members of my family and my in-laws—some pretty deep ones too—but everyone put those differences aside for Christmas and we celebrated in a way that just felt happy and good.\nThere\u0026#39;s a lot I have to be thankful for. Peace in various parts of my life is something I\u0026#39;m cherishing more than normal this year. May we all be generous peacemakers. I\u0026#39;m still working on it, but it\u0026#39;s worthwhile to keep trying. Be the slack and the flex in the system: absorb jostles and bumps, unjust as they are. We need worry more about what we can give in our relationships and less about what we might think we are owed. There\u0026#39;s a balance there: we shouldn\u0026#39;t allow ourselves to be abused—but trying to be a little kinder never hurts.\n"},{"id":44,"href":"/posts/2022-12-05_what_i_like_in_a_coding_font/","title":"What I Like in a Font for Code","section":"Technical Blog","content":"I\u0026rsquo;m well aware that I may have a bit of an obsession with fonts. I don\u0026rsquo;t think that\u0026rsquo;s too unusual for someone who works in tech, however. Sites like Programming Fonts exist to let people test drive and compare a bunch of different fonts. Just for fun, I thought I\u0026rsquo;d write up some of the features I look for in a programming font that I\u0026rsquo;ve come to deliberately pick out.\nCritical letter forms: i, I, l, 1; o, O, 0 # These are probably the most important letters to get write in any font that\u0026rsquo;s meant to be hyper-legible: lowercase l must be easily distinguishable from an uppercase I or the number 1, and the lowercase i should stand out nicely as well.\nI like to foot of the lowercase l to be curved to more easily distinguish it from the number 1. For example, this is what the letters look like in my Iosevka Output build:\nI find that that helps readability. I go back and forth as to whether or not I like the foot of the lowercase i to be likewise curved. My current font doesn\u0026rsquo;t have that set, but I used to configure Input Mono to work like that.\nZeros must be distinct from capital O. That\u0026rsquo;s usually pretty easy for a coding font to get right. I personally like the slash—I think that\u0026rsquo;s what I grew up with. Nothing wrong with a dot though.\nIncreased pickiness: a, g # I like double-storey a and g rather than their simpler counterparts. A single-storey a looks a little too much like a lowercase o, and I find the g without two loops looks too much like a lowercase y.\nWidth # Narrow fonts appeal to a lot of people. I don\u0026rsquo;t get it, however. I like how gentle an extended font is on the eyes. One of the reasons why I liked Input Mono so much was because it had nice, comfy, wide characters. Compare the readability:\n{{\u0026lt; tabs \u0026ldquo;normal-and-narrow\u0026rdquo; \u0026gt;}}\n{{\u0026lt;tab \u0026ldquo;Normal\u0026rdquo;\u0026gt;}}\n{{\u0026lt;/tab\u0026gt;}}\n{{\u0026lt;tab \u0026ldquo;Narrow\u0026rdquo;\u0026gt;}}\n{{\u0026lt;/tab\u0026gt;}}\n{{\u0026lt; /tabs \u0026gt;}}\nI find the wider font to be much more readable.\nLigatures # Nope. Just nope. I like to see exactly what characters are in my files. See Matthew Butterick\u0026rsquo;s take for more reasons why.\n"},{"id":45,"href":"/posts/2022-11-22_never_surrender/","title":"Never surrender your password","section":"Technical Blog","content":"In a study that Ars Technica reported on, researchers found that an alarming number of computer repair technicians snooped through clients\u0026rsquo; devices—and female clients were way more likely to have their data accessed. Yikes!\nI once had to take my laptop to get some repairs done. The TAB key on my 2016 MacBook Pro had started glitching, and that wasn\u0026rsquo;t going to fly when I was working on code and needed my tab completions and app switching to be seamless. I took my laptop to the Apple-authorized repair service at my school. The surly technician confirmed my warranty and asked me to fill out an intake form for my computer.\nOne of the fields on that form was for the root password to my computer. I noted that this form wasn\u0026rsquo;t going to be encrypted, and so I declined to give the password to decrypt my hard drive. (To be honest, even if I could have somehow verified that the form were going to be stored securely, I wouldn\u0026rsquo;t have given up the password.) The technician got a little huffy and said that they needed to be able to run diagnostics to make sure everything was done correctly, etc. This was hard to believe, since it was a hardware problem that could be handled without any software intervention. I refused again; I told them (and wrote in the notes field of the form for any other support technicians) that I worked nearby and could come enter my password if needed within two minutes of getting a call.\nThe technician didn\u0026rsquo;t like that, but I was insistent. Eventually they relented. I didn\u0026rsquo;t have to give up my password and the repairs were completed without any problems. I was never called to input my password. I doubt something nefarious would have happened at that campus repair shop, but you never know.\nThere\u0026rsquo;s too much on your hard drive that cannot leak: information about your bank, access to your email, saved passwords, photos, journal entries, etc. Never surrender your password. There may be times when there is a legitimate need for the master password to run some diagnostics, but you should if at all possible be present to put that password in yourself and monitor closely what is done with your hardware. Go out of your way to find reputable repair shops. It will be worth the privacy.\n"},{"id":46,"href":"/posts/2022-11-17_continutations/","title":"Continuations—what are they?","section":"Technical Blog","content":"I had a friend ask me what continuations are, and why they\u0026rsquo;re useful. There\u0026rsquo;s a ton of literature about continuations; this is just a simple example meant to showcase something small and hopefully grokkable.\nYou will need to understand a little bit of Racket, but if you know any Scheme, that should be good enough. If you just want a quick primer, check out Learn X in Y minutes for Racket.\n#lang racket ;;; Export these symbols (provide fail pick non-deterministic-factor) ;;; Global stack of choices (only visible to this module) (define *choices* \u0026#39;()) ;;; Pop a value off of the alternate choices stack (define (fail) (if (null? *choices*) #f (let ([next-choice (car *choices*)]) (set! *choices* (cdr *choices*)) (next-choice)))) This next function pick is where we capture the continuation. I\u0026rsquo;ve named it return-from-pick to illustrate that when you call this function, it will jump back to the point in the code where pick returns. However, this works even if you use the continuation after the thing the called pick itself has returned.\nInternally, the continuation is basically stack + program counter. It answers the question \u0026ldquo;where does this value go to when I return it?\u0026rdquo;\nWe \u0026ldquo;install\u0026rdquo; the continuation by calling it like a function. It\u0026rsquo;s a first-class value, though, so we can save it in a closure on a stack and call it as many times as we want.\n(define (pick vals) (if (null? vals) (fail) ; fallback if there\u0026#39;s nothing to choose (let ([my-choice (car vals)]) ; pick something (let/cc return-from-pick ; capture the continutation right here! ;; Push the rest of the options into the *choices* stack (for ([other-choice (cdr vals)]) (set! *choices* (cons (λ () (return-from-pick other-choice)) *choices*))) ;; This is how we return from the `pick\u0026#39; function with a particular value. (return-from-pick my-choice))))) Now we have to use our operator. Let\u0026rsquo;s write a factoring function that non-deterministically picks a factor. We test it to make sure that the one we picked works, and if it did, we return it. Otherwise, we tell the computer that we fail ed.\n(define (non-deterministic-factor n) ;; Pick some factor, dunno which (let ([some-factor (pick (range 2 n))]) ;; Did we pick a factor? (if (zero? (modulo n some-factor)) some-factor ; yes we did! (fail)))) ; oops, that was the wrong one If you save those snippets into a file called amb.rkt and try running it, you should see something like:\n$ racket -it amb.rkt \u0026gt; (non-deterministic-factor 42) 2 \u0026gt; (fail) 21 \u0026gt; (fail) 14 \u0026gt; (fail) 7 \u0026gt; (fail) 6 \u0026gt; (fail) 3 \u0026gt; (fail) #f \u0026gt; (fail) #f ,quit $ Moral of the story: we just implemented McCarthy\u0026rsquo;s non-deterministic/ambiguous amb operator which picks some value, tries it out, then seemingly backtracks no matter the code to the point where the value gets picked if the fail function is ever invoked. Moreover, this was all implemented in userland: no special compiler constructs, no macros, no nuffin'.\nIn reality, what we did was we saved the stack and program counter just before we returned from pick with our choice. When we call fail, we reinstantiate that stack frame but return a different value. The program proceeds as if we had returned with that value in the first place. (Though note that changes on the heap or the file system, etc. will not be reverted. It\u0026rsquo;s only in side-effect free code that the illusion of time travel will be complete. You could stick a print statement in the fail function to see just how many times it gets called as the program searches for a path that doesn\u0026rsquo;t call fail.)\nContinuations can also be used to implement cooperative threading, job queues, and exception handling if you language doesn\u0026rsquo;t support those. In each case, you can extend the language with continuations and functions without the rest of the code having to worry about it. It\u0026rsquo;s a very powerful, robust, and non-leaky abstraction.\n"},{"id":47,"href":"/posts/2022-11-07_unix_philosophy/","title":"Unix As a Tool Forge","section":"Technical Blog","content":"Wikipedia cites a few different sources on what \u0026ldquo;Unix Philosophy\u0026rdquo; is. Peter Salus summarizes it as:\nWrite programs that do one thing and do it well. Write programs to work together. Write programs to handle text streams, because that is a universal interface. That second bullet point is my favorite: making composable programs rather than monolithic systems. In this way, Unix is designed to be a forge for easily building new tools. The first rule—writing programs that do one thing well—is largely a means to the second. When you have building blocks that take simple shapes, you can compose them easily like Lego pieces.\nI think that second goal is what makes Unix win: instead of providing you with every tool under the sun, you get a set of composable tools that allow you to construct better tools perfectly tailored to your problem. No one hacking on a PDP-11 thought to make an easy way to publish a blog like this one, but they put the framework in place to let me put together the tools I need to deploy this very post with a single command.\nHow Emacs fits inside of Unix philosophy # One might argue that Emacs goes against Unix philosophy, for it can quite literally do pretty much everything. But that only violates the first rule—if you consider Emacs to be a tool forge, then Emacs is quite in line with the Unix philosophy. Emacs provides functions that all work on the buffer or bits of text, and these can all be composed to craft a work environment to fit your needs. I use over 100 different packages, and they all play nice together!\nEmacs once ran Germany\u0026rsquo;s flight control software (source). Please don\u0026rsquo;t try this at home.\nI have come to view Emacs as my primary forge. It\u0026rsquo;s my layer on top of Unix, if you will. If I have Emacs customized how I like it, it doesn\u0026rsquo;t matter too much what operating system lives underneath: I can get a lot of work done. I used to view Emacs just as a tool, and I used it exclusively as a text editor. As time went on, though, I began to value the extreme keyboard-centric control Emacs gave me over my system. That\u0026rsquo;s why I moved from the terminal to the GUI version of Emacs: I wanted to have more modifiers available to bind functions to.\nMany people use Emacs exclusively as a text editor, and that\u0026rsquo;s fine. Usually these people have gotten comfortable with the command line, which is just another kind of tool forge. The great thing is both places make building new tools easy. Whatever your toolkit (though I do recommend you add Emacs to it if it\u0026rsquo;s not already there!) make sure you can build new tools with ease.\nFurther Reading # Discussion on Hacker News A kind chap sent me a link to this blog post as well as their own thoughts, which seemed like good things to link to. "},{"id":48,"href":"/posts/2022-10-26_yet_another_blog_theme/","title":"Yet another blog revamp","section":"Technical Blog","content":"Yes, it\u0026rsquo;s time to redo my blog again.\nThis time I found an ultra light-weight blog theme. This page here is under 100KB!\nI wanted to make something that acts more like a homepage for my research, rather than a blog. I still have all my blog posts, but now the focus will be on a more professional presentation of my work.\nThis theme is really what I\u0026rsquo;ve wanted all along: a home page with a max-width for the text, table of contents, and built-in local search!\n"},{"id":49,"href":"/posts/2022-08-28_keep_email_federated/","title":"Email, Getting Work Done, and Corporations, Or: Outlook Considered Harmful","section":"Technical Blog","content":"It\u0026rsquo;s hard to overstate how important email is in our modern world. Even as hip new platforms like Slack \u0026amp;co. gain traction in the workplace, so much communication takes place in a crusty old medium that\u0026rsquo;s outlived every purported \u0026ldquo;email killer\u0026rdquo;. Where does it get its staying power from?\nEmail predates much of the Internet as we know it today. Its current incarnation first emerged in the early 80s, though it has roots in earlier forms of digital messaging from as far back as the 60s. \u0026ldquo;Email\u0026rdquo; is roughly three related protocols: SMTP, \u0026ldquo;Simple Mail Transfer Protocol\u0026rdquo;, which deals with the sending of mail; IMAP, or \u0026ldquo;Internet Message Access Protocol\u0026rdquo;, which allows mail clients to fetch mail; and POP3, or \u0026ldquo;Post Office Protocol\u0026rdquo;, an older mail fetching protocol largely superseded by IMAP.\nOne neat thing about email is that you don\u0026rsquo;t have to use a particular email client to send and receive messages: it doesn\u0026rsquo;t matter if you use Gmail\u0026rsquo;s web interface, their mobile app, or Thunderbird, or Apple\u0026rsquo;s built-in email program, or even text-based mail clients like mutt—everyone can still talk to each other.\nMoreover, different email clients have different strengths: Gmail, for instance, is so simple that your grandma can (and probably does) use it to send you pictures or reminders about the family reunion next weekend. Academics, who typically have to deal with overwhelming heaps of emails, can use keyboard-driven mail clients to digest all these messages. (See Nicolas P. Rougier\u0026rsquo;s mu4e-dashboard package for an example of what some academics do.)\nThe point: email derives its staying power from how the common platform (SMTP, IMAP) is decoupled from how one interacts with it. (mail clients) It is malleable and ubiquitous, and everyone can adapt it for their needs.\nOutlook is faux email # I\u0026rsquo;m starting a new position as a research assistant at the University of Utah, and I\u0026rsquo;m elated to be here. However, the university is pushing everyone to use their MS Outlook email system, and they\u0026rsquo;ve disabled SMTP and IMAP access. The mail client that I use (mu4e for those wondering) is built to work with these common, decades-old standards of IMAP and SMTP. I can\u0026rsquo;t use the built-in OS\u0026rsquo;s mail client or (heaven forbid) the web client nearly as effectively.\nI\u0026rsquo;ll be trying some work-arounds, but I\u0026rsquo;m not optimistic that anything will be resolved in the near future. So for now I\u0026rsquo;m stuck using the mail client provided by my operating system for work-related email. It\u0026rsquo;s really a shame because some brilliant Emacs users have made managing email pleasant and effective.\nWhy would the university block the tools that I need to do my job effectively? I have a theory on that.\nThe theory of two companies # This also goes by the name \u0026ldquo;staff and line\u0026rdquo;.\nInside every organization there are two smaller companies: company 1 and company 2.\nCompany 1 is concerned with the product of the organization. In a tech firm for instance, company 1 is usually made up of engineering, product, sales, and marketing. (Broadly speaking.) In a university, company 1 is the faculty who are there to teach and do research.\nCompany 2 is concerned with running the organization. In a tech firm, this includes IT, HR, middle management, etc. In a university, company 2 is comprised of the staff and administration.\nThe primary job of company 2 is to support company 1\u0026rsquo;s operations. However, as is the nature with any large system, company 2 often begins to put some of its priorities over those of company 1\u0026rsquo;s. I saw this happen in a tech company I left a few years ago when management mandated that developers track the time they spent on each ticket in our scrum waterfall system down to the minute. This wasn\u0026rsquo;t a move that helped the developers in any way—this was just for management to feel like they had some better control of the situation.\nLikewise with university email: no one I know would elect to use Outlook as their email platform. It seems the university administration has deemed it better to force everyone into a closed system to avoid the potential of lawsuits. It helps the university as an organization, but it gets in the way of the faculty\u0026rsquo;s work.\nI get nervous when company 2 starts putting its priorities over company 1\u0026rsquo;s. To some extent it\u0026rsquo;s necessary, but it can be a slippery slope into bureaucratic paralyzation.\n"},{"id":50,"href":"/posts/2022-08-11_til_vertical_monitors/","title":"Today I learned: Vertical monitors and subpixel anti-aliasing","section":"Technical Blog","content":"Something I learned today from a coworker: if you turn your monitor sideways, subpixel anti-aliasing gets completely broken. This isn\u0026rsquo;t as much of an issue on today\u0026rsquo;s high-dpi displays, but for anything lower than a 4k screen, the effect can be noticeable.\nJust a little interesting thing I learned today. Thanks to my good, knowledgeable friend and coworker Jonner Steck!\nAlso, while we\u0026rsquo;re on the topic of font rendering, I\u0026rsquo;ve updated Iosevka Output to more closely match Input Mono: the cross-bar on the f now lines up nicely with the x-height. However, I kept the hook on the f open; I think it\u0026rsquo;s more legible than Input in that regard. I\u0026rsquo;ve finally switched over from preferring Input and seeing Iosevka as weird, to now seeing my custom font as the familiar, good-looking one and the Input, though still very good-looking, is a little less familiar.\n"},{"id":51,"href":"/posts/2022-08-01_a_new_font/","title":"A New Font","section":"Technical Blog","content":"This week I created a custom build of the Iosevka font. I\u0026rsquo;ve used Input Mono for a long time now, and was very happy with it. However, it was missing a few glyphs that I wanted to use. Moreover, I didn\u0026rsquo;t have a license for the Input font to use on e.g. my blog. Iosevka is stupendously customizable, so I thought I\u0026rsquo;d see if I could get something close to Input\u0026rsquo;s styles.\nIosevka\u0026rsquo;s default style is extremely narrow. However, I discovered that the width of Iosevka extended at 13pt matched Input at 12pt exactly. Here\u0026rsquo;s a side-by-side comparison: the first picture is with Input Mono, and the second is with my new Iosevka Output font:\nFigure 1: Input Mono at 12pt font\nFigure 2: Iosevka Output at 13pt font\nI loose a few lines with the Iosevka font, but that\u0026rsquo;s a deliberate choice as its ascenders are pretty tall. I originally had leading = 1100 in the build plan, which matched Input exactly, but I decided that this was more legible.\nIt wasn\u0026rsquo;t that hard either. Turns out, there\u0026rsquo;s a predefined stylistic set (ss18) that matches almost all the Input characters well. Some features that I made sure were present:\nDouble-storey a and g: I find this more legible as I don\u0026rsquo;t mistake these characters for o or y respectively. Tailed-and-serif l: the curved bottom differentiates it clearly from 1 or I. \u0026ldquo;Term\u0026rdquo;-style spacing: I didn\u0026rsquo;t like characters such as → taking up more than a single character\u0026rsquo;s width. Looks pretty, but messes up some of my UI elements. There are a few more tweaks that I\u0026rsquo;ve made to the font, and I\u0026rsquo;m likely to tweak it some more. I\u0026rsquo;m still getting used to this Iosevka style, but I\u0026rsquo;m going to drive it for a week or so to give it a fair shake. It\u0026rsquo;s growing on me for sure.\nIf you want to try it out, head over to my Codeberg repo and download the build artifact.\nBuilding Iosevka # You\u0026rsquo;ll need nodejs (ugh) and ttfautohint installed. See the docs for custom Iosevka builds for more details.\nWhen you clone the Iosevka repository, be sure to not clone all 20 Gb of history:\ngit clone --depth 1 https://github.com/be5invis/Iosevka Once you\u0026rsquo;ve got the build repo cloned, copy my private-build-plans.toml file into the root of the Iosevka directory, and run according to the directions in the Iosevka project.\n"},{"id":52,"href":"/posts/2022-07-27_how_to_write_a_type_checker/","title":"How to write a type checker/type inferrer with good error messages","section":"Technical Blog","content":"This is an experimental type checker/inferer for a simple lambda calculus. All the source for this may be found on my Codeberg repository.\nDescription # This is a type inference system for a little language. (Described below.) It uses a fusion of type inference algorithms from PLAI, ESP, and μKanren. (See Resources)\nBroadly speaking, our type inference engine works by:\ngenerating typing constraints from the program solving those constraints We\u0026rsquo;ll describe each of those in more detail.\nLanguage description # We implement a really simple language that includes features such as the following:\n42 ; numeric literals #t ; booleans (let (x 1) (+ x 1)) ; single-variable let; binary math operators (λ y (+ y 2)) ; single-argument anonymous functions (let (id (λ x x)) (if (id #t) (id 2) (id 3))) ; let-polymorphism; conditionals At time of writing, the let-polymorphism works though it\u0026rsquo;s still a little rough.\nType checking vs type inference # Type checking a step in language implementation where type annotations supplied by the user are mechanically checked prior to compiling or execution. Any time when the checker can determine that a value of the wrong type flows to a place (e.g. a variable, argument to a function, etc) it is called a type error.\nType inference saves programmers from having to write out all type annotations. Most times (though not always) it is possible to infer what the type of a variable should be. Literal values are really easy, for example:\nlet foo = 42; The variable foo clearly should have some kind of integer type. However, type inference is more powerful than just inferring variable types from their initial values; for example, consider this Rust snippet:\nlet add_1 = |x| x + 1; // (lambda x: x + 1) for you Python programmers What should type should the variable x have? Well, we know that it gets passed to +, so definitely some numeric type. Although the programmer doesn\u0026rsquo;t explicitly annotate the parameter x with its type here, we can tell using information elsewhere in the program. This is the role of type inference.\nWhy do we care about type inference? # Type inference saves us a lot of typing. Moreover, if we are trying to retrofit a type system onto an existing system that has a lot of code written in it already, it would be nice to not have to require users of the language to go back and annotate all their existing code. We can still report type errors as we find them—they would have been caught at runtime anyway—ideally, existing code should just work, and future code should turn out safer.\nConstraint generation # What are constraints? # Constraints are statements about what how types and bits of a program relate to each other. For example, here is a little program with some constraints illustrated:\nFigure 1: A little Rust program with some type relationships illustrated.\nEven though none of the variables have explicit type annotations, we know that x must be some kind of number, add_1 is a function ℕ→ℕ, and y_plus_1 must be a number because it\u0026rsquo;s the same as the return value as add_1. Moreover, whatever y is, it has to match the input type of add_1 as well.\nHow do we generate constraints? # At time of writing, we only have equality constraints, which state that some particular expression must have the same type as another type expression. Later we will likely add subtype constraints or union constraints which will involve some form of back-tracking.\nOur algorithm walks through the AST of a program and emits a list of constraints on particular points of the AST. Please see one of the listed Resources for more details.\nMost explanations (PLAI, EPL) of a type inference algorithm dump the generated constraints into a set. Here we diverge somewhat from the literature: we gather the constraints into a list, which keeps the constraints in rough order of when we encountered those constraints in the program. This ordering is important for good error generation later on.\nWe will likely play with how these constraints are ordered in the future.\nA good excerpt from PLAI:\nWhat are constraints? They are simply statements about the types of expressions. In addition, though the binding instances of variables are not expressions, we must calculate their types too (because a function requires both argument and return types). In general, what can we say about the type of an expression?\nThat it is related to the type of some identifier. That it is related to the type of some other expression. That it is a number. [/Or in the case of this interpreter, that it is a boolean./] That it is a function, whose domain and range types are presumably further constrained. Unification # We use ideas from the unify algorithm in μKanren: we have a walk function along with a substitution list that we can modify non-destructively. This differs from how PLAI and EPL describe unify, which often does destructive replacement of variables in the substitution list.\nI think this algorithm has the benefit of being a little simpler to understand, once the purpose of the walk function is grokked. It does mean that you must invoke (walk ast-chunk substitution-list) in order to find the type of the AST node.\nSee the infer-and-annotate and patch-annotations functions for a demonstration of how the substitution list along with the original tagged AST can be used to get the type for every node in the program.\nConstructed types, or higher-order types # Our simple language doesn\u0026rsquo;t have (yet) types like (listof ℕ), but it could if we wanted to let it. Use function calls as a model for how we would handle these cases. From PLAI:\nWe have used numbers as a stand-in for all form of base types; functions, similarly, stand for all constructed types, such as listof and vectorof.\nError message generation # Our error message generator is sensitive to the order in which type constraints are eliminated during the unification process: we generate the constraints in rough order of when the type of something would be encountered. E.g., when evaluated the form (+ 1 2), we generate the constraints for the literal values 1 and 2, then we generate the numerical type constraint that + imposes on its arguments.\nThis seems to do a pretty good job of giving us the information we need.\nExtending the language # Adding new forms to the language only involves modifying the constraint generation and error message production routines. (Along with a few ancillary functions like AST tagging etc.) The unify routine essentially stays the same.\nWhen we add type unions we will have to modify unify to support some form of back-tracking. We will also have to make some modifications with let polymorphism.\nOpen Tasks # Basic type inference Decent error messages if and let forms Type unions let-polymorphism Occurrence typing for handling nullable types Resources # PLAI Programming Languages: Application and Interpretation, Krishnamurthi. See chapter 15 online. EPL Essentials of Programming Languages, Friedman and Wand. See Chapter 7. μKanren For the original paper, and implementation, and other resources, see my repo on Codeberg. "},{"id":53,"href":"/posts/2022-07-20_adding_a_clock_to_emacs/","title":"Adding a Clock to the Tab-Bar in Emacs 28","section":"Technical Blog","content":"Today I figured out how to add a tab-bar to Emacs. I didn\u0026rsquo;t like having it in the mode-line: it gets duplicated for every window and my mode-line space is precious. In contrast, the right side of the tab-bar was always blank. I\u0026rsquo;ve just been using my OS\u0026rsquo;s clock, but I started using non-native fullscreen with Emacs, so I wanted a view of the clock again.\nAdd this to your early-init.el or the like:\n(add-to-list \u0026#39;tab-bar-format \u0026#39;tab-bar-format-align-right \u0026#39;append) (add-to-list \u0026#39;tab-bar-format \u0026#39;tab-bar-format-global \u0026#39;append) (setq display-time-format \u0026#34;%a %F %T\u0026#34;) (setq display-time-interval 1) (display-time-mode) Adding that tab-bar-format-global to the tab-bar-format list means that whatever would to on the \u0026ldquo;global\u0026rdquo; section of the format line will now appear in the tab bar. The tab-bar-format-align-right puts the clock at the top-right hand corner, instead of right next to the tab. Here\u0026rsquo;s what it looks like:\nNote that this only works in Emacs 28.\nI wrote an ugly hack that uses a posframe to display the time in the right place. I do not recommend this, but if you\u0026rsquo;re still on Emacs 27 or earlier for whatever reason, this might work for you:\n;;; Hack to display a clock in the tab-bar (defun posframe-poshandler-real-top-right (info) (cons (- (plist-get info :parent-frame-width) (+ (plist-get info :posframe-width) (* (plist-get info :font-width) 2))) 0)) (defun update-posframe-clock () \u0026#34;Update the clock displayed with posframe\u0026#34; (let ((the-time (format-time-string \u0026#34;%H:%M:%S\u0026#34;))) (if (\u0026gt; (length (tab-bar-tabs)) 1) (posframe-show \u0026#34;*clock*\u0026#34; :string the-time :width 8 :poshandler \u0026#39;posframe-poshandler-real-top-right :background-color (plist-get (custom-face-attributes-get \u0026#39;tab-bar nil) :background)) (posframe-delete \u0026#34;*clock*\u0026#34;)))) (when (display-graphic-p) (run-with-timer 1 1 #\u0026#39;update-posframe-clock)) Again, I recommend you find something better than the above. It will almost certainly break. Caveat emptor.\n"},{"id":54,"href":"/posts/2022-07-17_social_media_rules/","title":"Rules for Social Media","section":"Technical Blog","content":"I\u0026rsquo;m not on many social media platforms these days. I like it like that. I mostly follow some academics and people who post interesting stuff. I post only occasionally, usually to show off my recent hiking exploits. I\u0026rsquo;ve come up with some rules for myself (all subject to change) about what I post.\nA post must meet all the following criteria:\nIt must be positive and uplifting.\nThere\u0026rsquo;s enough that\u0026rsquo;s negative on the internet. Don\u0026rsquo;t add to it.\nIt must be interesting\nI\u0026rsquo;m a bad judge of this sometimes; I don\u0026rsquo;t want to be that schmuck who\u0026rsquo;s posting drivel for the sake of posting. Sorry if that happens.\nNo politics.\nI\u0026rsquo;ll make a few exceptions here and there, but as a general rule I don\u0026rsquo;t like posting about politics. I do follow some people that I find interesting for political reasons; that expressly does not mean that I agree with all or any of their views. I will post mostly about technology, academics, jokes, and hiking.\nWhy no politics? I try to keep my views nuanced. It is fantastically difficult to convey any degree of nuance in a tweet or two. If I do have something I feel strongly about, I\u0026rsquo;ll post about it in my personal section of my blog so I can write something in long-form, but that\u0026rsquo;s it.\nI won\u0026rsquo;t post often, but when I do, I\u0026rsquo;ll try to make sure it meets a high bar of quality. I\u0026rsquo;m not out to get more followers or anything—I have just had some really good interactions online, and I want to filter for that. Fighting trolls can be fun, but is ultimately unproductive and uninteresting.\n"},{"id":55,"href":"/posts/2022-07-04_kanren/","title":"microKanren Reading","section":"Technical Blog","content":"μKanren (\u0026ldquo;micro-Kanren\u0026rdquo;) is a tiny, embeddable logic programming language. It\u0026rsquo;s easy to understand and implement in almost any language. It\u0026rsquo;s a great case study of an embedded language: unlike other common \u0026ldquo;embedded\u0026rdquo; languages like SQL or regex, which normally are represented as just plain-old strings, μKanren takes more advantage of the host language\u0026rsquo;s features.\nI recommend reading the original paper: it\u0026rsquo;s short, well-written, and easy to understand.\nI did a write-up which you can read on Codeberg. The README is my set of notes that I made while walking through the implementation of the paper, and the repository contains an implementation in Racket. I\u0026rsquo;ve included some fun use cases like a type checker/inference engine that takes up only 37 lines of code!\nIt\u0026rsquo;s a fun little language, and I might be able to use it at work soon actually. It\u0026rsquo;s definitely specialized for solving a particular class of problem, but you might be surprised how many things fall into that category. Have you used μKanren? Drop me a line—I\u0026rsquo;d love to hear about it!\n"},{"id":56,"href":"/posts/2022-07-02_update/","title":"Blog update","section":"Technical Blog","content":"Brief update on the blog: I had been running a custom fork of the Anatole theme; it diverged pretty heavily, and I found a nice way to customize the CSS. Behold! The new-and-improved blog.\nSome of the new extensions to Anatole include the ability to set a static page as your profile; I\u0026rsquo;ll do this and include links to lists of publications and whatnot. This should make my blog a better place for my professional/academic life.\nI have lost my comments and metrics plugins; I\u0026rsquo;m debating about whether or not I will want to re-include them. I wasn\u0026rsquo;t getting too much benefit from them (though it was exciting to see when a post I wrote made it to the front page of HN!) and they\u0026rsquo;re a little bit of a hassle to maintain.\nIn other news, I\u0026rsquo;m trying out SourceHut to host some of my projects; stay tuned for a post about μKanren, a tiny logic language that can be embedded into pretty much any language you want. You can read the material that will form the source of my post here on SourceHut if you are impatient.\n"},{"id":57,"href":"/posts/2022-03-02_sound_complete_and_duals/","title":"Complete and Liveness, Safe and Sound","section":"Technical Blog","content":"I have a hard time keeping these terms straight:\nliveness vs. safety soundness vs. completeness This is intended as a short guide for myself; maybe someone else will find it useful too! Note that this is all to the best of my knowledge and understanding at the present time; if there be faults, they be the faults of myself. I welcome correction and clarification if I am wrong.\nLiveness vs. Safety # Liveness and safety deal with properties of a system. Contrast that with soundness and completion, which are adjectives about analyses.\nLiveness # A liveness property of a system is of the form \u0026ldquo;something good will eventually happen.\u0026rdquo; One example is eventual consistency in a concurrent system: we want to know that, after some finite number of steps, our system comes to a consistent state of the world.\nAnother example might be with a bank: I want it to be the case that when I move money between accounts, the correct amount of money makes it to the destination account. That is something we want to eventually happen, and that\u0026rsquo;s what makes it a liveness property.\nSafety # Safety is the dual of liveness: in contrast to liveness, a safety property states that \u0026ldquo;something bad does not occur\u0026rdquo;. One example of a safety property is in an operating system, nothing prevents the kernel from preempting a task. We never want to get stuck in a state where the kernel cannot regain control of the processor. If our operating system is safe in this regard, we know that we\u0026rsquo;ll never have the case where a program supersedes the kernel.\nExtending the bank analogy, a safety property might be that we never want money lost in a transaction. The program might occasionally fail to deliver money, but no value is accidentally destroyed during a transfer.\nSoundness vs. Completeness # Soundness and completeness refer to whole systems that make some kind of decision, e.g. a type system or some kind of a static analysis.\nSoundness # From Wikipedia:\n[A]n argument is sound if it is both valid in form and its premises are true. Soundness also has a related meaning in mathematical logic, wherein logical systems are sound if and only if every formula that can be proved in the system is logically valid with respect to the semantics of the system.\nSoundness means the system is trustworthy. A sound type system, for example, will never tell you that a program is devoid of type errors when there are in fact type errors. Most type systems typically are sound. This means, however, that there are programs which may not contain a type error but that the type checker cannot prove to be devoid of errors.\nAnother term that may be used for soundness is correct. (Though, I believe, this may be highly context-dependent.)\nCompleteness # The dual of soundness: if a system is complete, it means the system can give an answer for every input. It might make some mistakes in reasoning. E.g. with a complete type system, there is no program which it cannot assign a type to (even if it\u0026rsquo;s a divergent type) but an assertion that a program is type-safe is not necessarily true.\nWhy can\u0026rsquo;t we have both soundness and completeness at the same time? Gödel is to blame for that.\n"},{"id":58,"href":"/posts/personal/2021-12-25_christmas/","title":"Christmas 2021","section":"Personal Blog","content":"It\u0026rsquo;s my first Christmas being a dad. The end of the school semester was unusually stressful; I didn\u0026rsquo;t have much time or energy to anticipate Christmas. But I\u0026rsquo;ve felt a marked lack of eagerness for getting presents. That feeling wanes each year—something I\u0026rsquo;m grateful for—but this year I only felt an eagerness for a time of peace and celebration with my family. Peaceful it has been.\nMy family isn\u0026rsquo;t perfect. (My baby daughter is about as perfect as they come, though!) The time I\u0026rsquo;ve gotten to spend so far and the time that I will spend with them is precious to me. My wife and I have focused so much on celebrating the birth of Jesus Christ that this commercialized junk we put up with has been all but absent from our home. We have a few books about Santa Claus that we read to our daughter, but we\u0026rsquo;ve listened to strictly Christ-centered music. (A Charlie Brown Christmas counts, though!) There\u0026rsquo;s been a spirit in our home that has brought me comfort and peace in this tumultuous year—more than any before it.\nMerry Christmas—may the peace of God be with you.\n"},{"id":59,"href":"/posts/2021-12-18_classroom_management_reviews/","title":"Class Management Reviews: Fall 2021","section":"Technical Blog","content":"A collection of what worked well and what didn\u0026rsquo;t in classes that I took this semester. This is partially for me to record what things reduced friction for me as a student so that one day, should I become a professor, I\u0026rsquo;ll be able to run the lowest-friction class ever!\nSynopsis # The best classes made it easy for me to see a list of everything that was due, when it was due, and what each assignment entailed. Exhaustively-written lab write-ups hosted on GitHub were a highlight. The worst was when I found numerous typos in an assignment.\nDescription of what I like generally # I like loading all of my assignments into org-mode. If you\u0026rsquo;re not familiar with it, you can think of it as a programmable version of Markdown (though they\u0026rsquo;re not really related) that includes utilities for managing tasks, calendar items, notes, general markup (I write many of my school papers with org-mode) and even spread sheets!1 My school file looks something like this:\n#+TITLE: School #+FILETAGS: :school: #+TAGS: { general(g) cs_460 math_485 music_202 pws_100 research(r) } \\n { reading(b) homework(h) test(t) } * General * CS 460 :cs_460: ** DONE HW 1 - Set up DEADLINE: \u0026lt;2021-09-03 Fri 23:59\u0026gt; CLOSED: [2021-09-03 Fri 23:32] ** TODO HW 2 - Networks and Delay DEADLINE: \u0026lt;2021-09-10 Fri 23:59\u0026gt; (Description here) ... * MATH 485... * MUSIC 202... * PWS 100 You can see top-level headings for each of my classes with assignments as sub-headings marked with TODO or DONE.2 Org-mode will munge all the assignments and display them for me in a nice calendar view.\nOn mobile I use beorg which is hands-down the best org-mode agenda view for iOS. (Note: agenda view. This app is best for managing your todo lists. If you want to edit org-mode files when you\u0026rsquo;re using org-mode for markup, there are some other ones that work a little better for that purpose.)\nAt the beginning of each semester I usually load all the assignments I can see into my org-mode file. This always involves a good amount of Perl and Emacs macros. Once everything is set up, I almost never miss an assignment.\nThe Good # One class had most of the assignments loaded into a spreadsheet that we could download. Easily the shortest time I had to spend to get things into the format that I like. It wasn\u0026rsquo;t complete, however, so I had to update it once or twice.\nMy CS class had the class labs in a repository on GitHub. If the professor pushed out a change to the lab spec, we just had to pull the repo. If there was a typo, we could submit a PR. (There was one that I found, and my professor merged my pr!)\nSubmissions required using tar. (CS class, obviously, and the professor gave us instructions. I can, however, remember the flags.) Yum. Gimme that UNIX goodness.\nLate days: for one class we had a pool of 10 late days that we could apply to almost any assignment. (Exceptions were exams, which makes sense and we were provided ample clarification on that.) This was nice because it let me budget my time. I could choose to push off a lab to get a more pressing assignment for another class in.\nThe Bad # Typos in assignments. Goodness gracious, proofread your assignments! I got a .doc3 file that was riddled with typos. It was all simple stuff like \u0026ldquo;tranport\u0026rdquo; or \u0026ldquo;trasported\u0026rdquo; that a spell checker would have flagged immediately. The Ugly # Proctorio. My botany class used Proctorio and I am not cool with that. I talked to the professor about my concerns—he listened, but wasn\u0026rsquo;t willing to turn off Proctorio. My RSI has been better, but I still don\u0026rsquo;t like having to use a web-interface to enter text. I\u0026rsquo;d much rather type up my answers in Emacs and paste them in. I\u0026rsquo;m grateful that I had a Raspberry Pi that I could use to isolate the ickiness. Conclusion # It was a pretty good semester, all in all. It was my first semester as a father; my wife was also finishing up, so that made things difficult. We got a lot of help from our parents—especially my mother-in-law—and I owe them all a debt of gratitude for helping us make it through the semester.\nI also applied to grad schools! I might write more on that later. I\u0026rsquo;m glad to have that out of the way. Now the waiting begins…\nAppologies to org-mode. This is a pretty sorry description. Just know that org-mode is very, very powerful.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI also have states for IN_PROGRESS, BLOCKED, and WONT_FIX.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI would administer a strike for using a .doc or .docx, but this was not a CS or math class. The .doc instead of .docx is suspect though.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":60,"href":"/posts/2021-12-07_metropolis_essay/","title":"Foundations of High-Modernist Ideology in Metropolis","section":"Technical Blog","content":"The following is from a essay from a class on German literature and film.\nFritz Lang’s movie Metropolis is primarily about the struggle between the oppressed working class and the ruling elite. What drives this tension, however, is a particular view of technology and technological progress that exacerbates the problems the film focuses on. This mentality is called high modernist ideology by Scott in his book Seeing Like a State:\nWhat is high modernism, then? It is best conceived as a strong (one might even say muscle-bound) version of the beliefs in scientific and technical progress that were associated with industrialization in Western Europe and in North America from roughly 1830 until World War I. At its center was a supreme self-confidence about continued linear progress, the development of scientific and technical knowledge, the expansion of production, the rational design of social order, the growing satisfaction of human needs, and, not least, an increasing control over nature (including human nature) commensurate with scientific understanding of natural laws.\n(Scott, 89)\nNote that this is different from the literary definition of high modernism. For the purposes of this paper, high modernist ideology is understood as a belief that rational, scientific systems will solve all of mankind’s ailments. Metropolis is situated right at the tail end of the reign of high modernist ideology, and illustrates some of the failings of that mentality.\nIn this paper we will examine how Metropolis illustrates the dangers of high modernist thinking in how it portrays man’s subservient relationship to machinery and the fragility of the city of Metropolis resulting from top-down, rational planning. Ironically, even though these themes of centralized failure have been common place in film for more than a century now,1 the dream of a perfectly organized Utopia persists in our culture today. Metropolis therefore remains an important case study of the dangers and failings of high modernism.\nMan Serves the Machine # The opening of Metropolis shows a stark example of men working as slaves to the machine. Freder goes down to the lower levels to see how the workers live. He passes workers mechanically going from pose to pose to keep the machines running. Their jerky, repetitive motions cast the human workers merely as organic components of each machine that they tend.\nWhen Freder arrives at the M-Machine, he witnesses an explosion that kills or seriously maims several workers, all because one worker was unable to reach a particular valve in time. The machine was obviously not designed to be ergonomic and was lacking critical safety features that would have prevented such a devastating accident. The machine’s complexity and human-hostile design make accidents like this essentially inevitable. The massive requirements that the machines impose on the humans shows the high modernist idea that humans should submit themselves to rational ideas, and that human nature can be overcome by rational, technical means.\nYet this submission to rational, mechanical systems is in itself an irrational one. Freder’s vision of Moloch gobbling up workers who dutifully march into the gaping jaws of the machine speaks to the almost fanatic devotion certain planners of large systems had to rationality. The vision closes and Freder sees some workers wordlessly2 collecting the bodies of the injured and dead, whilst others take up their posts to keep the machine working. There’s some redundancy in how the human workers are allocated to account for mechanical failures or accidents, but there’s no redundancy in the machines to account for human failures.\nWe get other hints throughout the film of the submission of men to the machine. Metropolis looks to be absolutely unlivable. In the upper levels, we do see crowds gathered for entertainment and sport, but the city streets are either entirely devoted to automobiles, or are so foreboding and unwelcoming that no pedestrian-centric economy could ever flourish there. The streets are sterile and perfectly regular; the buildings are all blocks and perfectly featureless. This prefigures some of the architecture and city planning that was present during the DDR: massive apartment complexes built out of prefabricated concrete slabs were often placed far away from the city center, so as to make the Plattenbau districts feel stifling. The straight lines might look good on paper, but maps and city plans are of necessity a simplification over what real life looks like. Life flourishes in the hand-crafted and in the unique. Top-down imposed grids crush what makes life interesting and livable in the city.\nThe Fragility of Monoculture and Centralized Planning # After the accident at the M-Machine, Freder rushes to tell his father, the architect and ruler of Metropolis, about what he saw. In his office at the top of the New Tower of Babel, Jon Frederson controls the city from a central vantage point: aides digest and bring him information, while others record his decisions and carry out his orders. He is the very model of a high modernist: his rationality has brought order and prosperity to the citizens of the upper levels, and everyone above is free to spend their time as they please. It seems that the city is working perfectly well. However, Metropolis turns out to be very fragile.\nFrederson’s control begins unraveling when his aids fail to bring him the information that he wants, and continues when Rotwang plots against him. Eventually the city collapses when the striking workers’ protest goes further than he had foreseen. The destruction of the Heart Machine causes the lower levels of the city to flood and the upper levels to loose power. Cars halt in the streets, and elevators plummet down their shafts. The apparently well-ordered city with bumper-to-bumper cars moving smoothly down the streets suffers cardiac arrest: broken elevators and stopped cars hinder the protagonists as they try to reach safety.\nThis fragility has a good analogue from the mistakes of high modernist ideology. Scientific forestry came about in the 1700s in Germany as a way to improve lumber yield. A plot of forest would be cleared of all “junk” trees and underbrush, and new trees of a single species were planted in straight lines. The ground was cleared to make way for the saplings, and each year there was a neat rotation between different parcels of land from which mature wood could easily and quickly be harvested. Initially, this was a great success: the wood was strong, straight, and plentiful. There was no junk wood that interfered, and lumber outputs could be reliably predicted.\nIt was not, however, without its drawbacks. In a book published in 1986, Richard Plochmann describes how yields dropped after the first few batches (Lang and Pye). The reasons for the drop are complex, but the cause was simple: the “clean” forest that produced such predictable quantities of lumber was a monoculture: there was no variety to protect against a pest that targeted a single species of tree. The soil fauna that are critical to a flourishing forest died off, and the trees withered when they didn’t get the nutrients that they needed.\nOne of the hallmarks of high modernist ideology is that problems can be solved by large, complex systems, be they mechanical, political, or bureaucratic. Such aspirations usually fail to take account of the difficulties in getting complex systems to run for long periods of time without encountering significant failures. Metropolis vividly illustrates the fall of Jon Frederson’s pride as the fragility in the massive system he created causes everything to fail around him.\nMediation # Amidst the warnings of the dangers of high modernist ideology, the message of Metropolis is tentatively hopeful: “the mediator between the hands and the head must be the heart!” By the end of the movie, we see the robot masquerading as a human unmasked and destroyed, and the beginnings of greater understanding between the architect of the city, and those that are actually required to live in the city and maintain it. This ultimately is also the cure for high modernist ideology: the designers of complex systems must take into account the needs and the experiences of those who would suffer the brunt of its effects. Metropolis casts this lesson in the discourse of class struggle, but it can also apply to those who design cities, automobiles, software, and other systems.\nWorks Cited # Scott, James C. Seeing like a State: How Certain Schemes to Improve the Human Condition Have Failed. Nachdr., Yale Univ. Press, 2008.\nLang, Chris, and Oliver Pye. “Blinded by Science: The Invention of Scientific Forestry and Its Influence in the Mekong Region.” Chrislang.Org, 1 Nov. 2000, https://chrislang.org/2000/11/01/blinded-by-science-the-invention-of-scientific-forestry-and-its-influence-in-the-mekong-region/.\nFootnotes # 1 Other films with central-point-of-failure plots include Star Wars, (the thermal exhaust port on the Death Star) The Lord of the Rings, (cast it into the fire!) Batman Begins, (the train with the microwave generator) etc.\n2 The failure of Texas’s power grid is an extremely interesting case study about the dangers of fragile systems.\n"},{"id":61,"href":"/posts/2021-11-23_email_paradise/","title":"In Email Heaven with Emacs, mu4e, and mbsync","section":"Technical Blog","content":" All mail clients suck. This one just sucks less.\n— Mutt\nI was a long-time mutt user. Come to think of it, I think the reason why I learned Emacs was because that was what $EDITOR was set to, and I needed to know how to get around so I could send email via mutt.\nAs more of my life has gotten sucked into Emacs, I\u0026rsquo;ve wanted to move my email into Emacs as well. I\u0026rsquo;ve been using a combination of mu4e and isync/mbsync to manage my email. I\u0026rsquo;m using Pobox for email hosting, and my inbox has never been so consistently near empty before.\nEmail Setup # I keep the following in a file that I require lazily in my Emacs config:\n(setq mu4e-mu-binary \u0026#34;/usr/local/bin/mu\u0026#34;) ;; Folders (setq mu4e-sent-folder \u0026#34;/Sent\u0026#34;) (setq mu4e-drafts-folder \u0026#34;/Drafts\u0026#34;) (setq mu4e-trash-folder \u0026#34;/Trash\u0026#34;) (setq mu4e-refile-folder \u0026#34;/Archive\u0026#34;) (setq mu4e-attachment-dir \u0026#34;~/Downloads\u0026#34;) ;; Signature stuffs ;; (setq user-full-name \u0026#34;\u0026#34;) ;; (setq user-mail-address \u0026#34;\u0026#34;) ;; (setq mu4e-compose-signature \u0026#34;\u0026#34;) ;; (setq smtpmail-smtp-server \u0026#34;\u0026#34;) ;; (setq smtpmail-smtp-user \u0026#34;\u0026#34;) (setq smtpmail-stream-type \u0026#39;starttls) (setq smtpmail-smtp-service 587) ;; When mu upgrades, run `byte-recompile-directory\u0026#39; on this folder ;; (byte-recompile-directory \u0026#34;/usr/local/Cellar/mu/1.6.8/share/emacs/site-lisp/mu/mu4e\u0026#34;) (add-to-list \u0026#39;load-path \u0026#34;/usr/local/Cellar/mu/1.6.8/share/emacs/site-lisp/mu/mu4e\u0026#34;) (require \u0026#39;mu4e) (setq mu4e-completing-read-function \u0026#39;completing-read) (setq mu4e-view-auto-mark-as-read t) (setq mu4e-view-show-addresses t) (setq mu4e-view-show-images t) ;; Org-mode integration (setq org-mu4e-link-query-in-headers-mode nil) ;; give me ISO(ish) format date-time stamps in the header list (setq mu4e-headers-date-format \u0026#34;%Y-%m-%d %H:%M\u0026#34;) ;; allow for updating mail using \u0026#39;U\u0026#39; in the main view: (setq mu4e-get-mail-command \u0026#34;mbsync -a\u0026#34;) ;; Fixes problem with duplicate UID errors (see ;; http://pragmaticemacs.com/emacs/fixing-duplicate-uid-errors-when-using-mbsync-and-mu4e/) (setq mu4e-change-filenames-when-moving t) ;; customize the reply-quote-string ;; M-x find-function RET message-citation-line-format for docs (setq message-citation-line-format \u0026#34;%N on %Y-%m-%d %H:%M %Z:\\n\u0026#34;) (setq message-citation-line-function \u0026#39;message-insert-formatted-citation-line) ;; Turn on word-wrap automatically when viewing emails (add-hook \u0026#39;mu4e-view-mode-hook \u0026#39;turn-on-visual-line-mode) (add-hook \u0026#39;mu4e-compose-mode-hook \u0026#39;turn-on-visual-line-mode) ;; Don\u0026#39;t hard-wrap my emails as I write! (add-hook \u0026#39;mu4e-compose-mode-hook (lambda () (auto-fill-mode -1))) ;; But make sure they flow on the receving end (setq mu4e-compose-format-flowed t) ;; How to send messages (setq message-send-mail-function \u0026#39;smtpmail-send-it) (define-key global-map (kbd \u0026#34;s-m\u0026#34;) \u0026#39;mu4e) And here\u0026rsquo;s how I get the lazy loading:\n(defvar lazy-email-loadedp nil) (defun lazy-boot-email () (interactive) (when (not lazy-email-loadedp) (message \u0026#34;Loading email config...\u0026#34;) (load-file \u0026#34;~/.dotfiles/email-setup.el\u0026#34;) (setq lazy-email-loadedp t) (message \u0026#34;Loading email config...done\u0026#34;) (mu4e))) (define-key global-map (kbd \u0026#34;s-m\u0026#34;) \u0026#39;lazy-boot-email) That defines s-m to the function that loads the email config file. When that file gets loaded, it overwrites the keybinding for s-m so that it doesn\u0026rsquo;t try to reload the file.\n"},{"id":62,"href":"/posts/2021-11-09_programs_and_intent/","title":"Programs and Intent","section":"Technical Blog","content":"What does this program do? At the most reduced level, one could say that a program\u0026rsquo;s behavior is defined by the effect it has on the hardware running it. That\u0026rsquo;s not very useful however; when we\u0026rsquo;re programming, we often have to deal with legacy code and tease out the original intent of the code.\nSaying that the meaning of a program is entirely encapsulated by the code is saying that the intent and the implementation are the same. They so rarely are!\nToday I found some Elixir code that looked like the following:\n@spec all_have_key?(lst :: [%{}], needed_key :: String.t()) :: boolean() def all_have_key?(lst, needed_key) do lst |\u0026gt; Enum.map(fn m -\u0026gt; m |\u0026gt; Map.keys() |\u0026gt; Enum.any?(fn k -\u0026gt; k == needed_key end) end) |\u0026gt; Enum.all?() end (Note, I just threw that together—possible syntax errors in there.)\nWhat is this code trying to do? It\u0026rsquo;s trying to check that each map in a list has a given key and return true or false on that condition. I don\u0026rsquo;t think the code even had a @spec to help explain that: all I had was the function name (which was not as clear as all_have_key) and the source.\nAfter a few moments of reflection, I rewrote it to this:\n@spec all_have_key?(lst :: [%{}], needed_key :: String.t()) :: boolean() def all_have_key?(lst, needed_key) do lst |\u0026gt; Enum.map(\u0026amp;Map.has_key?(\u0026amp;1, needed_key)) |\u0026gt; Enum.all?() end That big long complicated bit has a built-in function. The built-in function is more efficient because it doesn\u0026rsquo;t traverse the entire list of keys searching for a match: with a map, you get O(1) lookup time.\nSo what does a program mean? I\u0026rsquo;m pretty confident that I preserved the intended meaning of this program. But what\u0026rsquo;s a better way to express that intent?\nTests are useful, but they don\u0026rsquo;t capture everything. While I think this function was tested, no test can ever ensure 100% preservation of intent. Tests can only find witnesses of meaning mismatches.\nType systems are helpful too. But types come in varying degrees of precision: some languages give you an Int, while others give you Int or Nat or ∈ {1, 2, 3}. More powerful type systems let you express more of your intent in a way that can be mechanically checked, but they tend to also be more burdensome.\nThis is an open question that I know there\u0026rsquo;s a lot of ongoing research around. I\u0026rsquo;m excited to see what I find!\n"},{"id":63,"href":"/posts/2021-09-25_models_of_programming_draft2/","title":"Models of Programming","section":"Technical Blog","content":"Last week I was studying outside of a lecture hall where someone was teaching an introductory course on computer programming. There was a lot that I overheard that I disagreed with; this essay is an attempt to help me crystallize what exactly I disagreed with.\nWhat is programming? What is good programming? What should programming be like? How you answer depends a lot on what you value. What I value in programming has not always been the same, and I think I\u0026rsquo;m the better for having toured around the space a little bit. I recognize that there\u0026rsquo;s still a lot to explore; nonetheless, I present my admittedly limited perspective on some broad ways that people think about programming—especially in academia and pedagogy—and some of the strengths and weaknesses of each.\nOne way of thinking about programming is that you are ordering a computer to do your bidding: you, the programmer, sit at the helm of your CPU, afloat on a sea of data, and you have various levers and knobs that you can pull and twist to make the CPU get from point A to point B: load this value into memory slot i. Now add five to it. Now print that back out. Etc. This is called imperative programming, because you tell the computer every step it should take.\nI\u0026rsquo;m doubtful that there\u0026rsquo;s much deep insight into programming this way.1 It\u0026rsquo;s like writing a recipe for a horrendously unimaginative cook. If you\u0026rsquo;re teaching students how to program like this, they might get an appreciation for being detail-oriented and sweating the minutiae—that\u0026rsquo;s well and good—but I think that\u0026rsquo;s about where it stops.\nAnother way of thinking about programming is that you, the programmer, teach the computer to solve progressively more complicated problems by composing bits of behavior together. Programs start behaving more like the Fourier series: the aggregation of simple, easy-to-understand components yields a robust and flexible result.\nWhere it really starts getting interesting is when you bring more powerful programming languages into the mix: languages that let you do more than just give the computer a dumb set of instructions to dutifully and meticulously slog through. Languages like Scheme (and related languages like Racket, Clojure, and—I\u0026rsquo;d argue—Elixir) give you the tools to build up models of the problem you\u0026rsquo;re trying to solve. You begin to think about the fundamental nature of the problems at hand and how to proceed from there. Whereas in the first case, you\u0026rsquo;re more focused on how to get the computer to do something. Reversing your tack can lead you down a wrong path for a long time without you knowing it.\nBesides, high-level, functional programming languages make great pedagogical tools for more reasons than just the power they give you in modeling your program. Many of these languages put emphasis on building programs up from small, composable units with no side-effects that are easy to reason about, test, and put together. Not only do you learn how to sweat the details, you also learn how to orchestrate many simple pieces into complex solutions that fit the problem at hand. It\u0026rsquo;s the difference of being taught the rudiments of cooking and learning how to compose dishes that fit together into a complete meal meant to delight and nourish.\nThere\u0026rsquo;s some effort to achieve these ends when courses opt to focus on object-oriented principles. Sure, you learn about decomposing your problems along domain lines, but there\u0026rsquo;s often much more focus on mutation which can trip beginners up. Local-reasoning dissolves, and your layers of abstraction leak.\nFurthermore, OO is emphatically not a good fit for so many problems! Nevertheless, a great deal of effort has been expended by thousands of researchers to find \u0026ldquo;best-practice patterns\u0026rdquo; for each and every scenario. We\u0026rsquo;ve drifted back a little towards the rote recipe-following instruction. Abstract mathematics provides a much richer modeling domain—indeed, computability theory was born from the Lambda Calculus, and it has proved to be a very fruitful field for general modeling.\nAbstract mathematics isn\u0026rsquo;t a prerequisite to learning how to program (though it does turn out to be very useful the further one goes) but that doesn\u0026rsquo;t prevent us from teaching a more mathematically-oriented way of thinking about problem decomposition. There are many excellent books that do this, from the celebrated Structure and Interpretation of Computer Programs by Abelson and Sussman to How to Design Programs by Felleisen et. al.\nMy hope is that programming courses in higher-education settings (and high school settings!) will move away from imperative and even object-oriented programming towards a more functional approach.\nLow-level knowledge # I\u0026rsquo;d like to qualify an earlier claim: imperative programming has little benefit from a pedagogical standpoint.2 Now, that\u0026rsquo;s not entirely true, because there comes a point where you need to know the low-level details of how a computer works, and assembly is an imperative language. C is a great language for learning systems programming, because it exposes you to all the nuts and bolts of memory, interrupts, system calls, etc. There are a lot of footguns in this area, and that\u0026rsquo;s because physics is a beast. I still don\u0026rsquo;t think it\u0026rsquo;s a good idea to start with this stuff, much like a budding chef doesn\u0026rsquo;t need to know the details of the chemical reactions taking place in the oven, but there comes a point where knowing the underlying chemistry becomes indispensable.\nNow, there\u0026rsquo;s a very wrong way to teach programming, and that way is by using something as ungainly as C++.\nC++ is a pedagogically worthless language. It bogs a budding student down with historical baggage like header files and cryptic imports whilst drowning said student in the complexities of an abuse and archaic syntax, with nothing but an error message that\u0026rsquo;s as clear and useful as a lead-filled balloon used as a flotation device. It\u0026rsquo;s impossible to get a pleasing, mathematically-sound model of your domain in C++. Heck, you can\u0026rsquo;t even model something in an OO way whilst following the literature on that. Almost all effort is consumed in attempting to appease a persnickety compiler.\nSince getting the syntax and the ceremony right is so much of C++, it turns into a guess-and-check game, where the student keeps tweaking things until it works. This is not the way. You don\u0026rsquo;t learn anything about why things are the way they are. This is similar to one argument I\u0026rsquo;ve heard about how Java suffers from a similar problem. We shouldn\u0026rsquo;t be teaching students how to solve programs in a given language. Rather, we should be giving them tools to think about the problems they face and how to solve them.\n(apply + essay) # The thing that set me off from that lecture was that the instructor was suggesting students use pass-by-reference in function calls without even mentioning the headache that can come from side-effects and breaking referential transparency in functions. It\u0026rsquo;s the kind of thing that a beginner doesn\u0026rsquo;t need to know to program, but misuse can lead to some really nasty bugs. Anyway, programming with mutation is better avoided—best not to encourage techniques that students will have to unlearn when they encounter a pure language.\nTo sum up, I think the best way to start out thinking about programming is by considering how to model problem domains as best as possible, and functional languages give you the most and best tools to do that with. OO is an improvement over imperative programming, but do not use C++!\nThere\u0026rsquo;s something there for sure… I\u0026rsquo;ll come back to this.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSee, I told you I\u0026rsquo;d come back to it!\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":64,"href":"/posts/personal/2021-09-19_symbols/","title":"Reluctance to Bear a Symbol","section":"Personal Blog","content":"I feel uncomfortable with many symbols. I might have opinions about a subject, but there\u0026rsquo;s rarely a camp that has some symbol, flag, slogan, etc. that I\u0026rsquo;m comfortable with adopting because that camp does not accurately reflect my opinion. All too often, a slogan takes on more than its surface meaning, and that can make using that slogan tricky.\nA simple example is with politics. On certain topics I agree with whatever happens to be defined as the \u0026ldquo;conservative\u0026rdquo; viewpoint. On other issues, I favor the \u0026ldquo;liberal\u0026rdquo; opinion. I like some libertarian ideals, but I can\u0026rsquo;t agree with all of the \u0026ldquo;official\u0026rdquo; ones.\nEvery party, movement, or group comes up with some slogans that are either catchy or hard to refute. But these phrases are just symbols for broader ideas. An article from Persuasion summed it up nicely:\nTake, for example, Black Lives Matter. The slogan itself is (or at least should be) obvious and uncontroversially true. But there’s also a more substantive movement and political program behind BLM, which is rightfully more controversial.…\nWhether or not you agree with these goals, Black Lives Matter clearly means more to most activists than “black people’s lives matter.”\nThe danger with using slogans as \u0026ldquo;reasoning\u0026rdquo; is that they\u0026rsquo;re shallow: they\u0026rsquo;re inherently short, snippy, and difficult to attack. Arguing with a set of slogans is like trying to fight an image projected on fog. There\u0026rsquo;s no substance to meaningfully engage with, and then proponents of that movement will call you out for fighting against these \u0026ldquo;uncontrollably true\u0026rdquo; ideas.\nBesides, it\u0026rsquo;s way better to agree with ideas, not parties. Picking a party based on a few things you like about it, and then agreeing with the rest is like saying you like a particular food you\u0026rsquo;ve never eaten before, just because it has one or two ingredients that you like. I like mustard, but I\u0026rsquo;m not going to eat a cake that includes mustard.\nIdeas don\u0026rsquo;t compress well, if at all. Ideas can be simple, but trying to compress simple ideas leads to simplistic understanding. Life is inherently messy, and slogans and memes are simplifications on top of that messiness.\nIn place of a well-reasoned argument, political activists can lean on pithy memes to demonstrate their political allegiances. But when people use memes as a shortcut, they sacrifice the process of testing and inspecting their opinions. Insight comes from challenging ideas, and memes allow people to skirt this process.\n(ibid.)\nI recommend reading that Persuasion article. Don\u0026rsquo;t let slogans and memes be an intellectual shortcut. Embrace the nuance and messiness of this world, and learn to come to terms with it.\n"},{"id":65,"href":"/posts/2021-08-21_racket_mug/","title":"A programmable programming language? I'll drink to that!","section":"Technical Blog","content":"My wife and I got a chance to go to a place that lets you paint pottery and then have it fired. The pottery is all pre-made; you just get to paint it.\nIt\u0026rsquo;s been a very long time since I\u0026rsquo;ve worked with a physical art medium, so the mug looks kinda dumpy. I did alright with the Racket logo on the bottom-inside of the mug though!\nI\u0026rsquo;m working on some fun projects with Racket. It\u0026rsquo;s been a really enjoyable language to work with. If you haven\u0026rsquo;t given it a whirl, I recommend checking it out. The docs on the official Racket site are very good, and there are some absolutely stellar gentle introductions to the language like How to Design Programs that I would recommend.\n"},{"id":66,"href":"/posts/personal/2021-08-14_health/","title":"Health and Taking Care of Yourself","section":"Personal Blog","content":"It\u0026rsquo;s going to be another long night. My baby has reached the point where she\u0026rsquo;s too tired to sleep. She alternates between screaming at 90+ decibels and sleeping fitfully. She only transfers from the crying state to the sleep state after prolonged, labored rocking and soothing. She transfers back to the base crying state on her own after a few seconds.\nI still love her. I just don\u0026rsquo;t appreciate her as much during these times.\nOne thing that I\u0026rsquo;ve learned while watching my baby grow a little bit is just how hard keeping yourself alive is. My body is big enough that it can regulate food and water intake—feeding cycles are on the order of 5 hours instead of 2. Even then I can easily go 24 hours without eating anything if I choose. I can force myself to rest in bed, if not fall asleep. My baby can\u0026rsquo;t do any of that.\nOver the past few years I\u0026rsquo;ve had to be more careful with how I take care of myself. I know the warning signs of excessive sugar consumption, and I\u0026rsquo;ve learned to value avoiding the sugar headaches over whatever pleasure the treat provides. I\u0026rsquo;ve had to take a lot of care of my hands recently: I know the signs of RSI, and there\u0026rsquo;s so much I have to do to avoid another flare-up.\nI\u0026rsquo;ve found that regular running helps my hands stay happy. I guess the increased blood flow with the cardio helps them heal and be more resistant. I have to make sure I stay hydrated. I used to treat my hands very gingerly, but they\u0026rsquo;ve healed to the point where it\u0026rsquo;s better for me to exercise more with my hands. (Push-ups, etc.)\nHealthy food is so important too. That requires a lot of long-term planning and thinking, which is something that\u0026rsquo;s difficult for me. For some reason thinking about and planning around food is not something my brain likes to do. Compilers? Easy. Casserole? Not so much. But it has a tremendous impact on how well I can think, sleep, and act. My wife is a lifesaver in this regard; she loves to think about food and has steadily improved our diet.\nI can\u0026rsquo;t wait for my baby to learn how to sleep through the night. Every further step of independent self-regulation will be an exciting (and welcome!) one. In the mean time, she\u0026rsquo;s provided an interesting instance for me to reflect.\nI look forward to all the times she\u0026rsquo;ll offer similar reflection opportunities.\n"},{"id":67,"href":"/posts/2021-08-03_used_books/","title":"Ode to Used Book Stores","section":"Technical Blog","content":" When I get a little money I buy books; and if any is left I buy food and clothes.\n— Erasmus of Rotterdam\nUsed bookstores are my arch nemesis.\nI have two such stores in disturbingly close proximity to me. The first is Boomerang Books—within a short walk of my house and right next to Burgers Supreme (almost as dangerous)—and they carry textbooks at a fifth of the original price. Last time I went there I walked out with a book on graph theory I most certainly don\u0026rsquo;t need. The second is Pioneer Book. My wife and I went there on a date a couple of months ago. I walked out with a dozen books.\nMy wallet has suffered.\nWhat keeps me hooked is that my wallet has suffered much less than it would if they were not used books, though!\nThe serendipity is what gets me. I was walking up the stairs when I passed a copy of Walden be Emerson that was waiting to be sorted and shelved. I picked it up and added it to the pile.\nI\u0026rsquo;m not sure how much more my bookshelf can take. The books are already stacked two deep. I just need to make time, dig in, and start reading. Maybe I can give back some of those wonderful books after I\u0026rsquo;ve finished them.\n"},{"id":68,"href":"/posts/2021-05-20_cfa/","title":"Control-Flow Analysis","section":"Technical Blog","content":"Control-Flow Analysis is a popular technique for performing static analysis of many different kinds of programming languages. It\u0026rsquo;s most often needed in cases where you have some kind of dynamic dispatch: either where you have first-class functions or when you have objects and you call one of their methods.\nImagine for a moment that you were given a program which you were asked to analyze manually. You might start by going to the top of the program, running through each branch, and keeping track of the values variables could take. If the program is too complex to hold entirely in your head, you might start by writing down some abstractions to simplifiy remembering. For example, instead of remembering that the variable x holds the value of 12, you might just remember that it is a number. Thus, when you saw some assignment to x, such as x := x + 1, you could skip over that and just think that x is still a number.\nIf you came across a loop, you probably wouldn\u0026rsquo;t trace each execution through the loop: just one or two passes would be enough to tell you some interesting facts. For example:\ni := 0 while i \u0026lt; 10 { i++ print \u0026#34;i is {i}\u0026#34; } For a simple loop like this, it\u0026rsquo;s easy to show how the program will always make progress and complete the loop. For more complicated loops, proving progress might be impossible. (It might also be wrong: we do get programs with infinite loops.)\nIn these cases, we can just check to see if we\u0026rsquo;ve returned to a state that\u0026rsquo;s identical to a state that we\u0026rsquo;ve seen before: if x was a number, it should still be a number, etc. If the variables\u0026rsquo; (abstract) values are the same, we can conclude that there might be a loop and move on. It\u0026rsquo;s not guaranteed to be accurate, but it is a strategy that\u0026rsquo;s guaranteed to terminate.1\nThere\u0026rsquo;s more to CFA than what I\u0026rsquo;ve outlined here, but this should give you an idea. Stay tuned for more!\nThis is the classic completeness/consistency trade-off introduced by Kurt Gödel. A consistent evaluation of a program leaves in a state where there are programs that we cannot compute because we can\u0026rsquo;t tell if they halt. (The Halting Problem) A complete analysis, which is what we are interested in here, must sacrifice on consistency, and return inaccurate, though still useful results.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":69,"href":"/posts/personal/2021-06-13_this_shall_pass/","title":"This Too Shall Pass","section":"Personal Blog","content":"It\u0026rsquo;s cliché at this point to say that 2020 was a rough year. I\u0026rsquo;m grateful in that I and my wife were relatively unscathed by the pandemic. I had some personal health issues however that by themselves made 2020 a bit of a struggle. I learned some important lessons.\nIn February I had a big choir concert. That same weekend I had a large project for one of my CS classes due. I got an extension on my CS project so I could sing in the concert; but despite the extension, I was rushed and I spent an unusually long time in front of my computer working on my project after the concert was over.\nDue to the nature of the project, I had to use a mouse for much of it. The strain of pronation1 for such a long time did something in my right forearm. The next day I felt an ache every time I tried to turn my hands downward: even with a 15° tent on my split keyboard, I couldn\u0026rsquo;t lay my hands down to type. I felt a burning along the inside of my forearm whenever I tried. My grip was shot as well: I wasn\u0026rsquo;t able to open any tight jars, and I had to use my left hand for a lot of things that I normally would use my right hand for.\nI, at age 23, had developed a repetitive-strain injury.\nI went to a physical therapist. An ultrasound revealed no issues with my nerves. I was really happy about that because it meant that I didn\u0026rsquo;t need surgery. But I did need some non-surgical intervention: after many weeks of rest from work and several visits to a physical therapist, my hand started feeling a little better.\nAfter a month or so I was able to start going back to work. I started at working a few hours here and there, and over the course of a few months scaled back up to something close to what my hours normally were. I was extra-vigilant in doing my stretches and exercises that I had gotten from the physical therapist. Things were looking up.\nThen it started hurting again.\nIt didn\u0026rsquo;t take much: just a small deviation from my workout and a little added stress on my hands sent me back to the doctor. Some more deep-muscle massages and another break from work helped me to get back on track. But I was feeling shaken and a little depressed.\nThis cycle happened again a few more times. Each time, I wondered if I would ever be back to \u0026ldquo;normal\u0026rdquo; when I didn\u0026rsquo;t have to worry so much about my hands.\nI had been on the mend for a while and was feeling pretty happy about where I was. I invested in a new split keyboard that had more buttons for my thumbs which took the strain off of my pinky fingers. I switched to Vim-bindings in Emacs2 and made a concerted effort to avoid the mouse.\nThen I started running.\nI found a trail close by to where I live: it\u0026rsquo;s shady and pretty level. Running had always been my least favorite form of exercise, but I discovered that I actually enjoyed it.\nAfter just a few days, I noticed that my hands were feeling better than they ever had before. I think the cardio helped my hands get some more blood that they had been missing. My hands still feel great. Some days I don\u0026rsquo;t think about the fact that they were injured, which is a miracle.\nThen, after my first 5k, I got a bad case of runner\u0026rsquo;s knee.\nI\u0026rsquo;m still feeling it. It\u0026rsquo;s been a few days, and even walking has been has been a little painful. I think I pushed it too hard too quickly. I\u0026rsquo;m not great at this physical training thing.\nI\u0026rsquo;ve lost (temporarily) the form of exercise that I was just starting to enjoy. But something that I\u0026rsquo;ve learned from cycles of health and injury is that bad times come… and they also go. In the case of my hands, it took well over a year for me to feel like I was in a more normal place. I still feel like I\u0026rsquo;m on the mend—I still have a hard time using the keyboard on my laptop—but I\u0026rsquo;m optimistic that this time the worst is behind me, at least for the next few years.\nI\u0026rsquo;m still young, and I\u0026rsquo;m only just getting used to the idea that injuries don\u0026rsquo;t heal as well as they do when you\u0026rsquo;re a kid. It\u0026rsquo;s been a bit of a struggle to come to grips with that idea, but I\u0026rsquo;m getting there.\nIt\u0026rsquo;s always the best of times, as well as the worst of times. I\u0026rsquo;ve watched my wife, parents, and friends go through similar seasons of difficulty—sometimes spanning years of distress—only to emerge triumphant in some cases, or adapt when the difficulties never pass fully.\nI believe there is hope. I\u0026rsquo;m thankful for my family and my faith which helped carry me though these hard times. I know more will come, but I know I will make it through.\nThe motion of turning the palm downwards. Opposite of supination, which is to turn the palm upwards.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nYes, Vim-bindings! That\u0026rsquo;s a post for another day. I started using evil-mode and I can now say that the best text-editor is Emacs with Vim-bindings enabled.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":70,"href":"/posts/2021-04-writing-a-paper/","title":"The Technicalities of Writing a Paper for OOPSLA with Emacs and Zotero","section":"Technical Blog","content":"In the spring of 2021, I submitted a paper to the 2021 OOPSLA conference. These are my notes on how to use Emacs and Zotero to put together a technical paper, complete with bibliography, for the OOPSLA conference. Mostly this functions as notes for myself.\nThe OOPSLA conference uses the acmart LaTeX class. Put this at the top of your org file:\n#+TITLE: Concrete Cross-Product #+AUTHOR: Wiersdorf, Ashton #+DATE: \\today #+LATEX_CLASS: acmart #+LATEX_CLASS_OPTIONS: [sigplan,screen,review] Originally I thought that I had to download some huge LaTeX templates, but it turns out the TexLive distro that I have on my Mac ships with the acmart class. You do have to install the Libertine font. With brew this should be pretty easy:\nbrew install --cask font-linux-libertine If you\u0026rsquo;re on a different system, you can install from source. I\u0026rsquo;m not sure if this too comes bundled with any LaTeX distros. (Please correct me in the comments if I\u0026rsquo;m wrong!)\nEmacs is aware of different document types, and will throw a fit if you try to export with the #+LATEX_CLASS set to acmart. You\u0026rsquo;ll need to add this to your .emacs to sooth it:\n(add-to-list \u0026#39;org-latex-classes \u0026#39;(\u0026#34;acmart\u0026#34; \u0026#34;\\\\documentclass{acmart}\u0026#34; (\u0026#34;\\\\section{%s}\u0026#34; . \u0026#34;\\\\section*{%s}\u0026#34;) (\u0026#34;\\\\subsection{%s}\u0026#34; . \u0026#34;\\\\subsection*{%s}\u0026#34;) (\u0026#34;\\\\subsubsection{%s}\u0026#34; . \u0026#34;\\\\subsubsection*{%s}\u0026#34;))) Citations # TODO\n"},{"id":71,"href":"/posts/personal/2021-03-21_easter_2021/","title":"Easter 2021","section":"Personal Blog","content":"I love Easter. In my mind it is just as important as Christmas. Indeed, if Christ had not died for our sins and been resurrected, then there would be no reason to celebrate His birth.\nI recorded a short, simple vocal arrangement of \u0026ldquo;O Savior, Thou Who Wearest a Crown\u0026rdquo; by J. S. Bach with my wife.\nRecording of \"O Savior, Thou Who Wearest a Crown\" Your browser does not support the audio element. Download it here. I\u0026rsquo;m no audio engineer, but I tried to make it fun to listen to with headphones. :) Enjoy!\n"},{"id":72,"href":"/posts/2021-01-30_proctorio/","title":"Using a Raspberry Pi for Proctorio","section":"Technical Blog","content":"For one of my classes I am required to take a short weekly exam via Proctorio. There\u0026rsquo;s been some controversy surrounding this software. Although it claims it\u0026rsquo;s trustworthy, it\u0026rsquo;s not open-source, so no one can verify their claims. So naturally, I was reluctant to install it on my primary machine. Enter: the spare raspberry pi I have sitting around.\nAll it took was a USB webcam hooked up to a raspberry pi. For this project I wanted to maximize comparability, so I chose stock Ubuntu. I installed Chromium and the Proctorio plugin, and I was all set.\nProctorio slowed my machine to a crawl, but it didn\u0026rsquo;t effect taking my test that much. The I only time this was annoying was when I realized halfway through that I needed to switch my keyboard layout.\nI wish I didn\u0026rsquo;t have to use Proctorio. I don\u0026rsquo;t trust them. They say my information is encrypted, but they also do some kind of eye tracking to flag suspicious behavior. (Among other metrics.) Is this computation being run on my machine? This seems more like a job that would get farmed off to a server somewhere. in that case, it could not be encrypted.\nThat is just some speculation. Perhaps they really are a reputable company that I can trust with my data. But until I can verify that myself, I\u0026rsquo;ll keep it on a burner computer that I can fully wipe once I\u0026rsquo;m done.\n"},{"id":73,"href":"/posts/2021-01-06_passive_collection/","title":"Passive Data Collection Should Be Illegal","section":"Technical Blog","content":" Facebook knows how long you spend hovering over that auto-play video that showed up in your feed that you didn\u0026rsquo;t ask for. It\u0026rsquo;s doing experiments on you: it\u0026rsquo;s trying to gauge what they can show you to keep you on their website for longer. For my wife, it\u0026rsquo;s cooking tutorials.\n(Etc.)\nThis kind of tracking is bad because it happens opaquely without users\u0026rsquo; consent or knowledge. Companies use this data to make their products more addictive and targeted towards each individual user.\nI think there is better way. Any entity that wants to know something about you should ask you directly, in plain language about your preferences. They can then use that data to make suggestions, but this makes their algorithms simpler and more transparent.\nSome kinds of data that is valuable cannot be collected in this way. Take usability metrics, for instance. If users spend an unusually long amount of time on a particular page of a web app, it could be because that page is poorly designed. These kinds of data can still be collected provided they are anonymized, never used for profit through sale, and they still show the user what they are collecting.\n"},{"id":74,"href":"/posts/2020-12-23_freebsd_rpi4/","title":"FreeBSD on a Raspberry Pi 4 with 4GB of RAM","section":"Technical Blog","content":"This is the story of how I managed to get FreeBSD running on a Raspberry Pi 4 with 4GB of RAM, though I think the setup story is pretty similar for those with 2GB and 8GB.1\nI also managed to get Rust built from source, (kind of) which is nice because the default Rust installer doesn\u0026rsquo;t seem to work for FreeBSD running on a Raspberry Pi.\nIf there\u0026rsquo;s anything awry with these steps, please contact me so I can fix it.\nInstalling FreeBSD # First, get yourself a Raspberry Pi 4 and an SD card. (I don\u0026rsquo;t know how to boot from a hard disk; if anyone figures that out, please let me know.) Next, download the FreeBSD image from the 13.0 snapshot repository. I used what was the most recent version as of 2020-12-23 (FreeBSD-13.0-CURRENT-arm64-aarch64-RPI3-20201210-7578a4862f0.img.xz).\nFreeBSD doesn\u0026rsquo;t make Pi 4-specific snapshots, so you just have to use the RPI 3 version.\nUnpack the zip file, and flash that to your SD card:\nxz -d FreeBSD-13.0-CURRENT-arm64-aarch64-RPI3-20201210-7578a4862f0.img.xz sudo dd bs=1m if=FreeBSD-13.0-CURRENT-arm64-aarch64-RPI3-20201210-7578a4862f0.img of=/dev/DISK_NUMBER conv=sync Plug that into your Pi, and make sure it boots up.\nGet FreeBSD to recognize all the RAM available # You can check how much RAM the OS thinks it has like this:\nsysctl hw.physmem After upgrading the boot system, I got 4124610560 (4GB). Prior to this, this returned a much lower number (though I can\u0026rsquo;t remember what it was).\nFirst, on your FreeBSD pi, you\u0026rsquo;ll want to install the following packages:\nsudo pkg install sysutils/rpi-firmware sudo pkg install u-boot-rpi4 (Not sure how necessary that first one is, actually. Didn\u0026rsquo;t seem to hurt things though.)\nAfter you\u0026rsquo;re done installing the u-boot-rpi4 package, you will want to copy a file from your FreeBSD machine to something you can use to modify the SD card. (In my case, I used the same machine as the one I used to flash the SD card in the first place.)\nme@non-freebsd:~ $ rsync -aivz root@generic:/usr/local/share/u-boot/u-boot-rpi4/u-boot.bin . (NOTE: If you want to use rsync, you\u0026rsquo;ll have to install rsync on your FreeBSD machine with pkg install rsync)\nShut down your Raspberry Pi, pull out the SD card, and mount it onto that machine you just copied the u-boot.bin file to. Open up the MSDOSBOOT image, and find the u-boot.bin file in the root of the image. Delete it, and move the one you copied from your pi into its place. Eject the SD card, and replace it into your Pi. Boot it up!\nYou can check to make sure that your Raspberry Pi now enjoys the full amount of RAM available on your machine:\n$ sysctl hw.physmem hw.physmem: 4124610560 Installing Rust # I love Rust. Unfortunately, FreeBSD running on an ARM system (like a Raspberry Pi) is in Tier 3 support, so I had to do some work to get it built myself.\nPrerequisites # You will need to have all 4GB of RAM available. I tried this before getting the 4GB thing working, and builds kept failing.\nBuilding everything from source takes forever, so go ahead and install the following with pkg:\nperl (I think you need to specify a version with this one; just get the latest version) python llvm git cmake libgit2 ninja pkgconf Ports Tree # You\u0026rsquo;ll want to get the ports tree on your machine so you can build Rust. Make sure you set your clock so it\u0026rsquo;s the right time, then you can install the port tree:\nportsnap fetch portsnap extract That last command will take a while to run.\nStart Building # Rust takes a very long time to build and consumes a lot of CPU. My build has been running all day and it hasn\u0026rsquo;t finished yet. You\u0026rsquo;ll want to throttle up your fan on your Raspberry Pi if you\u0026rsquo;ve got one; thermal throttling can kick in pretty quickly when all four cores are going at 100%.\nThis should get the build started:\ncd /usr/ports/lang/rust make That should run for a few hours at least. Like, on the order of 18 hours or so. (Download speeds are not the bottleneck, at least not for me!)\nAnd, for me, unfortunately, the build died near the end with this error:\nFresh walkdir v2.3.1 Fresh cmake v0.1.44 Traceback (most recent call last):=====\u0026gt; ] 35/76: serde_json(build), cmake, walkdir, ryu(build) File \u0026#34;x.py\u0026#34;, line 11, in \u0026lt;module\u0026gt; bootstrap.main() File \u0026#34;/usr/ports/lang/rust/work/rustc-1.48.0-src/src/bootstrap/bootstrap.py\u0026#34;, line 1066, in main bootstrap(help_triggered) File \u0026#34;/usr/ports/lang/rust/work/rustc-1.48.0-src/src/bootstrap/bootstrap.py\u0026#34;, line 1039, in bootstrap build.build_bootstrap() File \u0026#34;/usr/ports/lang/rust/work/rustc-1.48.0-src/src/bootstrap/bootstrap.py\u0026#34;, line 824, in build_bootstrap run(args, env=env, verbose=self.verbose) File \u0026#34;/usr/ports/lang/rust/work/rustc-1.48.0-src/src/bootstrap/bootstrap.py\u0026#34;, line 153, in run raise RuntimeError(err) RuntimeError: failed to run: /usr/ports/lang/rust/work/bootstrap/bin/cargo build --manifest-path /usr/ports/lang/rust/work/rustc-1.48.0-src/src/bootstrap/Cargo.toml --verbose --frozen *** Error code 1 Stop. make[1]: stopped in /usr/ports/lang/rust *** Error code 1 Stop. make: stopped in /usr/ports/lang/rust However, I did notice that there was a rustc binary hanging out in /usr/ports/lang/rust/work/bootstrap/bin/rustc, along with binaries for cargo, rustdoc et. al. I think something in the standard lib (maybe serde) failed to build for some reason, but I tried compiling a little \u0026ldquo;Hello, World!\u0026rdquo; program, and that worked just fine. I don\u0026rsquo;t know how well other things will work.\nIf anyone manages to get everything working please tell me how you did it and I will update this post for the benefit of anyone coming after. :)\nUPDATE 2020-12-28 # I managed to compile a little rust program I made, and this includes serde. I\u0026rsquo;m not sure how well the filesystem watcher works; I\u0026rsquo;ll try that out some time and see how it goes. I just had to add /usr/ports/lang/rust/work/bootstrap/bin to my path, and I was able to run cargo build and then cargo run with no problems.\nSee this thread for some help on 8GB Raspberry Pis\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":75,"href":"/posts/2020-12-11-raspberry-pi-dos/","title":"Dr. Loopback, Or: How I Learned to Stop DOSing Myself and Love the Pi-Hole","section":"Technical Blog","content":"I noticed that my Internet was acting strangely: whenever I visited a web page, my browser would hang for a good second or two before it started loading anything. Zoom calls worked without a problem for school, so this tipped me off that something was wrong with the DNS lookup or the handshake.\nSure enough, I popped open my Pi-Hole admin console, and was greeted with this:\nThe green number in the Total Queries box would jump by 10, 20, or sometimes even 100 every second.\nI tried turning off, disconnecting, and rebooting my various computers and devices to see if it was just some rogue process messing everything up. No change. I rebooted my router. No change. I updated and restarted the Pi-Hole. Still no change.\nI noticed that a lot of requests to the domain lb._dns-sd._udp.0.0.0.10.in-addr.arpa. I did a web search and found a single post on a forum that suggested turning off conditional forwarding on the Pi-Hole.\nI went into admin settings, turned off conditional forwarding, and was rewarded with this:\nNow my pi isn\u0026rsquo;t overloaded with DNS requests, and my Internet is as snappy as it used to be.\nWhat happened, I think, was that a device on my network would try and lookup some name. The router would forward this request to the pi, which would then forward it back to the router, which would then send it back to the pi, etc. Boom. Infinite loop, and all my DNS requests got bogged down.\nI\u0026rsquo;m not very good with networking; that\u0026rsquo;s probably my biggest weakness. I learned a thing today, though!\n"},{"id":76,"href":"/posts/2020-11-future-of-emacs/","title":"RMS Does Not See the Future of Emacs","section":"Technical Blog","content":"I am an avid Emacs user. I\u0026rsquo;m using it right now to compose this post. I use it every single day for everything from work to school to personal notes. Most of my activity on GitHub comes from me tweaking little things in my configuration files. I now have an editor that perfectly fits my hands. Emacs is a big part of my life.\nI\u0026rsquo;m afraid it\u0026rsquo;s dying.\nRichard Stallman, one of the principle creators of Emacs and the head of the GNU Project, has made several choice in the past several months that I consider to be detrimental to the Emacs community and harmful for Emacs\u0026rsquo; further growth. RMS doesn\u0026rsquo;t seem to care that much about making Emacs appealing to new users, and I think this is a mistake. Emacs derives its strength from being uniquely customizable and extensible; the more people we get using Emacs, the more good extensions, packages, tutorials, etc. will be available for Emacs. Some of the growth-hostile things include:\nShutting down suggestions for making Emacs start with a sensible set of defaults that would make it significantly easier for beginners to get started1 Purging links to the most popular (and most useful!) Emacs package repositories, Melpa and Marmalade, just because they might contain links to sites with non-free Javascript2 Ignoring community-driven development and exercising veto rule in cases where I personally think it was unwarranted3 I can appreciate strong leadership; I think for creating most things, having a single leader drive the development of a product gives it focus and direction that otherwise might kill it off. (I think Python is a good example of this at work.) In this case with Emacs, however, I think RMS is badly out of touch and should focus on what we as a community can do to make Emacs more robust so that future generations of programmers will have a strong motivation to use Emacs—a desire to run free software motivates precious few people in their selection of their tools. We should make it more appealing for its features and performance as well.\nSome areas where Emacs stands to improve are:\nBeginner-friendliness The default Emacs theme looks awful. No computer user used to the comforts of macOS or Windows would want to go near that ugly beast. It should have a pretty-looking theme by default. One idea would be to make it so that a new user can select some pre-built themes. Performance There are some exciting things happening with gccemacs on this front. I\u0026rsquo;m not running that right now, as compiling Emacs master on macOS is a little persnickety. Improving its rendering engine would help too. I recognize that that is a big undertaking, and unfortunately I have little to offer in this regard. Ease of contribution Why not host Emacs development on a self-hosted GitLab instance? Or use some other issue tracker? I understand that there are some advantages for mailing lists, but the set of programmers who are a.) familiar with that work flow, and b.) prefer it, is dwindling. An issue/PR-style flow makes a lot more sense for most developers, and I think it would go a long way to enriching community involvement in Emacs\u0026rsquo; core development. These are just my thoughts, and will likely evolve over time. Unfortunately I cannot devote as much time as I would like to improving Emacs, though I do enjoy learning to write packages when I have the time.\nGood luck, all you Emacs maintainers out there. You\u0026rsquo;re heroes.\nhttps://lwn.net/Articles/819452/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/emacs-mirror/emacs/commit/5daa7a5fd4aced33a2ae016bde5bb37d1d95edf6\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttp://ergoemacs.org/misc/rms_emacs_tyrant_2018-03.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":77,"href":"/posts/2020-10-27-social-dilemma/","title":"The Social Dilemma","section":"Technical Blog","content":"I just finished watching The Social Dilemma, and here\u0026rsquo;s my hot take: The Social Dilemma is an emotive, accessible introduction to problems that, without exaggeration, pose an existential threat to life as we know it. If you can, watch it.\nHaving read Technopoly by Neil Postman, I didn\u0026rsquo;t feel like The Social Dilemma was revelatory in saying that technologies have unintended side-effects. What\u0026rsquo;s different about The Social Dilemma is that it is really accessible and it highlights real, present, concrete problems caused by Facebook, Twitter, Instagram, etc. (I think if Neil Postman had been alive to witness Facebook and Twitter, he would have been scared silly.)\nSocial media is perhaps unique in that there has never been a technology so complex that requires so little effort or expertise on the part of the end-user. Prior to the invention of the personal computer, the most complex piece of technology a lay person used was a car. Even though it is relatively easy to drive, a car still requires you to have some knowledge of its inner workings: knowing when to change the oil or coolant or when to get the tires replaced or the brakes checked is part of operating a car successfully.\nNot so with social media. All you need to know is how to type your name and scroll. The complexity behind Facebook\u0026rsquo;s implementation is orders of magnitude greater than that in any car. Yet Facebook is so easy to use that even the most illiterate, technologically inept person can figure it out. Therein lies some of the danger: Facebook, Google, Instagram, etc. all employ technologies1 to influence your behavior, and end users are entirely oblivious to their workings and effects.\nSo what do we do?\nAt the end of The Social Dilemma, many of the experts and creators of these technologies suggested that we need governmental regulation. I\u0026rsquo;m persuaded that our best bet lies in some kind of regulation, because market forces do nothing to incentivize their creators to fix the problems of polarization and misinformation. Exactly how that regulation should be enacted is an open question. Perhaps social media should be regulated like alcohol or tobacco: e.g. stricter limits on when someone can start using it, and visible warnings about the psychological effects that it has. Removing or severely curbing political advertisements, especially when paid for by parties other than the candidate in question, might have an interesting effect as well.\nAs for myself, I\u0026rsquo;ve gotten off of Facebook entirely. I\u0026rsquo;ve taken conscious steps to make it more difficult for me to get on Twitter. When I sleep, my phone is in a different room. Whenever I notice myself reaching for an app when I have nothing to do, I turn it off, delete it, or otherwise force myself to be more deliberate about my technology habits.\nWhen I have kids, I intend on acquainting them with the workings of computers and algorithms. While I don\u0026rsquo;t expect (or want) all of my kids to become computer scientists, I want them all to be aware of the mechanisms at play to help them be on their guard for addictive and manipulative technologies like social media.\nI am deeply worried about where things are going, and I do not think the solution to misinformation and polarization is more technology or AI or some other technological solution. It cannot be. They can help if employed correctly, but they cannot function as the cure. I think the only possible solutions will come from better regulation to shift the incentives of these massive technology companies and better education so that people can be more mindful, more deliberate, and less vulnerable to addiction or deception.\nNote that \u0026ldquo;technology\u0026rdquo; is more than a physical device. Technology includes things like writing or a mathematical formula. See my post on Technopoly for a little more detail on this subject.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":78,"href":"/posts/2020-election/","title":"To my Friends on the Fence","section":"Technical Blog","content":"I\u0026rsquo;d like to write tonight to my well-respected friends, who usually align themselves with the Republican party, but who may be questioning that choice during this election season.\nI know that some of you might vote republican because you believe that abortion is the most important issue.\nConsider this: when the Constitution was ratified, it did not immediately do away with slavery, nor did it give women the right to vote. Presidential terms were not limited to two years in office, and the voting age was set at 21. The framers of the Constitution knew that they would not be able to create a perfect government with perfect policies, so they created a mechanism by which the country could progress towards perfection. That mechanism—democracy—is what allows us to create good legislation and nullify bad laws.\nDonald Trump is dismantling that mechanism.\nEven if you agree with every policy decision made by Trump, he will sooner or later have to leave office, and then you might not agree with every decision made by the leader. If the mechanisms we have to check that power are gone, you will have no recourse. With Donald Trump as president, you might get what you want on a few issues, but I believe the damage to democracy will far outweigh whatever advantage may be derived from him holding a second term.\nMy Christian faith also makes me worry about Trump. While he enjoys popularity with many evangelical groups, Trump mocks them in private. He even has mocked my faith—Trump thinks Romney lost because he was a member of the Church of Jesus Christ of Latter-day Saints. Biden, on the other hand, defended Mitt Romney membership in the same church all the way back in 2011. I believe Biden is better-qualified for interacting respectfully between foreign leaders of differing faiths and values. Trump is just a bully.\nI do not agree with many of Biden\u0026rsquo;s policies. But I am voting for him anyway because he—far more than the incumbent—respects our democratic processes which allow for continual adjustment though fair, free means. Biden has shown respect to members of my faith, which I appreciate. I will probably disagree strongly with plenty of things that Biden will do while in office, but I believe that he will respect the democratic processes by which I may protest such decision.\nAppendix A: Trump Dismantling Democracy # This is by no means an exhaustive list, but let these \u0026ldquo;facts be submitted to a candid world\u0026rdquo;:\nHe has repeatedly attacked the integrity of our elections. He has refused to commit to accept the results of the upcoming election. He has accepted money from foreign powers. He has installed criminals and family relatives in high office. He has broadly dismissed scientific evidence when it was pertinent, favoring his opinion to empiricism. He has emboldened neo-Nazis and racists. He has shown utter disregard for rule of law and checks and balances. He has obstructed justice. "},{"id":79,"href":"/posts/personal/2020-09-19-on-nuance/","title":"An Explaination—Not an Excuse: Thoughts on Nuance","section":"Personal Blog","content":"The other day I responded poorly to some school assignment related frustration. An hour later after I had calmed down and resolved the issue, my wife gently chided me for how I acted. I expressed gratitude for her well-placed correction, and said that I had been having a bad day leading up to that. I then added that that was an explaination, not an excuse, and my wife understood the difference between the two.\n"},{"id":80,"href":"/posts/personal/2020-09-11-september-11th/","title":"The 11th","section":"Personal Blog","content":"Today is September 11th. I remember waking up 19 years ago, coming into the living room, and my dad getting down on one knee so he was closer to my level. He told me that earlier that morning two airplanes had crashed into some tall buildings in New York City. I didn\u0026rsquo;t know what that meant at the time, but I soon found out.\nFor several anniversaries thereafter, my elementary school class would spend a minute of silence in remembrance of those who died. Each year I learned more about what happened—not just about the hijackings, but also how the nation came together for a few weeks afterwards. People tell me there was a profound, nation-wide sense of mourning, community, and shared strength.\nAbout 3,000 people died, and 25,000 were injured.\nOur nation is in the grips of a pandemic that kills that same number every three days. There is a difference between a plane wielded like a bomb and a mindless virus, but the profound dismissal and denial of our present crisis by the current president is criminal. He has utterly failed to unite the nation. He has shown no sympathy for the hundreds of thousands of people who have died. Had he acted better in February—and he knew what was coming—he might have been able to say he saved some.\nNow the blood of thousands is on his hands.\nHe has sought to direct attention away from an ongoing crisis in an effort to improve his appearance. He displays no empathy for the immense loss and suffering in this country. Whereas we have been able to band together in the face of threats in the past, this time we are left weak because of the wickedness of a man who has fanned the flames of division, blame, and ignorance. I have never seen our nation so divided in my lifetime, and I fear what may yet lurk in our future.\nMay we let the memory of September 11th remind us of what we ought to do in the face of the present calamity. Let us overcome partisan barriers that divide us and focus on solving the problems at hand. I pray that we will be able to turn outwards, and listen, and heal.\n"},{"id":81,"href":"/posts/personal/2020-09-05-quarantine-in-1600s/","title":"Quarantine in the 1600s","section":"Personal Blog","content":"It\u0026rsquo;s been a long six months that we\u0026rsquo;ve been under quarantine and other disease-limiting measures. It hasn\u0026rsquo;t been easy, but thanks to something I saw at Königsstein Fortress I\u0026rsquo;m not complaining. Here\u0026rsquo;s why:\nKönigsstein1 Fortress, also known as the Saxon Bastille, overlooks a section of the Elbe river and is located just south of Dresden. This is a little bunker built on top of the fortress. This is what the sign says:\nIn the year 1680 40 people died of the plague at the fortress. In those times, those infected were placed in huts outside the fortress, since there were no other means of isolation. After the epidemic was over, this casemate2 was built as a precautionary measure in a natural fissure in the cliff. The \u0026ldquo;plague casemate\u0026rdquo; is 8 meters3 deep and has an entrance, an air shaft, and an opening for lowering in food. We don\u0026rsquo;t have any evidence of people staying and dying of the plague in here, however. At the end of the 19th century this was repurposed as an artillery observations stand and was covered with a layer of earth.\nI\u0026rsquo;m pretty sure they didn\u0026rsquo;t have good enough WiFi in there to watch Netflix.\nHere\u0026rsquo;s a look deeper into the pit:\nI\u0026rsquo;m encouraged by the increase in mask-wearing that I\u0026rsquo;ve seen in the past few weeks, and I\u0026rsquo;m deeply grateful for all the medical workers and \u0026ldquo;essential\u0026rdquo; laborers working in grocery stores, as part of the supply chain, etc. As a thank you, I\u0026rsquo;m working from home and doing my best to limit my contact with the outside world. I\u0026rsquo;m grateful that I can work from home and that my wife and I have plenty here at home to do. It\u0026rsquo;s a real blessing, and I get that many people don\u0026rsquo;t have that luxury.\nIf you\u0026rsquo;re staying home too but feel exhausted, just remember: at least you\u0026rsquo;re not locked in a cold stone box without any WiFi.\nKönigsstein means \u0026ldquo;king\u0026rsquo;s stone\u0026rdquo;. This fortress is huge. I don\u0026rsquo;t think any army has successfully conquered it.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA small room in the thickness of the wall of a fortress, with embrasures from which guns or missiles can be fired.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRoughly 26 feet.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":82,"href":"/posts/personal/2020-08-16-book-review-technopoly-v2/","title":"Book Review: Technopoly","section":"Personal Blog","content":" In Technopoly: The Surrender of Culture to Technology, Neil Postman argues that our infatuation with technology has insidiously eroded our culture. We gain much through technology, but it comes at a price; all too often we are blind to that price. This book seeks to call attention to the costs of a technology-focused society. I felt this poignantly because I, as a technology worker, know what that infatuation feels like.\nThis book review will be pretty limited in scope: I\u0026rsquo;ll only talk about new insights that I got from the book, as well as a few points that I disagreed with. I encourage everyone to read the book: the book itself will do a much better job of telling you what it\u0026rsquo;s about than I will! This post, then, should be regarded as an artifact of me trying to make sense of what I read, rather than a comprehensive analysis of the book.\nBook Introduction # For those of you who haven\u0026rsquo;t yet read Technopoly, this section is a meager summary of some of the points I\u0026rsquo;ll touch on\nWhat is \u0026ldquo;technology\u0026rdquo;? # Technology is defined rather broadly in Technopoly: rather than just physical tools, a technique or a system can be considered a technology. For example, writing is a technology. In chapters 6–8 he talks about medical and computer technologies, as well as \u0026ldquo;invisible\u0026rdquo; technologies like statistics and writing.\nTechnology is usually intended to serve a particular purpose: writing lets us communicate without the need to be temporally and physically proximate. Statistics help us make sense of a complex world. Technologies give us benefits. What Postman explores is what technologies take away.\nPostman doesn\u0026rsquo;t say that technology is bad per se, and his argument isn\u0026rsquo;t that we should stop using certain technologies. Rather, he argues that we need to step back and be more conscientious in our usage:\n[We should understand] that technology must never be accepted as part of the natural order of things, that every technology—from an IQ test to an automobile to a television to ac computer—is a product of a particular economic and political context and carries with it a program, and agenda, and a philosophy that may or may not be life-enhancing and that therefore require scrutiny, criticism, and control.\npp. 184–185\nOur culture is not inclined to think about what we loose by adopting a particular technology. Why should it? To say that a particular technology comes with some costs (besides those of a pecuniary nature) doesn\u0026rsquo;t sell well. Moreover, most of us are just flat-out blind to the costs of technology.\nWhat does technology do? # Postman outlines three broad effects of technology:\nTechnology restructures our interests: a tool or technique might change what we might think about. Facebook, Instagram, Twitter, etc. can make us more interested in creating engaging or entertaining content, rather than quality work.\nTechnology changes our symbols: technology can change how we think about things—it can reassign value and change how we perceive the world. Bureaucracies often push for greater efficiency because efficiency is perceived as intrinsically good.\nTechnology alters our community: Twitter is a great example of how technology alters the arena in which ideas are created and debated. But this happened even before the internet: the telegraph brought together disparate parts of the world and blended their conversations.\nThe Value Shift # What I found most interesting in Postman\u0026rsquo;s book is his exploration of how technology can alter our values. He\u0026rsquo;s careful to point out that a change in values is not necessarily bad—some values need adjustment—but what is problematic is that we might not recognize what values are shifting.\nTo clarify what values are shifting, Postman writes:\nThese include the beliefs that the primary, if not the only, goal of human labor and thoughts is efficiency; that technical calculation is an all respects superior to human judgment; that in fact human judgment cannot be trusted, because it is played by laxity, ambiguity, and unnecessary complexity; that subjectivity is an obstacle to clear thinking; that what cannot be measured either does not exist or is of no value; and that the affairs of citizens are best guided and conducted by experts.\npp. 51 (emphasis mine)\nThe ramifications of this are multifaceted; I cannot hope to go into them all here. Instead, I\u0026rsquo;ll give one example of this shift at work: Facebook.\nFacebook\u0026rsquo;s premise is stupid # Facebook bills itself as a social network. I take issue with the social bit of that moniker. Human connection does not happen in a virtual world. Our species has been forming communities for millennia by getting together in the real world. Facebook wanting to help \u0026ldquo;create connection\u0026rdquo; is a solution in search of a problem.\nFacebook isn\u0026rsquo;t the only company that makes a big deal out of these kinds of \u0026ldquo;innovations\u0026rdquo;: I follow Apple\u0026rsquo;s keynotes, and they always talk about how there are \u0026ldquo;great new ways\u0026rdquo; to \u0026ldquo;share and connect\u0026rdquo; with your friends. While sharing digital photos is a new phenomenon, this idea of connecting—not electronically, but in the human sense—requires no new technology. It\u0026rsquo;s easy to get caught up in the frenzy of \u0026ldquo;the latest new thing\u0026rdquo;, but once you wipe away the chrome, there\u0026rsquo;s surprisingly little substance underneath.\nFacebook touts \u0026ldquo;community\u0026rdquo; and \u0026ldquo;connecting people\u0026rdquo; as intrinsically valuable things. But are they? Not too long ago I read this in Ars Technica:\nAccusing Facebook\u0026rsquo;s algorithm of \u0026ldquo;promoting hatred and anger,\u0026rdquo; Himes added, \u0026ldquo;You keep using the word \u0026lsquo;community\u0026rsquo; and \u0026lsquo;authentic.\u0026rsquo; Those are value-neutral words. There is nothing good or bad about authenticity or good or bad about community.\u0026rdquo; Indeed, he went on, \u0026ldquo;community\u0026rdquo; can be explicitly bad.\nTechnopoly points out the general phenomenon going on here: technology (and technology-centric companies\u0026rsquo; marketing departments!) push us to value things that technology can accomplish: we value machines and processes that are \u0026ldquo;faster\u0026rdquo; or \u0026ldquo;more efficient\u0026rdquo;, but we ask whether or not these new technologies add meaningful value far too infrequently.\nI will add here that, amidst a pandemic, platforms like Facebook do truly add some value because we cannot meet together safely as we usually would. If anything, the way this pandemic has forced us to rely on digital facsimiles of in-person interaction should help us value the intrinsically and irreplaceable human qualities of what society, connection, and friendship really are.\nNot everything that counts can be counted… # Statistics is another tool that Postman discusses in his book. I won\u0026rsquo;t go too into depth here, but continuing on with the Facebook example, consider the case of \u0026ldquo;friends\u0026rdquo; and \u0026ldquo;likes\u0026rdquo;: these numbers serve as measures for how popular one is or how engaging someone\u0026rsquo;s blurb/photo/whatever is. Do these numbers measure anything of value? I think it\u0026rsquo;s hard to argue that they do. They are simplified, watered-down metrics that are easy to measure and compare. Because it\u0026rsquo;s easy to measure and compare these numbers, we\u0026rsquo;ve attached some value to them.\nI guess if you\u0026rsquo;re an advertiser,1 those metrics can give you some idea of whether or not your ad campaign is working. But Facebook doesn\u0026rsquo;t advertise (har har) itself to ordinary users as an ad platform. It says that it\u0026rsquo;s a social network, and then gamifies acquiring \u0026ldquo;friends\u0026rdquo; and making \u0026ldquo;connections\u0026rdquo;. But in real relationships, quality trumps quantity. People with a few good friends are happier than those with only a thousand acquaintances. But because of the presence and ease of use of these metrics, we have imputed value to them.\nTools: do we use them, or are we used by them? # Facebook isn\u0026rsquo;t the only technology to emerge in recent years that represents a fundamental value shift. There are others too. Consider Twitter: so much dialog happens on Twitter, and the tacit philosophy behind Twitter seems to be that you can have meaningful discussions when limited to 280 characters.\nIt\u0026rsquo;s not inevitable that we think that way, but the technology of tweets tends to direct our dialog in that way.\nTwitter is not the only technology that\u0026rsquo;s had a degrading effect on our public discourse: Postman makes a compelling argument in Amusing Ourselves to Death that television—and if he had lived to see it, he would have argued that the Internet as it is today—has had an insidious effect on our dialog.\nPostman is somewhat pessimistic about our prognosis. I\u0026rsquo;m a little more hopeful that individuals will be able to master technology rather than letting it master them. I agree, however, that it is difficult; to this end, Postman offers a few points of advice:\nThose who resist the American Technopoly are people\n…who refuse to accept efficiency as the pre-eminent goal of human relations;\n…who are, at least, suspicious of the idea of progress, and who do not confuse information with understanding;\nwho do not regard the aged as irrelevant;…\npp. 183–184\nThere\u0026rsquo;s a lot more in there that I can\u0026rsquo;t put down here. Go read the book yourself.\nConclusions # Reading this book has made me think about how I use and interact with technology. I abandoned Facebook over two years ago,2 so no changes on that front.\nI try and read from the Bible or the Book of Mormon every morning, and I like taking notes about what I read. I used to take notes with a pen and a notebook, but I switched to digital notes about two years ago. Recently I noticed that I started spending a lot of time working on maintaining all my cross references and indexes, rather than devoting that time to actual study. I decided to be a little more conscientious about how I use my time: I\u0026rsquo;ve since limited interaction with my computer to reviewing the study plan that I\u0026rsquo;ve set for myself. Once I\u0026rsquo;ve gone over my plan, I sit down a short distance away from my laptop and just read a hard copy of the scriptures.\nWhy did I start using digital notes in the first place? I wanted all my notes to be indexable and searchable. That has been nice, but Technopoly got me thinking about why I actually study: I seek for a connection with God each morning. If my note taking system is getting in the way of that, then I am doing something wrong.\nThis kind of examination is what Postman suggests as our primary defense against the encroachment of technology: we should examine every new technology, find what we give up by adopting it, and decide whether or not it is worth the price.\nWhich, to be fair, is the whole purpose of Facebook: put more ads in front of people\u0026rsquo;s faces.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThough, at the time of that post, I hadn\u0026rsquo;t yet deleted my account. Now my account is permanently gone—assuming Facebook actually deleted my data. (Which, frankly, I doubt they did entirely.)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":83,"href":"/posts/2020-08-10-moving-to-hugo/","title":"Moving to Hugo","section":"Technical Blog","content":"Hello world.\nNullam eu ante vel est convallis dignissim. Fusce suscipit, wisi nec facilisis facilisis, est dui fermentum leo, quis tempor ligula erat quis odio. Nunc porta vulputate tellus. Nunc rutrum turpis sed pede. Sed bibendum. Aliquam posuere. Nunc aliquet, augue nec adipiscing interdum, lacus tellus malesuada massa, quis varius mi purus non odio. Pellentesque condimentum, magna ut suscipit hendrerit, ipsum augue ornare nulla, non luctus diam neque sit amet urna. Curabitur vulputate vestibulum lorem. Fusce sagittis, libero non molestie mollis, magna orci ultrices dolor, at vulputate neque nulla lacinia eros. Sed id ligula quis est convallis tempor. Curabitur lacinia pulvinar nibh. Nam a sapien.\nAliquam erat volutpat. Nunc eleifend leo vitae magna. In id erat non orci commodo lobortis. Proin neque massa, cursus ut, gravida ut, lobortis eget, lacus. Sed diam. Praesent fermentum tempor tellus. Nullam tempus. Mauris ac felis vel velit tristique imperdiet. Donec at pede. Etiam vel neque nec dui dignissim bibendum. Vivamus id enim. Phasellus neque orci, porta a, aliquet quis, semper a, massa. Phasellus purus. Pellentesque tristique imperdiet tortor. Nam euismod tellus id erat.\nPellentesque dapibus suscipit ligula. Donec posuere augue in quam. Etiam vel tortor sodales tellus ultricies commodo. Suspendisse potenti. Aenean in sem ac leo mollis blandit. Donec neque quam, dignissim in, mollis nec, sagittis eu, wisi. Phasellus lacus. Etiam laoreet quam sed arcu. Phasellus at dui in ligula mollis ultricies. Integer placerat tristique nisl. Praesent augue. Fusce commodo. Vestibulum convallis, lorem a tempus semper, dui dui euismod elit, vitae placerat urna tortor vitae lacus. Nullam libero mauris, consequat quis, varius et, dictum id, arcu. Mauris mollis tincidunt felis. Aliquam feugiat tellus ut neque. Nulla facilisis, risus a rhoncus fermentum, tellus tellus lacinia purus, et dictum nunc justo sit amet elit.\nAliquam erat volutpat. Nunc eleifend leo vitae magna. In id erat non orci commodo lobortis. Proin neque massa, cursus ut, gravida ut, lobortis eget, lacus. Sed diam. Praesent fermentum tempor tellus. Nullam tempus. Mauris ac felis vel velit tristique imperdiet. Donec at pede. Etiam vel neque nec dui dignissim bibendum. Vivamus id enim. Phasellus neque orci, porta a, aliquet quis, semper a, massa. Phasellus purus. Pellentesque tristique imperdiet tortor. Nam euismod tellus id erat.\nPellentesque dapibus suscipit ligula. Donec posuere augue in quam. Etiam vel tortor sodales tellus ultricies commodo. Suspendisse potenti. Aenean in sem ac leo mollis blandit. Donec neque quam, dignissim in, mollis nec, sagittis eu, wisi. Phasellus lacus. Etiam laoreet quam sed arcu. Phasellus at dui in ligula mollis ultricies. Integer placerat tristique nisl. Praesent augue. Fusce commodo. Vestibulum convallis, lorem a tempus semper, dui dui euismod elit, vitae placerat urna tortor vitae lacus. Nullam libero mauris, consequat quis, varius et, dictum id, arcu. Mauris mollis tincidunt felis. Aliquam feugiat tellus ut neque. Nulla facilisis, risus a rhoncus fermentum, tellus tellus lacinia purus, et dictum nunc justo sit amet elit.\n"},{"id":84,"href":"/posts/2020-08-04-thoughts-on-pl-design-goals/","title":"Thoughts on Goals in Programming Language Design","section":"Technical Blog","content":"I\u0026rsquo;ve been thinking about programming languages a lot recently. A question I asked myself was: why do we work on, refine, and create new programming languages?\nI thought of several reasons, but they seemed to boil down into two broader reasons:\nBetter abstractions and more automation: some languages automate and ease some tedious tasks like memory management, concurrency, or type annotations. Almost all languages give you some ways of creating abstractions that let you reason with concepts in your problem domain, but different languages do this in different ways.\nMore precisely describe what you want: languages like Haskell let you describe the behavior of your program very precisely with an expressive type system. This lets you write correct programs with a high degree of confidence.\nOther languages give you a different level of control: C lets you manipulate bits at arbitrary memory locations and evaluate them as you please. You can get very good performance from a well-tuned C program.\nThere\u0026rsquo;s some overlap between these domains for sure, but these goals often seem to conflict one another: the first objective seems optimal for drafting programs. The second group is more tuned for long-running projects or programs with specific constraints. Permissive languages like Perl, Ruby, and most Lisps seem designed with the first objective in mind and are very easy to use when exploring an idea. They can be expressive and concise. More demanding languages, like Rust or Haskell, seem optimized for a long-lived project or a program with intensive system resource constraints or performance requirements. Maybe some people can draft in Rust, but I find it more difficult to whip up something in Rust than Perl or Elixir.\nCan we reconcile these two goals? Maybe. I think the further away you get away from the machine—trading some fine-grained control for abstraction—the closer the goals can converge. You can have a language well-suited for discovering an idea, which can then let you evolve your program into a more correct, reliable version.\nIn the end, I don\u0026rsquo;t think there is a perfect language. But some languages are more perfect than others! Hopefully I\u0026rsquo;ll strike on something interesting in my fumbling about with PL.\n"},{"id":85,"href":"/posts/2020-07-22-gui-emacs/","title":"Transitioning to GUI'd Emacs on macOS","section":"Technical Blog","content":"I went on an adventure today. I left behind the stable comforts of the terminal and compiled bleeding-edge Emacs that uses a native window system.\nThis is a big deal for me. As long as I can remember, I\u0026rsquo;ve used Emacs from within a terminal. I\u0026rsquo;ve decided to give the GUI\u0026rsquo;d Emacs a whirl.\nMy Journey # I\u0026rsquo;m running macOS Catalina (10.15.5). Originally I tried using the pre-built packages via brew (brew cask install emacs) and those available at Emacs for Mac OS X. However, all these pre-built binaries crashed on Catalina. I guess it\u0026rsquo;s a problem with Catalina. 🙄\nSo, I decided to try building from source. I cloned the Emacs source code directly from Savannah:\n$ git clone https://git.savannah.gnu.org/git/emacs.git I cd\u0026rsquo;d into that directory:\n$ cd emacs At this point you\u0026rsquo;ve got the bleeding-edge development Emacs. You might want to check out and pull a different branch or tag. I decided to check out the native-compilation branch:\n$ git checkout feature/native-comp $ git pull origin feature/native-comp (I\u0026rsquo;m pretty sure those are the right commands; stuff got a little funky while I was building.)\nI exported a magic1 environment variable that I got from a helpful Emacs StackExchange post:\n$ export LIBXML2_CFLAGS=\u0026quot;-I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/libxml2\u0026quot; After exporting that variable, I ran configure:\n$ ./configure Then I ran make:\n$ make That will create a binary at src/emacs that you can run to test to make sure that all is working as it should. If you\u0026rsquo;re satisfied with that emacs configuration, you can bundle it up into a stand-alone application:\n$ make install This will create Emacs.app inside of the nextstep/ directory. You are free to move that around:\n$ mv nextstep/Emacs.app /Applications/ I also went into System Preferences \u0026gt; Security and gave Emacs Full Disk Access. I heard of some people having difficulty accessing iCloud files from Emacs and this cleared it up. I haven\u0026rsquo;t had any difficulty—I just wanted Emacs to have full access anyway.\nNiceties # I still use the terminal a lot (though I might use it less directly if I can get comfortable with ansi-term mode) so I made a few shortcuts for myself:\nI symlinked /usr/local/bin/emacs to /Applications/Emacs.app/Contents/MacOS/Emacs:\n$ cd /usr/local/bin $ ln -s /Applications/Emacs.app/Contents/MacOS/Emacs emacs /usr/local/bin is already in my PATH, so now I can just type emacs on the command line and it will fire it up just as it used to\nI created an alias like this in my .zshrc file:\nalias 'e'='emacs -nw' That way, when I\u0026rsquo;m in a terminal and type e \u0026lt;filename\u0026gt; it will open up the file in Emacs in the terminal. I might change that behavior at some point in the future, but that will help me transition for the time being.\nI installed the exec-path-from-shell package so that Emacs could fire off processes like elixir when using lsp-mode. Otherwise, you get errors like this inside the *lsp::stderr* buffer:\nline 66: exec: elixir: not found Conclusion # Why did I do this? Because I was a little bored. I also wanted to experiment with some of the more extensive key binding opportunities that a full-bodied Emacs offers.\nI\u0026rsquo;ll write updates to my blog as time goes on. I might decide to switch back to regular-old Emacs in the terminal. Right now, however, I\u0026rsquo;m enjoying the GUI\u0026rsquo;d version.\nYou can see my Emacs config on my GitHub. Feel free to drop me a line if you have any questions.\nUPDATE 2020-07-23 # After using Emacs 28.0.5 for a day, here\u0026rsquo;s what I came away with:\nNo crashes. Things did start getting a little strange when I tried selecting text with the mouse in ansi-term without switching from character-mode to line-mode; I ended up killing that ansi-term session and creating a new one.\nI really missed having frames all in the same place and switching between them with C-x 5 o. I found a very acceptable replacement; as of Emacs 27, you can enable the built-in tab-bar-mode and switch between \u0026ldquo;tabs\u0026rdquo; with C-x t o, create new ones with C-x t 2, etc. It looks just like switching between frames does in the terminal, minus the display of which tab you\u0026rsquo;re on. I haven\u0026rsquo;t figured out how to turn that on yet.\nUsing the tab-bar stuff, I created a tab and fired up ansi-term. I was able to switch back and forth between my editor tab and the console tab as I would between iTerm tabs or if I were using C-z to suspend.\nInputting special characters via the keyboard has changed. No longer can I hit alt-shift-- to insert an em-dash. Instead, I turn on TeX mode input (C-\\ TeX RET) and I can type the TeX character sequence (in the case of an em-dash, you just type a normal dash three times) and it will be inserted into the buffer.\nIn short, I\u0026rsquo;m finding this switch a decently comfortable one. I\u0026rsquo;m not giving up very much, and I\u0026rsquo;m gaining a decent amount. I\u0026rsquo;ve had some difficulty getting all the colors in the theme how I like them—I might just give up for a bit and see if I get used to them.\nI\u0026rsquo;m not entirely sure what it does. I know that it didn\u0026rsquo;t work before using this environment variable, and now it works after I tried using it.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":86,"href":"/posts/2020-06-15-languages-and-fonts/","title":"Programming Languages and Typography","section":"Technical Blog","content":"An analogy occurred to me this evening as I was thinking about programming language design:\nChoosing good keywords and function names is like picking a good font; the ideas conveyed may be the same, but a change can drastically impact legibility and enjoyment of use.\nPHP does a spectacular job of providing a bad example. It\u0026rsquo;s like the Comic Sans of programming languages. Now there are many reasons why PHP is not a good language—I\u0026rsquo;d like to investigate this particular aspect of its design here briefly.\nThere are ~55 functions in PHP that start with array_. Why? Why would you need to call the map operator array_map? Or array_filter, etc. Most other languages just call it map and leave it at that.\nYou might argue that that is a superficial difference: you are still doing the same thing so the expressive power of PHP is the same as whatever other languages you are comparing it to. I disagree. That extra clutter of the array_ prefix should not be there and it\u0026rsquo;s purely clutter.\nA bad font changes the tone and the perception of a body of text. Likewise, shoddy selection of keywords and names in a language changes it\u0026rsquo;s tone and feel.\nOther examples:\nJava PHP\u0026rsquo;s function keyword and other similar atrocities Common Lisp (the length of its function names are a shortcoming) I\u0026rsquo;ll continue fleshing this iut more, but these are my thoughts at the present\n"},{"id":87,"href":"/posts/personal/2020-06-07-amusing-ourselves-to-death/","title":"Book Review: Amusing Ourselves to Death","section":"Personal Blog","content":" Overview # The primary thrust of this book is that television has degraded our mode of public discourse. Our news, politics, education, and even religion are delivered to us primarily through television, where they were once delivered via the written word. This transformation of medium is not irrelevant: just as poetry doesn\u0026rsquo;t survive fully intact when translated from one language to another, likewise ideas do not survive translation of medium.\nThis book was written in 1986. What foresight. If Postman was worried about the effects that television was having on public discourse, he would have been scared silly to see how much of our dialog is held online on Facebook and Twitter, where all ideas are compressed into 140 to 280 characters and algorithms designed to optimize for consumer engagement determine what rises to prominence and what does not. Thus rational thought is drowned out\u0026mdash;stamped out\u0026mdash;by a deluge of content that is shallow, simplistic, and sensational.\nWhat follows are my notes that I wrote as I read the book, organized by chapter. Do note that these notes are not meant to stand on their own; if you have not read the book, they will likely seem disjoint.\nReading Notes # Typographic America (p. 30) # The typographical America read a lot.\nThe telegraph commoditized information: news was suddenly taken out of context and held as valuable per se. The question: if something is not relevant to my actions, can it still be valuable?\nThe Peek-a-Boo World (p.64) # p. 69: Is the problem then in unidirectional means of communication? We can\u0026rsquo;t reply and can\u0026rsquo;t really engage. We become passive and the signal gets lost in the noise.\nNow\u0026hellip; This (p. 99) # The idea here seems to be this: television has become the paradigm of information transmittal. Because it strips things of context and things are to be understood by themselves, contradictions fade. Magazines follow suit: entertainment is news, and news must be entertaining.\nShuffle Off to Bethlehem (p. 114) # p. 117: Prose survives translation between languages, whereas poetry does not survive. Likewise, ideas do not survive changes in medium unchanged. Television (and now mediums like Twitter, Instagram, etc.) do great violence to ideas.\np. 121: TV demands that what what be presented be easy. Elder Maxwell\u0026rsquo;s talks are nice to watch, but move far too quickly and are way more intricate than can be comfortably comprehended. There is some place for easy: beginners to faith will have difficulty appreciating everything about Elder Maxwell.\nReach Out and Elect Someone (p. 125) # p. 128: Commercials are less about the character of the product and mare more about the character of the consumer.\nReach out and Elect Someone (p. 126) # Capitalism works when the buyer and producer can both know what is good and what is valuable. In sports, there are rules and standards that cannot be muffled over; a basketball player who misses all his free throws cannot weasel his way into being considered a \u0026ldquo;good player\u0026rdquo;.\nYet the virtues exposed by television are how entertaining something is. It becomes \u0026ldquo;How good can a president look?\u0026rdquo; rather than \u0026ldquo;is this a good man?\u0026rdquo; We see that quite strongly today.\np. 135:\nAs Xenophanes remarked twenty-five centuries ago, men always make their gods in their own image. But to this, television politics has added a new wrinkle: Those who would be gods refashion themselves into images the viewers would have them be.\nIs this what gets Trump supporters so fanatic\u0026mdash;to the point where they cannot see his contradictions? What image does he portray that they wish they had?\nOne thing he projects is a disregard for the status quo. He\u0026rsquo;s also fiercely tribal\u0026mdash;people want an enemy they can scapegoat, and he leads the charge against everyone and everything. People then feel like if they\u0026rsquo;re on his team, they\u0026rsquo;re winning. What they think they\u0026rsquo;re winning, I have no idea. But they seem to think that they are winning something.\nThat\u0026rsquo;s kind of like a game show: a meaningless contest of luck, strength, trivia recall, etc. which is filmed in a futuristic studio. Everything is automatic and accompanied by jazzy music and flashing lights. Game shows are strange things.\np. 141: Television\u0026rsquo;s Censorship: television doesn\u0026rsquo;t ban books\u0026mdash;it displaces them, which is just as bad. I\u0026rsquo;ve wished for a super power\u0026mdash;not to be invisible, but that no one would be able to focus their attention on me and pay attention to what I am doing. It would be far easier to get away with stuff if no one noticed you than it would be if you were merely invisible: floating objects catch people\u0026rsquo;s attention rather quickly!\np. 141: Collateral learning: what do you learn outside of the content of the lesson? Helping students develop the right attitudes towards learning is important and tricky.\nTeaching as an Amusing Activity (p. 142) # p. 145: Television makes new conceptions of knowledge and how it is acquired. The Internet has compounded this a thousand fold: google it, tweet it, stream it on-demand, etc.\n"},{"id":88,"href":"/posts/personal/2020-05-23-masks/","title":"Masks","section":"Personal Blog","content":"Masks have become a hot issue. Here\u0026rsquo;s my 2¢.\nSummary # I think everyone should wear a mask, unless they have a compelling medical reason not to.\nLook at it this way: a mask will either help you and those around you, or it will do no harm—beyond a little social awkwardness. If we look at the trade-offs in a game-theory-style matrix, we get:\n| | Masks Help | Masks don\u0026rsquo;t help | |\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;| | Wear a mask | +100 | 0 | | Don\u0026rsquo;t wear a mask | -100 | 0 |\nThere is nothing to loose by wearing a mask, while there is the possibility of loosing a whole lot if we don\u0026rsquo;t. There\u0026rsquo;s some preliminary research showing that masks in fact help prevent transmission of COVID-19.\nOne way to think about wearing a mask is it\u0026rsquo;s like wearing a seat belt: seat belts save lives. Wearing seat belts is mandatory—rightly so!\nBut masks, unlike seat belts, not only help the wearer, but also protect others. True, cloth masks (home-made; surgical masks and N95 masks do much better of course) don\u0026rsquo;t seem to provide much protection for the wearers, but they do catch some non-negligible portion of the virus coming out of infected people. That one glob of saliva, if it lands right, could be the difference between life-and-death for someone else.\nWearing a mask shows respect and care for those around you. It shows solidarity: hundreds of thousands of people have died across the world—with over 100,000 in the US alone. We need to look out for each other.\nRefusing to wear a mask is disrespectful. It\u0026rsquo;s more than just driving without a seat belt. It\u0026rsquo;s like driving drunk: you might be fine, but there are so many other people that you are endangering.\nIf you continue to not wear a mask just because you feel it restricts your freedom, then I think society is well within its rights to deny you access or services out of self-preservation: the ice cream licker faces prison time, and drunk drivers can have their licenses suspended.\nFinally, think about the disrespect and selfishness you show by not wearing a mask. In essence you are saying, \u0026ldquo;I cannot be bothered to put up with mild discomfort in order to potentially save people\u0026rsquo;s lives.\u0026rdquo;\nIf you think I\u0026rsquo;m wrong about something or that there\u0026rsquo;s something I ought to understand better, please reach out to me via my Keybase. (My email is also in my résumé if Keybase isn\u0026rsquo;t working for you.) I prefer rational, one-to-one discussion; unfortunately the medium of the Internet makes that difficult.\n"},{"id":89,"href":"/posts/2020-05-20-computers-and-abstractions/","title":"Computers and Abstractions","section":"Technical Blog","content":"Computers are funny things. At the lowest level they\u0026rsquo;re just a pile of ones and zeros that we assign meaning to. It\u0026rsquo;s something you can easily take for granted, but there\u0026rsquo;s a disconnect with how we talk about how things operate at the hardware level and then again at the software level.\nSince writing a compiler, I\u0026rsquo;ve been able to bridge that gap in part. The fundamental idea is that we represent some meaning in a concrete, though still high-level form. Example: we might represent an entry in a contact book with a struct.\ndefstruct [name: :string, age: :integer] The critical step is this: we find a way to consistently represent that entity in the physical realm. We pack up a bunch of ones and zeros next to each other that are spaced apart at the right distances. Operations on bits in that neighborhood have to obey the rules we put in place. (E.g. treat the bits representing the age as a single thing, the bits representing the name can be broken up along character boundaries, etc.) Once our operations are complete, assuming our rules—our invariants—were never violated, then we can ascribe new meaning to the resulting mass of ones and zeros.\nPerhaps this isn\u0026rsquo;t that profound. Or maybe it\u0026rsquo;s more profound than my attempt to talk about it shoes. I\u0026rsquo;m sure I\u0026rsquo;ll gain more insight about this phenomenon as time goes on.\n"},{"id":90,"href":"/posts/2020-05-09-starting-fresh/","title":"Starting Fresh","section":"Technical Blog","content":"I\u0026rsquo;ve been building a compiler for a small lambda calculus that compiles to x86. It\u0026rsquo;s pretty broken, and I decided to start from scratch. I checked out a new branch in Git, and then deleted the entirety of my compiler before I had a chance to do anything else.\nIt hurt. But it was a good kind of hurt.\nI don\u0026rsquo;t usually just blow everything away like that. Even this time, I\u0026rsquo;m keeping many of my auxiliary functions. I\u0026rsquo;m not rewriting the parser or some of my x86-helper routines. Those can stay.\nI just wanted a blank slate. It\u0026rsquo;s nice having Git because I know I can always go back, but I\u0026rsquo;m not sure I will. I might glance back at my old branch occasionally, but by and large I\u0026rsquo;m starting fresh.\nFresh starts are important. I think one silver lining found among the clouds of this COVID-19 madness is that this is a chance to start fresh for so many people. Yes, it\u0026rsquo;s hard, and yes, there is lots of sadness, uncertainty, and grief. Take advantage of your life being paused and let this be a fresh start for something.\nMy wife is working on a writing habit. I\u0026rsquo;m working on developing research-oriented habits. I\u0026rsquo;m trying to read a paper every day—it\u0026rsquo;s not going super well, but I am improving!\nIt\u0026rsquo;s dark enough outside. Look for the silver lining and start fresh.\n"},{"id":91,"href":"/posts/2020-02-12-freebsd-on-a-raspberry-pi/","title":"FreeBSD on a Raspberry Pi","section":"Technical Blog","content":"I\u0026rsquo;m a FreeBSD guy. My first computer was a FreeBSD machine that my dad had running in a closet. I learned how to use Emacs as well as the command line on that black-screen white-text no-mouse interface. That\u0026rsquo;s how real programmers spend their childhood! 😎 😜\nI\u0026rsquo;ve only heard good things about FreeBSD. While not known as particularly desktop-friendly (various Linux distros win here) I\u0026rsquo;ve heard tales of its rock-solid stability. I wanted to try running on FreeBSD again, just to see what all the fuss was about.\nInstalling # Installing was relatively straight forward. I followed the instructions here.\nOnce I got the card flashed (took about an hour) and booted, I reset the passwords for users root and freebsd. Note that at time of writing WiFi wasn\u0026rsquo;t supported; I had to hard-link an Ethernet cable. It found the connection without any trouble, so that was nice.\nInitial Setup # Setting up the clock # https://www.freebsd.org/doc/handbook/network-ntp.html\nThe clock is necessary to start working with the ports. Set the config variables in /etc/rc.conf:\nntpd_enable=YES ntpd_sync_on_start=YES # This one might not be necessary You should be able to just run this without rebooting. (I ended up rebooting, but I think I did things out of order.)\nservice ntpd start Installing the port tree # https://www.freebsd.org/doc/handbook/ports-using.html\nRun the following: (I think you can do this in any directory)\nportsnap fetch portsnap extract Installing the critical tools: Emacs and Git # I tried going into /usr/ports/editors/emacs/ and running make install, but I must have had an option wrong because it tried installing\u0026hellip; I think the entire X Windowing System. Yikes.\nI gave up after about a day and instead ran pkg install emacs-nox and pkg install git; those ran pretty quickly.\n"},{"id":92,"href":"/posts/2019-12-13-switching-to-ivy-from-helm/","title":"Switching from Helm to Ivy","section":"Technical Blog","content":"Yet again, I\u0026rsquo;ve tweaked my emacs configuration. The big change this time is switching to Ivy from Helm.\nI\u0026rsquo;d like to say right off the bat that Helm is a great tool. I used it for several months and enjoyed it. Once thing that I love about helm is how discoverable it makes commands and functions. helm also got me into using bookmarks. I don\u0026rsquo;t keep many bookmarks; I tend to collect a few when working on a multi-file project long-term. The bookmark that I use most consistently is to my .emacs file; these days I\u0026rsquo;m fiddling constantly with my settings.\nI switched to Ivy because I found its completion options to be killer when using Magit: being able to fuzzy match branch names was sooo nice. I\u0026rsquo;ve also liked how Ivy handled completing file names. I feel faster. I\u0026rsquo;m not sure if I\u0026rsquo;m that much faster navigating around my file tree with it, but it does feel nice. There\u0026rsquo;s so much that Ivy makes better: any function using completing-read benefits from Ivy\u0026rsquo;s fuzzy matching.\nIt\u0026rsquo;s been a gradual process; there\u0026rsquo;s a lot that Helm does out-of-the-box that Ivy took some tweaking to get right. For example, sorting candidates for M-x by most recently used was one of my favorite features of Helm. I had to install Ivy Prescient to get the behavior I wanted. On top of that, I needed Counsel to show the key bindings next to their functions in M-x. Finally, I like to be able to fuzzy match anywhere within the command name, so I took out the leading ^ in counsel with this:\n(use-package counsel :config (ivy-configure \u0026#39;counsel-M-x :initial-input \u0026#34;\u0026#34;)) Conclusion # Both Helm and Ivy are fantastic packages. They\u0026rsquo;ve changed the way I use Emacs and I feel like they\u0026rsquo;ve made me substantially more productive and happy. If you haven\u0026rsquo;t used either, you might want to start off with Helm for a nice out-of-the-box experience with loads of features and sensible defaults. However, if you just would like to be able to fuzzy-match things, Ivy is your library. It\u0026rsquo;s fast, clean, and configurable. The only problem is that it sometimes requires configuration before it\u0026rsquo;s exactly how you like it.\n"},{"id":93,"href":"/posts/2019-02-27-macros-with-elixir/","title":"Macros with Elixir","section":"Technical Blog","content":"I gave a presentation at the Utah Elixir Meetup this February. Here\u0026rsquo;s the recording of my presentation:\nWatch on YouTube I\u0026rsquo;ve posted the slides as an HTML file, along with some materials to follow along with, on my GitHub account. Check it out!\n"},{"id":94,"href":"/posts/2019-02-06-citations-with-pandoc/","title":"Citations with Pandoc","section":"Technical Blog","content":"Today I figured out how to get Pandoc to automatically generate MLA citations for me!\nI used Pandoc and the Biblatex bibliography format. What\u0026rsquo;s nice about this is that you can enter in all the information you know about the source, keep it nice and organized in a file, and then change the citation style on the fly. Imagine if you thought you had to use MLA, but then realized you needed to switch to APA citation styles. You can do that instantly with Pandoc and Biblatex.\nFirst, you\u0026rsquo;ll need pandoc and pandoc-citeproc. (Instructions to install are on the Pandoc website. If you\u0026rsquo;re running macOS, you can use Homebrew to install with brew install pandoc and brew install pandoc-citeproc.)\nNext, create a bibliography file. Pandoc can work with many different formats, outlined in their documentation, but I\u0026rsquo;ll show an example with Biblatex, the bibliography database format used with LaTeX.\nExample markdown file:\n--- title: Irresponsible Encryption author: Ashton Wiersdorf date: \\today bibliography: research/refs.bib link-citations: true cls: Modern Language Association 8th edition --- Imagine a world where every phone call was tapped, where every purchase online could compromise your credit card, and where every one of your online accounts could be hacked. Imagine if every email you sent were scanned, analyzed, and the findings sold to the highest bidder. Imagine if your health, financial, and shopping records were public. That would be the end of our modern life as we know it. That is a real possiblity we are facing. (Especially if you use Gmail—Google has scanned the contents of emails in the past to serve targeted ads. [See @scroogled_blog]) Governments across the world—from the United States to Australia—are pushing or have passed legislation that mandates \u0026quot;exceptional access mechanisms\u0026quot;—means by which they can break encryption if they have a warrant to do so. They point to cases where criminals—from drug dealers to terrorists—have used encryption to conceal evidence against themselves. However, what they are asking for would have its consequences. \\pagebreak # References Note how I have bibliography: research/refs.bib at the top of the file. That lets Pandoc know where to go to find the biblography file. Then you can have a database file like this stored in research/refs.bib:\n@online{scroogled_blog, Annotation = {Ars Technica reports on this---the scary part is that Google was scanning emails in the first place.}, Author = {Diane Greene}, Crossref = {ars_scroogled}, Date = {2017-06-23}, Title = {As G Suite gains traction in the enterprise, G Suite's Gmail and consumer Gmail to more closely align}, Url = {https://blog.google/products/gmail/g-suite-gains-traction-in-the-enterprise-g-suites-gmail-and-consumer-gmail-to-more-closely-align/}, Urldate = {2019-02-05}, Bdsk-Url-1 = {https://blog.google/products/gmail/g-suite-gains-traction-in-the-enterprise-g-suites-gmail-and-consumer-gmail-to-more-closely-align/}} @online{ars_scroogled, Author = {Ron Amadeo}, Date = {2017-06-23}, Title = {Scroogled no more: Gmail won't scan e-mails for ads personalization}, Url = {https://arstechnica.com/gadgets/2017/06/gmail-will-no-longer-scan-e-mails-for-ad-personalization/}, Urldate = {2019-02-05}, Bdsk-Url-1 = {https://arstechnica.com/gadgets/2017/06/gmail-will-no-longer-scan-e-mails-for-ad-personalization/}} ... Each entry has a cite key: something that lets you refer to the citation from within your document. Note how in the markdown file I wrote [See @scroogled_blog]. That gets replaced with the following in the final product:\n…Google has scanned the contents of emails in the past to serve targeted ads. (See Greene 2017)…\nAnd at the end of the paper, I get a nice-looking citation like this:\nGreene, Diane. 2017. “As G Suite Gains Traction in the Enterprise, G Suite’s Gmail and Consumer Gmail to More Closely Align.” June 23, 2017. https://blog.google/products/gmail/g-suite-gains-traction-in-the-enterprise-g-suites-gmail-and-consumer-gmail-to-more-closely-align/.\nTo generate the finished product, I simply run pandoc --filter pandoc-citeproc paper.md -o paper.pdf. Poof! Nicely formatted and automatic citations!\nTo change the citation style, simply alter what is on the line starting with cls: in the header. You can find a list of valid styles here, with more information here. Good luck with your papers!\n"},{"id":95,"href":"/posts/2019-01-24-marked-man/","title":"Marked Man","section":"Technical Blog","content":"Marked Man (mm) is a little program I wrote to view Markdown files like UNIX man pages. (Because who wants to leave their terminal just to open a file?)\nIt uses Pandoc to convert between Markdown and the groff format. As a happy side-effect, this program can read basically anything as a man page: HTML, LaTeX, Word files (seriously), ePub, etc. Anything that Pandoc can read, Marked Man can handle.\nInstalling # I\u0026rsquo;m working on getting this set up with Homebrew. For now, check out my GitHub repository here.\n"},{"id":96,"href":"/posts/personal/2019-01-15-duckduckgo/","title":"DuckDuckGo","section":"Personal Blog","content":"DuckDuckGo is a search engine. Like Google Search, you just throw some keywords into a box and get a list of results. Lots of people use Google, but I don\u0026rsquo;t. DuckDuckGo works better for me, and this is why.\nThe Duck ## Consistent Results Did you know that Google will give you different search results, based on who you are and what you have searched for in the past? This is called a filter bubble, and it\u0026rsquo;s annoying and dangerous. DuckDuckGo doesn\u0026rsquo;t put you in a filter bubble.\nGoodies and Tools # Oh, man do I love the tools DuckDuckGo gives software developers. Here are just a few.\nSoftware Development # Need to find a color? Search \u0026ldquo;color picker\u0026rdquo;. A built-in color picker pops up. Want to know the HTML character entity for, say, the interrobang? (‽) Type \u0026ldquo;HTML entity ‽\u0026rdquo; Got some JSON that you need to prettify? Search \u0026ldquo;json validator\u0026rdquo; for a validator and beautifier. Searching Stack Overflow, Mozilla Developer Network, etc. with Bangs! (more later) Keybinding references for Emacs, Vim, Bash, etc. Emacs cheat sheet (expands to show more keystrokes) #### Entertainment Need to play 2048? Yes, just search \u0026ldquo;2048\u0026rdquo; and an in-browser game pops up. Today\u0026rsquo;s XKCD (search \u0026ldquo;xkcd\u0026rdquo;) Cheat sheets for Kerbal Space Program, Minecraft, League of Legends, etc. Bangs # Perform special operations by putting the appropriate !-sequence at the beginning of your search.\n!yt Search YouTube (\u0026quot;!yt glitter bomb package\u0026quot;) !a Search Amazon !w Search Wikipedia !mdn Search Mozilla Developer Network !unsplash Search Unsplash photos !img Search Google images—proxied for you so you can keep your privacy !ldss Search LDS Scriptures (just found this one 🤯 There are thousands. Literally.\nMisc. # Generate Lorem Ipsum filler text by searching \u0026ldquo;lorem ipsum\u0026rdquo; Check the weather with \u0026ldquo;weather \u0026lt;zipcode\u0026gt;/\u0026lt;city name\u0026gt;\u0026rdquo; Calculator with \u0026ldquo;calculator\u0026rdquo; Searching the weather For a full list of instant answers, see here.\nFor a full list of Bang-directives, see here.\nIt\u0026rsquo;s incredible. It\u0026rsquo;s simple. Perhaps best of all, ad-free! Well, they do display ads based on your search term for just that search. They don\u0026rsquo;t track you. The ads are not customized to you, rather they are customized to your search. They\u0026rsquo;re not intrusive either. I forgot they were there until I was typing this. 😄\nBut seriously. DuckDuckGo is amazing. Give it a try.\nYou can even enable it as your default search engine on iOS. Go to Settings \u0026gt; Safari \u0026gt; Search Engine and select DuckDuckGo. You can set it as well in Safari on desktop, as well as Firefox. (I don\u0026rsquo;t use Chrome or Edge, though I imagine they\u0026rsquo;d let you do the same. Comment below if you find anything out.\n"},{"id":97,"href":"/posts/personal/2019-01-05-organization-theory/","title":"Organization Theory","section":"Personal Blog","content":"Life is messy. We devote a lot of time and effort into managing that chaos. I thought of a little \u0026ldquo;theory\u0026rdquo;, if you will, that helps me.\nThe Home Theory # Everything needs a home. The class of things that need homes is broad. It includes:\nSchool assignments Legal documents Pictures Recipes Ideas Projects Books Charging cables Tools etc. The home needs to suit the thing that goes there. I have found that getting this right is really tricky. But once you have a home for a thing, you never loose it. You will want to put things back into their homes when you are done using it, because it will feel right. If the home doesn\u0026rsquo;t fit the item, you run into a bit of friction—that slows you down and makes you more likely to put the thing where it\u0026rsquo;s easy.\nOne thing that stood out to me from Zen and the Art of Motorcycle Maintenance was the author\u0026rsquo;s discussion about tools. Regarding tool organization:\nOne of the first warning signs of impatience is frustration at not being able to lay your hand on the tool you need right away. If you just stop and put tools away neatly you will both find the tool and also scale down your impatience without wasting time or endangering the work. (pp. 286)\nI mentioned this a bit when I talked about text editors, but this holds true for more things than physical or software tools. Consider a home for finances: if you have a budgeting program you always use, then it\u0026rsquo;s much easier to keep track of your finances because records of transactions have a home to go to.\nThe investment of time is worth it.\nSymptoms of No Home # I once didn\u0026rsquo;t have a home for a while. I mean, I lived in a house and was provided with more than adequate food, shelter, clothing, etc. However, I didn\u0026rsquo;t have a room. We were renovating our basement to make more space, and until that was complete, I slept on an air mattress.\nThe air mattress was no problem. I was young enough that it didn\u0026rsquo;t hurt my back. (I can\u0026rsquo;t believe that I\u0026rsquo;m suddenly \u0026ldquo;old\u0026rdquo; and reposing on a mattress hurts my back!) The biggest struggle for me is that I didn\u0026rsquo;t have a home for my stuff, and I didn\u0026rsquo;t have a place where I could go to be quiet.\nI\u0026rsquo;m quite introverted. That means after spending time with people, I need quiet time to relax and recharge. I didn\u0026rsquo;t get that. The barrage of noise I experience in that time made it difficult for me at times.\nI\u0026rsquo;m grateful that I have a home now. It\u0026rsquo;s important. It\u0026rsquo;s important for things and people to have a home.\n"},{"id":98,"href":"/posts/2018-12-14-semester-finished/","title":"Semester Finished","section":"Technical Blog","content":"I finished the semester! This is how I feel:\nDon\u0026rsquo;t you?\nWell, I still have finals. But those are easy compared to the projects I\u0026rsquo;ve had to push out. I\u0026rsquo;ll probably write about my escapades later. :)\n"},{"id":99,"href":"/posts/2018-12-06-editor-apology/","title":"Editors, or The Tools of my Trade","section":"Technical Blog","content":"I spend a fair portion of every day writing programs. As with all professions, using the right tools makes a huge difference in my productivity and general happiness. Having good tools helps me keep my gumption up.\nOne of my favorite books is Zen and the Art of Motorcycle Maintenance. Contrary to what the title suggests, this book is actually not about motorcycles. It’s about a lot of things; one topic is about tools and caring about your trade.\n… By far the most frustrating gumption trap is inadequate tools. Nothing’s quite so demoralizing as a tool hang-up. Buy good tools as you can afford them and you’ll never regret it.‌‌(ibid. p.g. 291)\nFor me, my most important tool is my text editor: manipulating source code is what I spend ALL DAY doing. I’ve selected Emacs as my primary text editor.\nLots of programmers use what’s called an IDE If programming were cooking, then an IDE would be a knife that has a sink, a strainer, and a toaster-oven built into it.\nI find IDE’s visually distracting. Everything is done with buttons that you click. Emacs has so much more screen devoted to content.\nEmacs and Vim do have steeper learning curves. This is in part because the absence buttons make the features only discoverable via manuals. When working with an IDE, the presense of buttons hints at the existence of certain features.\nI find it a shame when people don\u0026rsquo;t read, prefering a video tutorial or the like. Emacs’s features are very discoverable, but not in the way most people are used to. The apropos-function command is terribly useful—if you think a certain command should exist, searching all available function names for a particular string has helped me find both what I\u0026rsquo;ve gone looking for, and what I didn\u0026rsquo;t know I wanted!\nThe advantage to using keyboard only navigation is that hundreds of commands are immediately available all the time, without having to dig through menus or such. It takes me the same amount of time to access complicated commands as it does moving around a file.\nAgain, from Zen and the Art of Motorcycle Maintenance:\n…One of the first warning signs of impatience is frustration at not being able to lay your hand on the tool you need right away.‌‌(ibid. p.g. 286)\nMoving a mouse takes me out of my flow, which slows me down and leads to gumption traps. If something takes longer, I\u0026rsquo;m more reluctant to do it. That means my productivity drops.\nNow, you might have used a word processor for text editing all your life. Or perhaps you\u0026rsquo;re comfortable with your IDE. I encourage you to stretch beyond what you\u0026rsquo;re comfortable with, and learn Emacs. An investment in a powerful text editor will change how you consider how you program. Editing will become more fluid, and the barrier of buttons and menus will fade away.\nLearning Emacs # There is an index of learning resources here. If you\u0026rsquo;re just looking for a cheat sheet, check this link out. Also, see my cheat sheet. (I update this one occasionally.)\nIf you\u0026rsquo;re coming from an IDE and miss feature X, you might be able to find the corresponding Emacs feature here.\nPicture Credit # I found this via a Google Image search; the origional file came from this blog post, which I think resonates with mine quite well.\n"},{"id":100,"href":"/posts/2018-10-08-induction-and-side-effects/","title":"Induction and Side-Effects","section":"Technical Blog","content":"Today in my proofs class (MATH 290 at BYU) we talked about the concept induction. I like this, because it sounds a lot like recursion.\nOn the Wikipedia article, there\u0026rsquo;s an excerpt from a book that illustrates the principle with an analogy using a ladder:\nMathematical induction proves that we can climb as high as we like on a ladder, by proving that we can climb onto the bottom rung (the basis) and that from each rung we can climb up to the next one (the step). — Concrete Mathematics, page 3 margins\nThe problem with this, however, is that climbing a ladder has side-effects! Namely, when you climb up a step, you get tired. Eventually, there comes a point where you get so tired that you collapse from exhaustion, fall off the ladder and smack into the hard, uncaring ground of reality below.\nThis will happen to you too if your recursive functions have side effects: you code will be really hard to debug, and eventually, a bug somewhere in the state of your system will deftly shove your process off the call stack to crash on the cold, hard, uncaring silicon below.\nPhoto by Robin Joshua on Unsplash\n"},{"id":101,"href":"/posts/2018-08-11-life-hacks-text-notifications/","title":"Life Hacks: Text Notifications","section":"Technical Blog","content":" Life Hacks: Text Notifications # So many notifications come to us in the form of an audible alert, and this can sometimes be inconvenient. Who likes having their phone go off in church? The problem is that sound propagates regardless of the intended target. Touch, on the other hand, is an inherently personal sensation. Setting your phone to vibrate lets you know you\u0026rsquo;re being alerted, without notifying everyone else in the room as well.\nUnless you read Braille, touch has far less bandwidth than sound. However, you can pack a small amount of information into a vibration, like who\u0026rsquo;s calling or texting you. There\u0026rsquo;s a sweet feature on iPhones that lets you set custom vibration patterns for your contacts. Here\u0026rsquo;s how to set it up:\nGo to your \u0026ldquo;Contacts\u0026rdquo; app. I\u0026rsquo;ve got a version of my personal contact card that I AirDrop to people when they want my contact information. I\u0026rsquo;ll use that to demonstrate.\nHit Edit in the top right corner, then scroll down until you see Text Tone. Click on that.\nYou\u0026rsquo;ll see a bunch of options where you can set a custom ringtone for that person. You can also set a custom vibration pattern. Right now, mine is set to \u0026ldquo;Default\u0026rdquo;. Go ahead an click on that.\nThere are a bunch of standard patterns you can choose from. You can also create some custom ones! I have a lot of custom vibrations:\nDown at the very bottom of the list is an option to create a new one. Tapping on that will give you a screen like this:\nThis is what setting a new vibration pattern looks like:\nI encode the initials of my most frequent contacts in Morse Code. It lets me know who\u0026rsquo;s texting me without having to take my phone out of my pocket. It helps me know if I should answer immediately, or if the conversation can wait for a minute or two. It took me a week or two to be able to distinguish between the texts, but now I can recognize who is texting or calling me immediately!\nDoes anyone know if Android supports the same? Let me know, and I\u0026rsquo;ll post about that here.\nNote to people from Facebook: I won\u0026rsquo;t know if you tell me via one of the contact methods I talked about here.\n"},{"id":102,"href":"/posts/personal/2018-06-23-leaving-facebook/","title":"Leaving Facebook","section":"Personal Blog","content":"Deutsche Übersetzung folgt.\nI\u0026rsquo;ve left* Facebook.\nThere\u0026rsquo;s an asterisk there. I\u0026rsquo;m not going to delete my account, but I\u0026rsquo;m no longer checking Facebook more than once or twice a month, if that. I\u0026rsquo;m not trying to be a recluse—below are a few ways to contact me that I do check far more often than Facebook. I want to be your friend, but I\u0026rsquo;d rather that friendship be through a real connection rather than some online \u0026ldquo;status\u0026rdquo;.\nWhy I\u0026rsquo;m Leaving # First of all, I care deeply about my online privacy. I\u0026rsquo;m not perfect, but I try to keep myself free from trackers so I can decide what I see online instead of aggregators like Facebook and Google. Facebook is out to get you and your contact information. I don\u0026rsquo;t like it.\nSecondly, I don\u0026rsquo;t like Facebook\u0026rsquo;s closed model of the Internet—they make it so search engines can\u0026rsquo;t find even public Facebook posts. Their model not what I want for anything I choose to share with the world—this blog is much better. Additionally, with my blog, I have a much richer medium for publishing my thoughts and writing.\nFinally, I don\u0026rsquo;t think Facebook merits a daily scroll-through. The information that I care about I find in other news sources and online in manuals. For entertainment, I usually read books or play a game on my phone. Reading about the minutia of people\u0026rsquo;s lives is not interesting to me.\nThat being said…\nI\u0026rsquo;m still keeping my account # Why? Because all you guys use it, and I want to know when you get married, have a baby, when there\u0026rsquo;s a mission reunion, etc. I would really prefer to learn about these things via some other medium, but until we all migrate to Keybase or something, I\u0026rsquo;m going to keep one eye on what my friends like to publish on Facebook. Even then, I\u0026rsquo;ll still likely miss many things. ¯\\_(ツ)_/¯\nI\u0026rsquo;ll also link to my blog posts. There\u0026rsquo;s stuff I\u0026rsquo;d like to share with you guys, and this is the way I\u0026rsquo;d like to do it. It gives me a richer medium to communicate. Furthermore, writing a blog post is more arduous than writing something on Facebook—if I write something, it means I will have found it sufficiently important to spend some time on.\nHow to contact me # A few options to contact me:\nEmail—my first name dot then my last name at mailblock dot net.1 That\u0026rsquo;s probably the easiest. Keybase—it\u0026rsquo;s a free messaging/file sharing app. My Keybase ID is ashton314. I prefer this method: it\u0026rsquo;s secure and private. GitHub—really only if it\u0026rsquo;s about code. Friends—find someone who has my number and ask them for it. Please don\u0026rsquo;t send it over Facebook Messenger, though. Conclusion # I\u0026rsquo;ve already been pretty sparing in my Facebook interactions. This post is just to let you know why I might have missed an announcement or two. :) It\u0026rsquo;s nothing personal—I\u0026rsquo;m just not on Facebook very often.\nDeutsch # Ich habe Facebook verlassen.*\nEs gibt noch einige Bedingungen, aber! Ich werde zwar meine Konto nicht löschen, aber ich gehe auf Facebook ziemlich selten—höchstens ein oder zwei Mal im Monat. Ich bin kein Einsiedler; ich will einfach ich auf eine persönlicher Ebene ein Freund sein. Mir ist es Egal ob wir ins Internet als \u0026ldquo;Freunden\u0026rdquo; bezeichnet werden.\nWarum ich Facebook verlasse # Erstens, mir ist meine Privatsphäre sehr wichtig. Ich will es nicht, dass Facebook meine Taten ins Internet folgt. Ich habe zwar nichts zu verbergen. Das heißt aber nicht, dass Facebook meine jegliche Tat wissen soll.\nZweitens, ich mag wie Facebook das Internet verwendet gar nicht. Wenn ich etwas auf Facebook schreibe, können Such-machine es nicht finden. Wenn ich ein Link zu etwas erstellen will, macht Facebook das unsicher. Es kann sein, dass wenn jemand etwas postet, kann ich es sehen, aber du nicht.\nZum Schluss, ich glaube es nicht, dass ich täglich auf Facebook gehen soll. Mir ist es wichtiger andere Sachen zu lesen, statt dass, was Facebook mir gibt.\nJedoch…\nIch lösche mein Konto nicht. # Der Grund dafür ist einfach: ihr seid alle noch auf Facebook. Ich freue mich wann ich von ihre schöne Lebenserfahrungen höre. Ich möchte es wissen, wann ihr heiraten, ein Baby bekommen, wenn es ein Missionstreffen gibt, usw. Ich höre es liber durch ein anderes Mittel als Facebook, aber bis wir alle auf Keybase sind, werde ich noch ein Facebook Konto behalten. Ich werde aber viele Dinge verpassen. Bitte wissen, dass es nicht persönlich gemeint ist: wir sind noch Freunden, ich gehe einfach ganz ganz selten auf Facebook.\nWie man mich kontaktieren kann # Es gibt einige Möglichkeiten:\nEmail—mein erster Name Punkt mein letzter Name at mailblock Punkt net.2 Das ist wahrscheinlich am einfachsten. Keybase—es ist eine Kostenlose Nachricht und Filesharing App. Mein Keybase ID ist ashton314. Mir ist diese Methode am besten: es ist sicher und privat. GitHub—wirklich ist das nur wenn es um Code geht. Friends—find einfach jemand, der mein Handynummer schon hat. Zum Schluß # Ich bin schon ganz selten bei Facebook. Ich hoffe, dass ihr es versteht, dass wenn ich vielleicht etwas wichtiges verpasst habe, war es gar nicht persönlich gemeint—ich bin halt fast niemals auf Facebook.\nPhoto Credits: # unsplash-logoThought Catalog\nI\u0026rsquo;m not writing that in normal form because I don\u0026rsquo;t want a web scraper to find it and spam me. Yuck. I like it when search engines find my blog posts. I don\u0026rsquo;t like it when they find my email address.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIch hab mein Emailaddresse so geschrieben, damit ich kein Spam bekommen werde. Ich mag es, wenn das Internet mein Post sieht. Ich mag es nicht, wenn schlechte Programmen mein Emailaddresse finden.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":103,"href":"/posts/2017-11-18-drafting/","title":"Drafting","section":"Technical Blog","content":"I once asked my dad over email how to improve my the potency of my words and thoughts. His reply came back as one word:\nRevision.\nGood writing does not emerge spontaneously; it comes as one practices writing. A \u0026ldquo;draft\u0026rdquo; is a pass of writing a particular work. It\u0026rsquo;s like sketching in art: when an artist starts a painting, they usually start with a rough sketch outlining where the ﬁgures will be, what the landscape will be like, etc. These sketches are composed of many lines: each coming closer to their ﬁnal position.\nWhen I draft, I start out with a few different freewrites. I usually start with a stream of consciousness to get my ideas out on paper and to sort of flesh out what I actually want to talk about. Then I will beat out a very rough draft. After this initial draft, I usually will have a good idea of how I want to treat the subject matter. I will do things like read my paper aloud to hear how it flows, check for grammatical inconsistencies, look for more concise phrases that convey my ideas more clearly. Occasionally I will decide that I need to change how I structure my argument entirely. In these situations I will often do a complete rewrite.\nI usually use something akin to semantic versioning—the first version number of my draft indicates the major write of the paper, (e.g. 0.0.1 for the rough draft, 1.0.0 for the first full draft after the rough draft, 2.0.0 for the next full rewrite, etc.) the second number might indicate significant changes in the text, but not complete structural changes, and the third number indicates minor changes, such as spelling and grammar errors.\nI don\u0026rsquo;t follow this system too rigorously; it\u0026rsquo;s just a kind of fun thing I use to keep track of my drafts. My brain is messy some times, and I\u0026rsquo;m okay with that.\n"},{"id":104,"href":"/posts/2017-11-09-quick-website-programming-with-mojolicious-and-polymer/","title":"Rapid Website Development with Mojolicious and Polymer","section":"Technical Blog","content":"My girlfriend works for BYU SA—it\u0026rsquo;s the division of BYU that\u0026rsquo;s responsible for planning and running events. As part of her job, she has to review song lyrics and make sure that the song is okay to play at BYU functions.\nThis can get rather irksome. Imagine reading text looking for vulgar words or phrases. Yuck. I took some time this evening to write a little website that checks MetroLyrics for any vulgar words or phrases. I have an extensible blacklist which gets initialized at server start by some phrases from FrontGate.\nI coded this up with Mojolicious and Polymer Web Components. Polymer might have been a little overkill, but it saved me from writing lots of boring jQuery to set variable.\nHere\u0026rsquo;s what the site looks like:\nYou can look at the code for the repository here.\nThis all took about 3 hours, the last of which was spent mostly getting some of the finer points of the user interface to work.\nI\u0026rsquo;d be happy to get some contributions to my project, if anyone is feeling a little bored. ;-) Some more robust song searching would be nice, as well as better heuristics for bad phrases and whatnot.\n"},{"id":105,"href":"/posts/2017-10-26-eh-blog-we-have-a-problem-here/","title":"Eh, Docker, we have a problem here…","section":"Technical Blog","content":"Quick note for those who don\u0026rsquo;t know about Docker: Docker is a program that lets me take packaged-up programs (called images or containers) and run them without having to worry much about dependencies.\nToday I decided to upgrade my version of Ghost Blog. I\u0026rsquo;m using the Docker image on a Digital Ocean droplet. Updating should be simple, I thought. I would take down the blog then spin it back up again after pulling down the latest Docker image. I ran docker stop ghost-blog, removed the container with docker rm ghost-blog then ran docker pull ghost:latest. The container came down without a problem.\nThen the trouble began.\nI tried restarting the image:\ndocker run -d --name ghost-blog -p 80:2368 -v /home/ghost/blog-data:/var/lib/ghost/content ghost But when I ran docker ps, no docker containers were running. I tried looking at the log of the ghost-blog container and was greeted with this message:\ntar: /var/lib/ghost/content.orig: Cannot open: No such file or directory tar: Error is not recoverable: exiting now tar: This does not look like a tar archive tar: Exiting with failure status due to previous errors Hhmmm… I tried creating /var/lib/ghost/content.orig, but that didn\u0026rsquo;t help. I then copied my blog-data/ folder, blew the old folder away, then tried running again, but to no avail.\nI was out of ideas, so I decided to inquire at the great oracle of DuckDuckGo. The first result was this lovely issue on GitHub that covered exactly the problem I was facing.\nI created the directory specified and was able to fire up the docker container without a problem. I think I must have made an incompatible upgrade. ¯_(ツ)_/¯\nBackup Woes # Running around as the root user of a system is always dangerous. I was painfully reminded of that today when I accidentally deleted my backup folder instead of moving its contents to the original location. 🤦🏻‍♂️Oops.\nFortunately, I had made another backup of all my content saved as a JSON file on my laptop. I fired up the docker container, opened to the website in a web browser, and imported all my old files. Day saved. 😌\nUnfortunately I lost all my configurations. Not that there was a lot, but I did loose the Disqus integration as well as some settings for me as an administrator. Alas. I\u0026rsquo;ll fix the comments sometime later. Probably after midterms…\nSo, lessons: make backups. Then don\u0026rsquo;t delete the backups.\nI am enjoying the Ghost blog. It\u0026rsquo;s pretty minimal and doesn\u0026rsquo;t get in my way. I just wish I had been a little more careful today.\n"},{"id":106,"href":"/posts/2017-09-23-emacs-tips-and-tricks/","title":"Emacs Tips and Tricks","section":"Technical Blog","content":" Emacs Tips and Tricks # To Learn About # ☒ Company-mode (completion framework for lots of stuff) ☒ YASnippets (templates) ☒ Auto-YASnippets (something like that—I installed it for temporary templates) ☒ Alchemist mode (integrates with company mode—tooling for Elixir) ☐ What do M-. and M-, do? ☐ font-lock-add-keywords would let me add new keywords to a language ☐ hi-lock ☐ highlight-phrase, unhighlight-regex ☒ Registers ☐ Auto-loading packages to make startup time shorter Things that make me happy # Undo in region (just highlight something and hit undo) Generate Backus-Nauer Forms with a slightly modified syntax with ebnf-eps-buffer Helm # You can filter buffers by pattern with Helm. Type: @pattern to find buffers matching pattern. If you want to have spaces in the pattern, you must escape them with a backslash.\nSearching with the Silver Searcher # You’ll need helm-ag. After searching, you get the following keybindings:\nKey Bindings # Key Action C-c o Open other window C-l Search in parent directory C-c C-e Switch to edit mode C-x C-s Save ag results to buffer(Ask save buffer name if prefix key is specified) C-c C-f Enable helm-follow-mode C-c \u0026gt;, right Move to next file C-c \u0026lt;, left Move to previous file C-c ? Show help message Edit mode keymap # Key Action C-c C-c Commit changes C-c C-k Abort C-c C-d Mark delete line C-c C-u Unmark Saved buffer keymap # Key Action RET Jump to current line posion C-o Jump to current line posion in other window g Update result Registers # Any letter can be a register. (Uppercase and lowercase are distinct.) In the follinwg examples, \u0026lt;r\u0026gt; represents a register name.\nWorking with the point:\nC-x r SPC \u0026lt;r\u0026gt; Store point in register (mnemonic: C-SPC saves current mark) C-x r j \u0026lt;r\u0026gt; Jump to point saved in register (mnemonic: jump) Working with text:\nC-x r s \u0026lt;r\u0026gt; Save region into register C-x r i \u0026lt;r\u0026gt; Insert contents of register (also works for numbers) Working with numbers:\nC-u NUMBER C-x r n \u0026lt;r\u0026gt; Save a number C-u NUMBER C-x r + \u0026lt;r\u0026gt; Increment register \u0026lt;r\u0026gt; by NUMBER (if C-u NUMBER omitted, increments by 1) Other:\nC-x C-k r \u0026lt;r\u0026gt; Save last kbd macro to register Special Modes # Racket # Start everything off right with M-x run-geiser RET racket RET.\nC-c C-d TAB Open up documentation for command under point Calc # TAB rotate Web Mode # I do a fair amount of web programming. web-mode is awesome! There are way too many keystrokes for me to list. Here are my favorite, though:\nC-c C-e / Close element. (Mnemonic: C-element / (for closing HTML tags))\nC-c C-f Fold. Collapses current tag and subtree. Same keystroke to unfold.\nMarkdown Mode # C-c C-] Complete markup of element. (e.g. sticks “###” at the end of a line on a h3 element\nTAB When called on a heading, collapses/expands the heading.\nShift-TAB Cycles global folding/visibility\nText keys: (all start with C-c C-s)\nC-c C-s s Make current word/region bold (s is for strong)\nC-c C-s e Italics. (e for emphasis)\nBookmarks # I installed the bm module. Run bm-toggle to book mark a line visually. Native bookmarks:\nC-x r m New bookmark. Prompts for a name. Mnemonic: “mark”\nC-x r b Jump to a bookmark. Mnemonic: “bookmark”, or “back to bookmark”\nC-x r l List bookmarks.\nJumping to a bookmark will do so in the current window, and will put you where the point last was in that buffer. If you are already in the buffer, then it will jump to the point where to bookmark was set.\nBookmarks persist over a session—I’m not sure where the file is, but they do get stored in some file.\nExpansion # M-/ will do “dynamic expansion”—if there is a word in one of the buffers of the current session that starts with whatever your cursor is on, it will expand to that word. Multiple consecutive invocations of this function will cycle through available expansions.\nThere’s a way to do manual expansion, but I don’t know it.\nWindow enlargements # I’ve defined a few nice functions. Here they are:\n(defun sticky-enlarge-window-horizontally (prefix) (interactive \u0026quot;P\u0026quot;) (enlarge-window-horizontally (if prefix (car prefix) 1)) (unless (current-message) (message \u0026quot;(Use `[' and `]' to adjust window size)\u0026quot;)) (let ((map (make-sparse-keymap))) (define-key map (kbd \u0026quot;]\u0026quot;) 'enlarge-window-horizontally) (define-key map (kbd \u0026quot;[\u0026quot;) 'shrink-window-horizontally) (set-transient-map map t))) (defun sticky-shrink-window-horizontally (prefix) (interactive \u0026quot;P\u0026quot;) (shrink-window-horizontally (if prefix (car prefix) 1)) (unless (current-message) (message \u0026quot;(Use `[' and `]' to adjust window size)\u0026quot;)) (let ((map (make-sparse-keymap))) (define-key map (kbd \u0026quot;]\u0026quot;) 'enlarge-window-horizontally) (define-key map (kbd \u0026quot;[\u0026quot;) 'shrink-window-horizontally) (set-transient-map map t))) (define-key global-map (kbd \u0026quot;C-x }\u0026quot;) 'sticky-enlarge-window-horizontally) (define-key global-map (kbd \u0026quot;C-x {\u0026quot;) 'sticky-shrink-window-horizontally) (define-key global-map (kbd \u0026quot;\u0026lt;f7\u0026gt;\u0026quot;) 'shrink-window-horizontally) (define-key global-map (kbd \u0026quot;\u0026lt;f8\u0026gt;\u0026quot;) 'balance-windows) (define-key global-map (kbd \u0026quot;\u0026lt;f9\u0026gt;\u0026quot;) 'enlarge-window-horizontally) Functions # toggle-truncate-lines will toggle how long lines are displayed\nC-x C-d is essentially ls — lists the contents of a directory\nC-u M-| pipe region to a shell command and replace it with the output\nYou can get sweet sed-like behavior with something like this:\nperl -ne 's/^(\\d+)\\.(\\d+)/\u0026lt;\u0026lt;1 Thes. $1:$2\u0026gt;\u0026gt;/g; print' Macro wisdom # Put cursor where it is supposed to go, begin recording (C-x (), do thingy, isearch to next location, and then stop recording. (C-x )) This lets you see what is going to be edited next, and hit C-s C-s if you want to skip to the next match.\n\u0026lt;f3\u0026gt; Is a very fancy key. Normally, it will begin recording a macro. Once you are defining a macro, hitting \u0026lt;f3\u0026gt; again will insert the current macro counter.\n\u0026lt;f4\u0026gt; is its best friend. Hitting \u0026lt;f4\u0026gt; while defining a macro will end the macro. Hitting \u0026lt;f4\u0026gt; otherwise will then run the last defined keyboard macro. Running C-u \u0026lt;f4\u0026gt; runs the second macro in macro ring. Running C-u 4 \u0026lt;f4\u0026gt; runs the first macro 4 times. (Adjust 4 as you will.)\nYou can use Lisp inside of a macro. For example, to insert incrementing numbers, do:\nM-: (setq x 1) RET C-( C-u M-: x RET M-: (setq x (+ x 1)) \u0026lt;whatever else\u0026gt; C-) You can repeat a macro until an error is signaled with C-u 0 C-x e.\nYou can also run apply-macro-to-region-lines (C-x C-k r) to fire a macro on every line in the region.\nTo prompt a user for input while writing a macro, do: C-u C-x q. This is a variant of C-x q which queries the user.\nRecursive editing # Hitting C-r will enter a recursive editing level when the macro is run, but not while you are recording.\nC-x q enters a query state: y continues to execute the macro, n aborts the current iteration, and q aborts all together.\nC-u C-x q lets you enter in some text.\nTo finish recursive editing, type C-M-c. To abort and halt execution, type C-].\nRectangles # To select text in a rectangle, use C-x SPC. The region will then highlight like a rectangle. The kill and yank commands will work like normal (i.e. hitting C-k will kill the rectangle.)\nC-x r M-w Copy rectangle as kill. (Think M-w)\nC-x r N Inserts numbered lines in the rectangle. Accepts a prefix argument to change at what number the lines start at.\nM-x string-insert-rectangle Prompts for a string and inserts it at the current rectangle. So you can go from this:\none two three four to this:\n- one - two - three - four by setting the mark on the o of one, then moving to the f in four, then running the command.\nMisc. Keystrokes # C-x \u0026lt;right arrow\u0026gt; cycle through buffers\nC-x C-q toggle read-only mode in current buffer\nC-x C-; to set comment column to cursor’s current column\nC-x C-h Really \u0026lt;any prefix\u0026gt; C-h shows a listing of all possible completions after the prefix character.\nC-x 8 RET Insert arbitary unicode character by name. You can insert snowmen like this!\nC-x 8 \u0026lt;char\u0026gt; There are a bunch of characters that you can insert after this. “\u0026lt;” will insert “«”\nC-x n n Only displays the region. Good for focusing. Use C-x n w to display everything.\nC-x $ To hide lines in the current buffer, type ‘C-x $’ (‘set-selective-display’) with a numeric argument N. Then lines with at least N columns of indentation disappear from the screen.\nC-u Prefix argument. The default is 4. If you want to grow the current window by, say, 15 lines, do following: C-u 15 C-x ^.\nC-u \u0026lt;number\u0026gt; \u0026lt;key\u0026gt; Repeats \u0026lt;key\u0026gt; \u0026lt;number\u0026gt; times. It’s different for inserting digits. If you wanted to insert 5 seven times, type C-u 7 C-u 5.\nC-x C-k C-i Inserts the current value of the keyboard macro counter and increments it. When C-u proceeds the command, the previous value is inserted, and the counter is not updated. A prefix argument specifies a different increment.\nC-x C-k C-c Prompts for the initial value of the keyboard macro. Must be called prior to starting macro definition to be used this way. It has another behavior if called during macro definition. See this page for help.\nC-x C-k n Give the last kbd macro a name, which you can then call\nESC-^ Join this line to the previous and fix up whitespace at join. Useful if auto-fill-mode was turned on and you need to unwrap a line.\n\u0026lt;f1\u0026gt; Run help\n\u0026lt;f2\u0026gt; Appears to be a prefix command, much like C-x.\n\u0026lt;f10\u0026gt; Opens the menu. As in, the one at the top of the screen that you never have actually used. With ACTUAL GRAPHICS!!\nC-x RET f Allows you to set the encoding when saving the file. Useful for stripping bad line endings in DOS files.\nDired # C-o In dired, opens the file the cursor is on in the other window. Occur # C-u M-s o \u0026lt;pattern\u0026gt; RET Copies all strings mattching \u0026lt;pattern\u0026gt; (if you use .*thingy.* it will copy the whole line with “thingy” in it) into buffer called *Occur* ### Regexes Not like Perl. In (?:aaa|bbb), the characters (, ), and | all match themselves. If you want perl-like behavior, escape them: \\(?:aaa\\|bbb\\).\nBut when you want to type that in a string literal, use \u0026quot;\\\\(?:aaa\\\\|bbb\\\\)\u0026quot;.\nCharacter Classes # Some common character classes:\n. works as expected (any char) [[:ascii:]]+ any ascii character [_A-Za-z0-9]+ letters, digits, underscores \u0026quot;\\([^\u0026quot;]+\\)\u0026quot; capture text between double quotes (not accounting for escaped chars) Regex search and replace: # M-x replace-regexp Replace regexp: right\\|left Replace regexp with: \\,(if (equal \u0026quot;right\u0026quot; \\\u0026amp;amp;) \u0026quot;left\u0026quot; \u0026quot;right\u0026quot;) Looks like the \\,(...) syntax says “evaluate me”. :)\nRegex search and replace with captured bit # M-x replace-regexp Replace regexp: subject(\\([A-Za-z]+\\)) Replace regexp with: \\1 That gets subject(*), and retuns *\nProgramming Languages # C # Compile (using make -k) with M-x compile.\nAny errors will show up in a special buffer; visit with C-x `\n"},{"id":107,"href":"/posts/2020-11-making-emacs-packages/","title":"A Beginner's Guide to Making Emacs Packages: from mkdir to MELPA","section":"Technical Blog","content":"DISCLAIMER: I am by no means a wizard at Emacs Lisp development. I will do my best to ensure that the advice and instructions here are as accurate as possible, but bear in mind that I\u0026rsquo;m kind of figuring this out as I go along. NO WARRANTY!\nI wrote this as I developed my very first Emacs package. This will guide you through what I found to be the bare minimum necessary in crafting a minor-mode for Emacs.\nThis guide assumes you are already familiar with using Emacs and programming in Lisp—any dialect will be fine. Emacs Lisp has some quirks you won\u0026rsquo;t see in many other flavors of Lisp (most notably the presence of dynamic scoping, though we\u0026rsquo;ll use lexical scoping in this guide as it\u0026rsquo;s required to submit stuff to MELPA). It also assumes you have a GitHub account and know how to use Git and the command line.\nGetting Started # Submitting to MELPA # Further Reading # "},{"id":108,"href":"/docs/about/","title":"About","section":"Docs","content":" About Me # I\u0026rsquo;m Ashton Wiersdorf, and I\u0026rsquo;m a PhD student at the University of Utah studying programming languages with Ben Greenman. I live in Salt Lake City, Utah.\nMy most recent place of employment outside of academia was with Spiff, where they were nice enough to let me hack on their interpreter. Before Spiff I worked at a few other positions as a full-stack engineer.\nI\u0026rsquo;ve sung with the BYU Men\u0026rsquo;s Chorus and I play the piano. Other hobbies include swimming and hiking\u0026mdash;Utah has some of the most diverse landscape anywhere in the US: from dense forests to barren desert. If you visit, I highly recommend checking out some of the national parks.\nI have been married to my wife Sarah since 2018; we met when we were in high school and she\u0026rsquo;s been my best friend ever since. You can see her blog here. We became parents in the summer of 2021 and couldn\u0026rsquo;t be happier!\nI served a two-year mission for the Church of Jesus Christ of Latter-day Saints in Germany. Consequently, I speak fluent German and have a great appetite for German food. My wife and I were able to visit Berlin for a few months in 2019. If you\u0026rsquo;re interested in visiting Europe, Berlin is a must.\nThis blog is primarily where I\u0026rsquo;ll post about research, school, and programming. I\u0026rsquo;m studying programming languages, though my interests are not strictly constrained to any one field. I like literature and philosophy, so there will be the occasional book review that I\u0026rsquo;ll post under my personal section. I change my mind a lot; I\u0026rsquo;m still learning, so things written here should not be understood as an immutable reflection of my opinions.\nColophon # This blog is built by Hugo, and the theme is a modified version of hugo-book. The body font is Valkyrie, the headings are Concourse, and the monospace font is Iosevka Output. This blog is hosted on GitHub Pages.\nFor analytics I use Goat Counter which doesn\u0026rsquo;t track any personal data. It\u0026rsquo;s basically just a way for me to see what\u0026rsquo;s popular and what\u0026rsquo;s not.\nI write my blog in Emacs. I use ox-hugo to export from org-mode to Hugo-friendly Markdown. I used to use Hugo\u0026rsquo;s built-in org-mode handler, but it messed things up like apostrophes and didn\u0026rsquo;t handle some other formatting as I wanted it to. The ox-hugo library does a much better job.\nThis is the third iteration of my blog style. Previously I\u0026rsquo;ve run blogs with Ghost and Jekyll. I moved to Jekyll from Ghost because I wanted a lighter-weight static site, and I moved from Jekyll to Hugo for the lovely themes and some of the more advanced capabilities it offers.\n"},{"id":109,"href":"/posts/2021_user_friendly_foss/","title":"Emacs and Why We Need More User-Friendly Free Software","section":"Technical Blog","content":"I made an Emacs setup that I built for my wife. She\u0026rsquo;s a writer, no a programmer, so I tried to make things as simple as possible.\nI think a lot of people in tech (myself included) suffer from the same case of tool-frenzy: we like building powerful tools for us to use so we can make more powerful tools. There\u0026rsquo;s nothing inherently wrong with this; it does solve some problems and it does help some people.\nBut the point of the Free Software Foundation is to make free software more prevelant. How can we do that if we don\u0026rsquo;t meet users where they are?\nI\u0026rsquo;m not advocating that we should stop our focus on the power-user tools—no, it is essential that we maintain our focus on making good CLI interfaces, not nerfing our OS, etc. But what we can do is make it so that more people feel comfortable getting started with some software.\nAs an example to maybe help you build some empathy: consider taxes. I\u0026rsquo;m not an expert at the US tax code, but I do have to pay taxes. So, I kind of bumble through the process every year and it\u0026rsquo;s painful. There are people who know the tax laws really really well that make tools to help me file my taxes better. They\u0026rsquo;re not stripping power users of these filing tools of their needs, but they can reach both audiences.\nI think\n"},{"id":110,"href":"/misc/2023-06-25_lesson/","title":"Lesson 2023-06-25","section":"Miscs","content":" Business # Join the SLC MS 9th Ward EQ Discord server! Set up a ministering interview with Ashton Reading # D\u0026amp;C 20:46–47,53–54,59 Moroni 6:3–5 Supplemental # Anytime you do anything that helps anyone—on either side of the veil—take a step toward making covenants with God and receiving their essential baptismal and temple ordinances, you are helping to gather Israel. It is as simple as that.\nPresident Nelson\nI would expand this to \u0026ldquo;any time you help someone take a step toward keeping their covenants and letting God into their lives a little more\u0026rdquo;.\nTo all brethren holding the priesthood, I invite you to inspire members to keep their covenants, fast and pray, study the scriptures, worship in the temple, and serve with faith as men and women of God. We can help all to see with the eye of faith that obedience and righteousness will draw them closer to Jesus Christ, allow them to enjoy the companionship of the Holy Ghost, and experience joy in life!\nA hallmark of the Lord’s true and living Church will always be an organized, directed effort to minister to individual children of God and their families. Because it is His Church, we as His servants will minister to the one, just as He did. We will minister in His name, with His power and authority, and with His loving-kindness.\nPresident Nelson\n"},{"id":111,"href":"/posts/2021-08-28_rule_of_experts/","title":"Rule of Experts","section":"Technical Blog","content":"Wouldn’t it be nice if experts ruled place? Instead of politicians who know nothing, you could get a domain expert to make informed decisions.\n"},{"id":112,"href":"/posts/2021-04_coddling_mind/","title":"The Coddling of the American Mind","section":"Technical Blog","content":"Note: I might want to just publish the summary, or omit parts of the reading notes.\nSummary # Reading Notes # p. 28: I love the cross-talk between some of Taleb\u0026rsquo;s ideas (specifically about antifragility) and what a university is supposed to provide. Part of the problem with these \u0026ldquo;safe spaces\u0026rdquo; is that, by validating people\u0026rsquo;s feelings and deeply-held beliefs by removing them from alternative viewpoints, you are suggesting that their beliefs, formed without a wholistic perspective, are good enough. It destructs the entire purpose of learning.\nI\u0026rsquo;m reminded about the things\n"},{"id":113,"href":"/posts/2020-10-22-privacy/","title":"Why Privacy","section":"Technical Blog","content":"why should anyone care about privacy? Privacy is important because it prevents bad actors from learning about you. If a bad actor can learn about you, they can anticipate your actions and beliefs, and uses things in coordination to influence your behavior without your awareness.\nI think that digital surveillance is in part responsible for the polarization we see in our society. When people know that they are being watched, or that their events are being broadcast to a wide audience, they may act in ways that are easier to define. Instead of being a moderate who agrees with Democrats on some issues but Republicans on some other issues, the persona they broadcast online encourages some more pure, more extreme beliefs.\n"}]