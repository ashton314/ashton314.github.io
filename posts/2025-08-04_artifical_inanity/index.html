<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="There&rsquo;s something icky about LLM-generated text when you think it&rsquo;s written by a human. I think I finally put my finger on one reason why I feel this way.">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#eceff4">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#121519">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="https://lambdaland.org/posts/2025-08-04_artifical_inanity/">
  <meta property="og:site_name" content="Lambda Land">
  <meta property="og:title" content="AI stands for “Artificial Inanity”">
  <meta property="og:description" content="There’s something icky about LLM-generated text when you think it’s written by a human. I think I finally put my finger on one reason why I feel this way.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-08-04T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-08-04T00:00:00+00:00">
    <meta property="article:tag" content="Writing">
<title>AI stands for “Artificial Inanity” | Lambda Land</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" >
<link rel="stylesheet" href="/book.min.c213a7040939e3bdda137b858c10dae85781d1599a31b2aee8be2feb4500ce1b.css" integrity="sha256-whOnBAk5473aE3uFjBDa6FeB0VmaMbKu6L4v60UAzhs=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.29e7047ec5edb1ecf9a407522a22452c07bec48565176f1c833fd0f9facc201f.js" integrity="sha256-KecEfsXtsez5pAdSKiJFLAe&#43;xIVlF28cgz/Q&#43;frMIB8=" crossorigin="anonymous"></script>

  <script defer src="/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js" integrity="sha256-b2&#43;Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC&#43;NdcPIvZhzk=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><img src="/img/lambda_logo.png" alt="Logo" /><span>Lambda Land</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>











  



  
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/about/" class="">About</a>
  

        </li>
      
    
  </ul>











  
<ul>
  
  <li>
    <a href="/posts/"  >
        Technical Blog
      </a>
  </li>
  
  <li>
    <a href="/index.xml"  target="_blank" rel="noopener">
        RSS Feed
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 

        
        <hr />
        <div class="my-book-toc">
          <div class="my-book-toc-content">
            
  
<details>
  <summary>Contents</summary>
  <nav id="TableOfContents"></nav>
</details>


 
          </div>
        </div>
        
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>AI stands for “Artificial Inanity”</strong>

  
</div>


  
  <aside class="hidden clearfix">
    
  
<details>
  <summary>Contents</summary>
  <nav id="TableOfContents"></nav>
</details>



  </aside>
  
 
      </header>

      
      
<article class="markdown">
  <h1>
    <a href="/posts/2025-08-04_artifical_inanity/">AI stands for “Artificial Inanity”</a>
  </h1>
  
  <h5>4 Aug 2025</h5>



  

  
  <div class="post-metadata-tags">
    
      <a href="/tags/writing/">Writing</a>
  </div>
  



<p>There&rsquo;s something icky about LLM-generated text when you think it&rsquo;s written by a human. I think I finally put my finger on one reason why I feel this way.</p>
<div class="marginnote">
<p>Note on the title: &ldquo;Artificial Inanity&rdquo; comes from Neal Stephenson&rsquo;s novel <em>Anathem</em>.</p>
</div>
<p>At work I was sent a long design document and asked for my thoughts on it. As I read, I had a really hard time following it. Eventually I guessed correctly (confirmed via a follow-up conversation I had with the &ldquo;author&rdquo;<label class="margin-toggle sidenote-number" for="sn1"></label>
<input id="sn1" class="margin-toggle" type="checkbox">
<span class="sidenote">
I have &ldquo;author&rdquo; in quotes because, if a machine wrote it, you don&rsquo;t merit being called the <em>author</em> of the work.
</span>
) that an LLM had generated the majority of the document. Parts of it <em>sounded</em> like a decent design document, but there was just way too much fluff that served only to confuse me.</p>
<p>When I read technical documents, I read to understand the content. In this mode of reading, I operate under the assumption that the author had a reason for choosing the words they did, and that every sentence is there to convey something that the author wishes me to understand.</p>
<p>This mode fails when an LLM or the like has generated the text. When I read something I know came out of a computer&rsquo;s probabilistic sampling of a token-space, I have read knowing that every statement might be some hallucinated slop or incidental filler. I <em>cannot</em> trust that the human operator&rsquo;s intent is expressed by the machine. In fact, I am confident that it is often <em>not</em>, but I have to waste tremendous effort trying to find that gap. Reading slop text when I think I&rsquo;m reading real text is exhausting: since I am not on the alert for hallucinations or irrelevancies, every turn of phrase that seems out of place causes me to wonder <em>why that phrase it there</em> and <em>what am I missing</em> when in reality, such questions are ill formed: that was just a phrase composed by accident that <em>sounds</em> good but actually is devoid of much intent at all.</p>
<p><em>Intent</em> is the core thing: the <em>lack</em> of intent is what makes reading AI-slop so revolting. There needs to be a human intent—human will and human care—behind everything that is demanded of our care and attention. Even if you agree with Rolland Barthes&rsquo;<label class="margin-toggle sidenote-number" for="sn2"></label>
<input id="sn2" class="margin-toggle" type="checkbox">
<span class="sidenote">
The author of <em>The Death of the Author</em>, an essay where Barthes argues that focusing on the author&rsquo;s intent is fruitless—the meaning of a text is the effect it has on the audience.
</span>
views on literary criticism, the fact that there <em>is</em> an author who put care and intent into a work imbues that work with infinitely more meaning than if it were spat out by a machine.</p>
<p>Counterfeits to human connection will—unfortunately—always be in demand. The multi-billion dollar industry churning out pornography is proof enough. People will probably always, from here on out, be using LLMs to cheat their way through classes and themselves out of learning. Some might turn to them for some faux-companionship. Others will be prompting themselves to death by offloading more and more of their reasoning to machines, convinced that the computer—like a slot machine—somehow will let them win bigger in life.</p>
<p>I am <strong>not</strong> saying that LLMs are worthless—they are marvels of engineering and can solve some particularly thorny problems that have confounded us for decades. But it&rsquo;s important to remember that, no matter how capable these machines get, they are not humans. And no human is so worthless as to be replaceable with a machine.</p></article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
<script async src="/js/menu_fixer.js"></script>
<script data-goatcounter="https://boink.lambdaland.org/count" async src="//boink.lambdaland.org/count.js"></script>
<a rel="me" style="display: none" href="https://fosstodon.org/@wiersdorf">Mastodon</a>
<div class="copyright-footer">
  <small>© Ashton Wiersdorf 2026</small>
</div>

      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

  </main>

  
</body>
</html>












